(5879, 300) (5879, 52) (2568, 300) (2568, 52) (15424, 300) (15424, 52)
17992
  (0, 7394)	6.686038286434835
  (0, 7579)	9.544554181485928
  (0, 8435)	1.1089956803115342
  (0, 9187)	1.4870258028519843
  (0, 9412)	3.4992585948383703
  (0, 9715)	8.687769937101656
  (0, 9722)	2.6831883644039674
  (0, 10649)	2.428921084638427
  (0, 10738)	0.09818243264420962
  (0, 10836)	3.739323224804961
  (0, 11937)	2.330442047497012
  (0, 12542)	3.606641355876964
  (0, 12888)	3.02851632033319
  (0, 13067)	4.35029811356276
  (0, 13073)	2.3388242585209373
  (0, 13236)	2.5284796776801453
  (0, 13573)	2.03853163893571
  (0, 13630)	1.7178555995344762
  (1, 6773)	4.6162200221746765
  (1, 7352)	2.48534630686257
  (1, 7394)	10.029057429652251
  (1, 8228)	3.3602874789180293
  (1, 8236)	11.429664621685571
  (1, 8707)	2.7241125791123393
  (1, 9657)	22.280113863795975
  :	:
  (17991, 6619)	5.00515582833163
  (17991, 6688)	2.5465482720906456
  (17991, 6690)	4.132423070796605
  (17991, 8122)	2.991346301610737
  (17991, 8579)	0.5254001830155217
  (17991, 9087)	5.452468046375295
  (17991, 9104)	3.2299256610547857
  (17991, 10380)	2.6292767444269107
  (17991, 10738)	0.09818243264420962
  (17991, 11118)	2.473542891137685
  (17991, 12137)	2.8079312509954106
  (17991, 12172)	4.065283689759292
  (17991, 12422)	4.74658184003792
  (17991, 12449)	6.0249872391466255
  (17991, 12450)	5.798847182840153
  (17991, 12762)	4.203374806768889
  (17991, 13101)	2.2203469947570738
  (17991, 13183)	4.231390464459422
  (17991, 13186)	2.330442047497012
  (17991, 13283)	1.2562305119428314
  (17991, 14115)	2.001260244138478
  (17991, 14362)	23.189205994155152
  (17991, 14446)	2.588071774882391
  (17991, 15151)	2.9569343040130085
  (17991, 15162)	2.6687238299637284
(17992, 17992)
(17992, 17992)
17992
Tensor("graphconvolution_2/SparseTensorDenseMatMul/SparseTensorDenseMatMul:0", shape=(None, 52), dtype=float32)
Epoch: 0001 train_loss= 3.95124 train_acc= 0.01633 val_loss= 3.93091 val_acc= 0.46401 time= 0.36909
Epoch: 0002 train_loss= 3.93171 train_acc= 0.44242 val_loss= 3.89803 val_acc= 0.45942 time= 0.14800
Epoch: 0003 train_loss= 3.89804 train_acc= 0.43681 val_loss= 3.85092 val_acc= 0.45636 time= 0.13009
Epoch: 0004 train_loss= 3.84915 train_acc= 0.43341 val_loss= 3.78821 val_acc= 0.45636 time= 0.13100
Epoch: 0005 train_loss= 3.79176 train_acc= 0.43324 val_loss= 3.70870 val_acc= 0.45636 time= 0.15600
Epoch: 0006 train_loss= 3.70517 train_acc= 0.43222 val_loss= 3.61194 val_acc= 0.45636 time= 0.13297
Epoch: 0007 train_loss= 3.61832 train_acc= 0.43239 val_loss= 3.49781 val_acc= 0.45636 time= 0.13400
Epoch: 0008 train_loss= 3.50415 train_acc= 0.43239 val_loss= 3.36791 val_acc= 0.45636 time= 0.13552
Epoch: 0009 train_loss= 3.36716 train_acc= 0.43239 val_loss= 3.22513 val_acc= 0.45636 time= 0.15840
Epoch: 0010 train_loss= 3.24010 train_acc= 0.43239 val_loss= 3.07396 val_acc= 0.45636 time= 0.13101
Epoch: 0011 train_loss= 3.07085 train_acc= 0.43239 val_loss= 2.91943 val_acc= 0.45636 time= 0.12999
Epoch: 0012 train_loss= 2.94665 train_acc= 0.43239 val_loss= 2.76771 val_acc= 0.45636 time= 0.15600
Epoch: 0013 train_loss= 2.80222 train_acc= 0.43239 val_loss= 2.62537 val_acc= 0.45636 time= 0.13001
Epoch: 0014 train_loss= 2.62189 train_acc= 0.43239 val_loss= 2.49928 val_acc= 0.45636 time= 0.12999
Epoch: 0015 train_loss= 2.51281 train_acc= 0.43239 val_loss= 2.39547 val_acc= 0.45636 time= 0.13300
Epoch: 0016 train_loss= 2.38769 train_acc= 0.43239 val_loss= 2.31586 val_acc= 0.45636 time= 0.15201
Epoch: 0017 train_loss= 2.31887 train_acc= 0.43239 val_loss= 2.25822 val_acc= 0.45636 time= 0.13528
Epoch: 0018 train_loss= 2.27853 train_acc= 0.43239 val_loss= 2.21685 val_acc= 0.45636 time= 0.13300
Epoch: 0019 train_loss= 2.22006 train_acc= 0.43239 val_loss= 2.18428 val_acc= 0.45636 time= 0.16000
Epoch: 0020 train_loss= 2.19202 train_acc= 0.43256 val_loss= 2.15337 val_acc= 0.45636 time= 0.13203
Epoch: 0021 train_loss= 2.16486 train_acc= 0.43273 val_loss= 2.11939 val_acc= 0.45636 time= 0.13205
Epoch: 0022 train_loss= 2.15950 train_acc= 0.43273 val_loss= 2.08027 val_acc= 0.45636 time= 0.13200
Epoch: 0023 train_loss= 2.08672 train_acc= 0.43324 val_loss= 2.03542 val_acc= 0.45636 time= 0.15205
Epoch: 0024 train_loss= 2.05235 train_acc= 0.43562 val_loss= 1.98609 val_acc= 0.45942 time= 0.13100
Epoch: 0025 train_loss= 2.00354 train_acc= 0.43885 val_loss= 1.93463 val_acc= 0.46708 time= 0.13300
Epoch: 0026 train_loss= 1.96600 train_acc= 0.45178 val_loss= 1.88343 val_acc= 0.47626 time= 0.15000
Epoch: 0027 train_loss= 1.91962 train_acc= 0.46096 val_loss= 1.83448 val_acc= 0.49005 time= 0.13095
Epoch: 0028 train_loss= 1.85999 train_acc= 0.47865 val_loss= 1.78911 val_acc= 0.50689 time= 0.13400
Epoch: 0029 train_loss= 1.81308 train_acc= 0.50927 val_loss= 1.74753 val_acc= 0.53446 time= 0.13560
Epoch: 0030 train_loss= 1.78073 train_acc= 0.52696 val_loss= 1.70927 val_acc= 0.55283 time= 0.16100
Epoch: 0031 train_loss= 1.72971 train_acc= 0.55605 val_loss= 1.67313 val_acc= 0.59724 time= 0.13200
Epoch: 0032 train_loss= 1.69232 train_acc= 0.58445 val_loss= 1.63779 val_acc= 0.62787 time= 0.13150
Epoch: 0033 train_loss= 1.66034 train_acc= 0.59704 val_loss= 1.60277 val_acc= 0.64165 time= 0.13300
Epoch: 0034 train_loss= 1.64006 train_acc= 0.61167 val_loss= 1.56772 val_acc= 0.66309 time= 0.15200
Epoch: 0035 train_loss= 1.58394 train_acc= 0.63140 val_loss= 1.53305 val_acc= 0.67075 time= 0.13000
Epoch: 0036 train_loss= 1.57310 train_acc= 0.64467 val_loss= 1.49900 val_acc= 0.68147 time= 0.13200
Epoch: 0037 train_loss= 1.51642 train_acc= 0.64994 val_loss= 1.46624 val_acc= 0.68913 time= 0.15400
Epoch: 0038 train_loss= 1.50144 train_acc= 0.65419 val_loss= 1.43478 val_acc= 0.69372 time= 0.13297
Epoch: 0039 train_loss= 1.47326 train_acc= 0.65300 val_loss= 1.40468 val_acc= 0.69525 time= 0.13400
Epoch: 0040 train_loss= 1.44788 train_acc= 0.65147 val_loss= 1.37602 val_acc= 0.69678 time= 0.13614
Epoch: 0041 train_loss= 1.39947 train_acc= 0.66321 val_loss= 1.34865 val_acc= 0.69678 time= 0.15597
Epoch: 0042 train_loss= 1.38912 train_acc= 0.66525 val_loss= 1.32213 val_acc= 0.69985 time= 0.13204
Epoch: 0043 train_loss= 1.36174 train_acc= 0.67750 val_loss= 1.29622 val_acc= 0.70597 time= 0.13000
Epoch: 0044 train_loss= 1.31963 train_acc= 0.68821 val_loss= 1.27107 val_acc= 0.71057 time= 0.15600
Epoch: 0045 train_loss= 1.29869 train_acc= 0.69553 val_loss= 1.24659 val_acc= 0.70904 time= 0.13399
Epoch: 0046 train_loss= 1.29855 train_acc= 0.69706 val_loss= 1.22287 val_acc= 0.71516 time= 0.13100
Epoch: 0047 train_loss= 1.25724 train_acc= 0.70607 val_loss= 1.19998 val_acc= 0.71822 time= 0.13200
Epoch: 0048 train_loss= 1.23400 train_acc= 0.71764 val_loss= 1.17795 val_acc= 0.72435 time= 0.15400
Epoch: 0049 train_loss= 1.20913 train_acc= 0.72223 val_loss= 1.15681 val_acc= 0.73354 time= 0.13364
Epoch: 0050 train_loss= 1.19297 train_acc= 0.73210 val_loss= 1.13648 val_acc= 0.74579 time= 0.13400
Epoch: 0051 train_loss= 1.17779 train_acc= 0.73958 val_loss= 1.11693 val_acc= 0.75191 time= 0.13700
Epoch: 0052 train_loss= 1.15593 train_acc= 0.74451 val_loss= 1.09792 val_acc= 0.75957 time= 0.15600
Epoch: 0053 train_loss= 1.14105 train_acc= 0.74588 val_loss= 1.07943 val_acc= 0.76417 time= 0.13103
Epoch: 0054 train_loss= 1.11017 train_acc= 0.76340 val_loss= 1.06135 val_acc= 0.76876 time= 0.13001
Epoch: 0055 train_loss= 1.10488 train_acc= 0.75676 val_loss= 1.04358 val_acc= 0.77335 time= 0.15499
Epoch: 0056 train_loss= 1.06949 train_acc= 0.77105 val_loss= 1.02605 val_acc= 0.77642 time= 0.13297
Epoch: 0057 train_loss= 1.06465 train_acc= 0.76050 val_loss= 1.00879 val_acc= 0.77948 time= 0.13103
Epoch: 0058 train_loss= 1.05188 train_acc= 0.76561 val_loss= 0.99179 val_acc= 0.78101 time= 0.15200
Epoch: 0059 train_loss= 1.01819 train_acc= 0.78057 val_loss= 0.97496 val_acc= 0.78407 time= 0.13300
Epoch: 0060 train_loss= 0.99729 train_acc= 0.78840 val_loss= 0.95845 val_acc= 0.79326 time= 0.13346
Epoch: 0061 train_loss= 0.98077 train_acc= 0.79282 val_loss= 0.94218 val_acc= 0.79479 time= 0.13500
Epoch: 0062 train_loss= 0.95852 train_acc= 0.79520 val_loss= 0.92626 val_acc= 0.79632 time= 0.13616
Epoch: 0063 train_loss= 0.95508 train_acc= 0.79095 val_loss= 0.91083 val_acc= 0.79939 time= 0.15800
Epoch: 0064 train_loss= 0.92912 train_acc= 0.79861 val_loss= 0.89580 val_acc= 0.80858 time= 0.13103
Epoch: 0065 train_loss= 0.91632 train_acc= 0.80167 val_loss= 0.88111 val_acc= 0.80704 time= 0.13000
Epoch: 0066 train_loss= 0.90451 train_acc= 0.80779 val_loss= 0.86687 val_acc= 0.80858 time= 0.15500
Epoch: 0067 train_loss= 0.88943 train_acc= 0.80949 val_loss= 0.85277 val_acc= 0.81470 time= 0.13100
Epoch: 0068 train_loss= 0.87736 train_acc= 0.80643 val_loss= 0.83877 val_acc= 0.81623 time= 0.13100
Epoch: 0069 train_loss= 0.86346 train_acc= 0.81051 val_loss= 0.82471 val_acc= 0.81623 time= 0.13300
Epoch: 0070 train_loss= 0.85235 train_acc= 0.81834 val_loss= 0.81088 val_acc= 0.81776 time= 0.15100
Epoch: 0071 train_loss= 0.82837 train_acc= 0.82157 val_loss= 0.79738 val_acc= 0.81930 time= 0.13297
Epoch: 0072 train_loss= 0.81800 train_acc= 0.82939 val_loss= 0.78423 val_acc= 0.82083 time= 0.13300
Epoch: 0073 train_loss= 0.80761 train_acc= 0.82242 val_loss= 0.77147 val_acc= 0.82389 time= 0.16000
Epoch: 0074 train_loss= 0.79169 train_acc= 0.82497 val_loss= 0.75893 val_acc= 0.82695 time= 0.13300
Epoch: 0075 train_loss= 0.76612 train_acc= 0.82854 val_loss= 0.74656 val_acc= 0.82695 time= 0.13003
Epoch: 0076 train_loss= 0.75853 train_acc= 0.83484 val_loss= 0.73453 val_acc= 0.83002 time= 0.13305
Epoch: 0077 train_loss= 0.74774 train_acc= 0.83654 val_loss= 0.72275 val_acc= 0.83461 time= 0.15205
Epoch: 0078 train_loss= 0.74160 train_acc= 0.83722 val_loss= 0.71117 val_acc= 0.84074 time= 0.13045
Epoch: 0079 train_loss= 0.71558 train_acc= 0.84385 val_loss= 0.69981 val_acc= 0.84227 time= 0.13196
Epoch: 0080 train_loss= 0.71108 train_acc= 0.84470 val_loss= 0.68843 val_acc= 0.84686 time= 0.15704
Epoch: 0081 train_loss= 0.70732 train_acc= 0.84198 val_loss= 0.67726 val_acc= 0.85299 time= 0.13400
Epoch: 0082 train_loss= 0.69457 train_acc= 0.85168 val_loss= 0.66595 val_acc= 0.85605 time= 0.13425
Epoch: 0083 train_loss= 0.68052 train_acc= 0.84606 val_loss= 0.65477 val_acc= 0.85911 time= 0.13400
Epoch: 0084 train_loss= 0.66618 train_acc= 0.85185 val_loss= 0.64408 val_acc= 0.86371 time= 0.16000
Epoch: 0085 train_loss= 0.66380 train_acc= 0.85355 val_loss= 0.63385 val_acc= 0.86524 time= 0.13300
Epoch: 0086 train_loss= 0.64528 train_acc= 0.85457 val_loss= 0.62379 val_acc= 0.86830 time= 0.13100
Epoch: 0087 train_loss= 0.63843 train_acc= 0.85304 val_loss= 0.61401 val_acc= 0.87136 time= 0.13303
Epoch: 0088 train_loss= 0.61515 train_acc= 0.86290 val_loss= 0.60445 val_acc= 0.87443 time= 0.15301
Epoch: 0089 train_loss= 0.60060 train_acc= 0.86800 val_loss= 0.59522 val_acc= 0.87443 time= 0.13104
Epoch: 0090 train_loss= 0.60551 train_acc= 0.86290 val_loss= 0.58633 val_acc= 0.87596 time= 0.13149
Epoch: 0091 train_loss= 0.60237 train_acc= 0.87090 val_loss= 0.57778 val_acc= 0.87902 time= 0.15499
Epoch: 0092 train_loss= 0.57966 train_acc= 0.86852 val_loss= 0.56954 val_acc= 0.88208 time= 0.13200
Epoch: 0093 train_loss= 0.56372 train_acc= 0.88093 val_loss= 0.56134 val_acc= 0.88361 time= 0.13426
Epoch: 0094 train_loss= 0.55881 train_acc= 0.87583 val_loss= 0.55279 val_acc= 0.88974 time= 0.13600
Epoch: 0095 train_loss= 0.56011 train_acc= 0.87430 val_loss= 0.54421 val_acc= 0.88974 time= 0.15700
Epoch: 0096 train_loss= 0.54855 train_acc= 0.88110 val_loss= 0.53595 val_acc= 0.88974 time= 0.13200
Epoch: 0097 train_loss= 0.54415 train_acc= 0.87957 val_loss= 0.52817 val_acc= 0.89280 time= 0.13100
Epoch: 0098 train_loss= 0.51998 train_acc= 0.88893 val_loss= 0.52089 val_acc= 0.88821 time= 0.15584
Epoch: 0099 train_loss= 0.51878 train_acc= 0.88501 val_loss= 0.51415 val_acc= 0.88668 time= 0.13159
Epoch: 0100 train_loss= 0.52610 train_acc= 0.87685 val_loss= 0.50775 val_acc= 0.88361 time= 0.13201
Epoch: 0101 train_loss= 0.51212 train_acc= 0.88433 val_loss= 0.50159 val_acc= 0.88515 time= 0.13399
Epoch: 0102 train_loss= 0.50453 train_acc= 0.88859 val_loss= 0.49534 val_acc= 0.88821 time= 0.15600
Epoch: 0103 train_loss= 0.49153 train_acc= 0.88944 val_loss= 0.48945 val_acc= 0.88821 time= 0.13100
Epoch: 0104 train_loss= 0.49994 train_acc= 0.88229 val_loss= 0.48305 val_acc= 0.88821 time= 0.13400
Epoch: 0105 train_loss= 0.47531 train_acc= 0.89233 val_loss= 0.47647 val_acc= 0.88821 time= 0.13600
Epoch: 0106 train_loss= 0.47749 train_acc= 0.89335 val_loss= 0.47037 val_acc= 0.89127 time= 0.15600
Epoch: 0107 train_loss= 0.45627 train_acc= 0.89131 val_loss= 0.46465 val_acc= 0.89433 time= 0.13200
Epoch: 0108 train_loss= 0.45699 train_acc= 0.89624 val_loss= 0.45916 val_acc= 0.89433 time= 0.13000
Epoch: 0109 train_loss= 0.45991 train_acc= 0.89879 val_loss= 0.45381 val_acc= 0.89587 time= 0.14300
Epoch: 0110 train_loss= 0.44398 train_acc= 0.89709 val_loss= 0.44874 val_acc= 0.89587 time= 0.13107
Epoch: 0111 train_loss= 0.44716 train_acc= 0.89794 val_loss= 0.44403 val_acc= 0.89587 time= 0.13101
Epoch: 0112 train_loss= 0.43786 train_acc= 0.89743 val_loss= 0.43940 val_acc= 0.89587 time= 0.13299
Epoch: 0113 train_loss= 0.43951 train_acc= 0.89573 val_loss= 0.43477 val_acc= 0.89433 time= 0.15200
Epoch: 0114 train_loss= 0.41727 train_acc= 0.90356 val_loss= 0.43005 val_acc= 0.89587 time= 0.13186
Epoch: 0115 train_loss= 0.41796 train_acc= 0.90679 val_loss= 0.42511 val_acc= 0.89893 time= 0.13300
Epoch: 0116 train_loss= 0.42535 train_acc= 0.90134 val_loss= 0.42039 val_acc= 0.90046 time= 0.16003
Epoch: 0117 train_loss= 0.42049 train_acc= 0.90815 val_loss= 0.41609 val_acc= 0.90046 time= 0.13800
Epoch: 0118 train_loss= 0.40101 train_acc= 0.90713 val_loss= 0.41203 val_acc= 0.90046 time= 0.13100
Epoch: 0119 train_loss= 0.40480 train_acc= 0.90798 val_loss= 0.40809 val_acc= 0.90658 time= 0.13101
Epoch: 0120 train_loss= 0.39416 train_acc= 0.90934 val_loss= 0.40446 val_acc= 0.90658 time= 0.15399
Epoch: 0121 train_loss= 0.38345 train_acc= 0.91597 val_loss= 0.40107 val_acc= 0.90658 time= 0.13201
Epoch: 0122 train_loss= 0.37896 train_acc= 0.91869 val_loss= 0.39820 val_acc= 0.90352 time= 0.13096
Epoch: 0123 train_loss= 0.38061 train_acc= 0.91495 val_loss= 0.39488 val_acc= 0.90046 time= 0.13303
Epoch: 0124 train_loss= 0.37629 train_acc= 0.91818 val_loss= 0.39226 val_acc= 0.90199 time= 0.15200
Epoch: 0125 train_loss= 0.37209 train_acc= 0.91852 val_loss= 0.38826 val_acc= 0.89893 time= 0.13497
Epoch: 0126 train_loss= 0.37376 train_acc= 0.91580 val_loss= 0.38410 val_acc= 0.90352 time= 0.13400
Epoch: 0127 train_loss= 0.35983 train_acc= 0.91699 val_loss= 0.37980 val_acc= 0.90505 time= 0.16000
Epoch: 0128 train_loss= 0.35643 train_acc= 0.91767 val_loss= 0.37620 val_acc= 0.90505 time= 0.13204
Epoch: 0129 train_loss= 0.34088 train_acc= 0.91818 val_loss= 0.37302 val_acc= 0.90505 time= 0.13200
Epoch: 0130 train_loss= 0.34678 train_acc= 0.92039 val_loss= 0.37049 val_acc= 0.90812 time= 0.13400
Epoch: 0131 train_loss= 0.35737 train_acc= 0.91988 val_loss= 0.36799 val_acc= 0.91118 time= 0.15100
Epoch: 0132 train_loss= 0.33236 train_acc= 0.92703 val_loss= 0.36595 val_acc= 0.90965 time= 0.13001
Epoch: 0133 train_loss= 0.35385 train_acc= 0.92056 val_loss= 0.36427 val_acc= 0.91271 time= 0.13100
Epoch: 0134 train_loss= 0.34006 train_acc= 0.92329 val_loss= 0.36255 val_acc= 0.90965 time= 0.15499
Epoch: 0135 train_loss= 0.33206 train_acc= 0.92550 val_loss= 0.36110 val_acc= 0.90812 time= 0.12997
Epoch: 0136 train_loss= 0.32375 train_acc= 0.92890 val_loss= 0.35916 val_acc= 0.90659 time= 0.13400
Epoch: 0137 train_loss= 0.32565 train_acc= 0.92839 val_loss= 0.35624 val_acc= 0.90505 time= 0.16100
Epoch: 0138 train_loss= 0.32394 train_acc= 0.92584 val_loss= 0.35324 val_acc= 0.90812 time= 0.14457
Epoch: 0139 train_loss= 0.31515 train_acc= 0.92703 val_loss= 0.34998 val_acc= 0.90812 time= 0.13104
Epoch: 0140 train_loss= 0.31050 train_acc= 0.92839 val_loss= 0.34698 val_acc= 0.90659 time= 0.13100
Epoch: 0141 train_loss= 0.30899 train_acc= 0.92856 val_loss= 0.34413 val_acc= 0.90965 time= 0.15601
Epoch: 0142 train_loss= 0.30647 train_acc= 0.92924 val_loss= 0.34108 val_acc= 0.90812 time= 0.12910
Epoch: 0143 train_loss= 0.31106 train_acc= 0.92805 val_loss= 0.33823 val_acc= 0.91118 time= 0.13100
Epoch: 0144 train_loss= 0.29154 train_acc= 0.93349 val_loss= 0.33534 val_acc= 0.91271 time= 0.13400
Epoch: 0145 train_loss= 0.29911 train_acc= 0.93094 val_loss= 0.33363 val_acc= 0.91271 time= 0.15800
Epoch: 0146 train_loss= 0.29987 train_acc= 0.93128 val_loss= 0.33237 val_acc= 0.91577 time= 0.13181
Epoch: 0147 train_loss= 0.28827 train_acc= 0.93111 val_loss= 0.33131 val_acc= 0.91424 time= 0.13297
Epoch: 0148 train_loss= 0.28278 train_acc= 0.93230 val_loss= 0.33011 val_acc= 0.91730 time= 0.13703
Epoch: 0149 train_loss= 0.27674 train_acc= 0.93945 val_loss= 0.32857 val_acc= 0.91730 time= 0.15700
Epoch: 0150 train_loss= 0.27210 train_acc= 0.94047 val_loss= 0.32681 val_acc= 0.91577 time= 0.13100
Epoch: 0151 train_loss= 0.27802 train_acc= 0.93621 val_loss= 0.32473 val_acc= 0.91271 time= 0.12999
Epoch: 0152 train_loss= 0.27940 train_acc= 0.93621 val_loss= 0.32271 val_acc= 0.91424 time= 0.15600
Epoch: 0153 train_loss= 0.27610 train_acc= 0.93519 val_loss= 0.32033 val_acc= 0.91577 time= 0.13008
Epoch: 0154 train_loss= 0.26819 train_acc= 0.93349 val_loss= 0.31799 val_acc= 0.91577 time= 0.13073
Epoch: 0155 train_loss= 0.27076 train_acc= 0.93621 val_loss= 0.31599 val_acc= 0.91271 time= 0.13300
Epoch: 0156 train_loss= 0.27933 train_acc= 0.93553 val_loss= 0.31372 val_acc= 0.91424 time= 0.15308
Epoch: 0157 train_loss= 0.27187 train_acc= 0.93689 val_loss= 0.31228 val_acc= 0.91577 time= 0.13497
Epoch: 0158 train_loss= 0.25746 train_acc= 0.93945 val_loss= 0.31055 val_acc= 0.91577 time= 0.13400
Epoch: 0159 train_loss= 0.25957 train_acc= 0.93860 val_loss= 0.30895 val_acc= 0.91577 time= 0.16100
Epoch: 0160 train_loss= 0.24206 train_acc= 0.94557 val_loss= 0.30757 val_acc= 0.91884 time= 0.13604
Epoch: 0161 train_loss= 0.24425 train_acc= 0.94047 val_loss= 0.30595 val_acc= 0.91884 time= 0.13103
Epoch: 0162 train_loss= 0.24403 train_acc= 0.94557 val_loss= 0.30466 val_acc= 0.92037 time= 0.13100
Epoch: 0163 train_loss= 0.24536 train_acc= 0.94540 val_loss= 0.30374 val_acc= 0.92343 time= 0.14500
Epoch: 0164 train_loss= 0.24026 train_acc= 0.94506 val_loss= 0.30310 val_acc= 0.92037 time= 0.13109
Epoch: 0165 train_loss= 0.24445 train_acc= 0.94387 val_loss= 0.30270 val_acc= 0.92037 time= 0.13100
Epoch: 0166 train_loss= 0.23236 train_acc= 0.94999 val_loss= 0.30219 val_acc= 0.91884 time= 0.13304
Epoch: 0167 train_loss= 0.24077 train_acc= 0.94404 val_loss= 0.30142 val_acc= 0.91884 time= 0.15297
Epoch: 0168 train_loss= 0.23575 train_acc= 0.94829 val_loss= 0.29997 val_acc= 0.91730 time= 0.13400
Epoch: 0169 train_loss= 0.23379 train_acc= 0.94268 val_loss= 0.29822 val_acc= 0.91884 time= 0.13500
Epoch: 0170 train_loss= 0.21877 train_acc= 0.94897 val_loss= 0.29725 val_acc= 0.91577 time= 0.16000
Epoch: 0171 train_loss= 0.21676 train_acc= 0.94999 val_loss= 0.29655 val_acc= 0.91730 time= 0.13105
Epoch: 0172 train_loss= 0.22973 train_acc= 0.94489 val_loss= 0.29513 val_acc= 0.91730 time= 0.12995
Epoch: 0173 train_loss= 0.22567 train_acc= 0.94506 val_loss= 0.29390 val_acc= 0.91884 time= 0.14900
Epoch: 0174 train_loss= 0.23104 train_acc= 0.94625 val_loss= 0.29213 val_acc= 0.91884 time= 0.13700
Epoch: 0175 train_loss= 0.23193 train_acc= 0.94693 val_loss= 0.29092 val_acc= 0.91730 time= 0.13000
Epoch: 0176 train_loss= 0.21444 train_acc= 0.95305 val_loss= 0.29059 val_acc= 0.91884 time= 0.13140
Epoch: 0177 train_loss= 0.21632 train_acc= 0.94999 val_loss= 0.29016 val_acc= 0.91730 time= 0.13400
Epoch: 0178 train_loss= 0.21704 train_acc= 0.94659 val_loss= 0.28944 val_acc= 0.91884 time= 0.15500
Epoch: 0179 train_loss= 0.22869 train_acc= 0.94744 val_loss= 0.28913 val_acc= 0.92037 time= 0.13600
Epoch: 0180 train_loss= 0.20957 train_acc= 0.95271 val_loss= 0.28829 val_acc= 0.92190 time= 0.13400
Epoch: 0181 train_loss= 0.20920 train_acc= 0.95629 val_loss= 0.28756 val_acc= 0.92037 time= 0.15604
Epoch: 0182 train_loss= 0.20867 train_acc= 0.94999 val_loss= 0.28664 val_acc= 0.91884 time= 0.13095
Epoch: 0183 train_loss= 0.21116 train_acc= 0.95152 val_loss= 0.28510 val_acc= 0.91884 time= 0.13100
Epoch: 0184 train_loss= 0.19757 train_acc= 0.95356 val_loss= 0.28350 val_acc= 0.92343 time= 0.14100
Epoch: 0185 train_loss= 0.19831 train_acc= 0.95390 val_loss= 0.28194 val_acc= 0.92649 time= 0.13805
Epoch: 0186 train_loss= 0.19390 train_acc= 0.95663 val_loss= 0.28041 val_acc= 0.92802 time= 0.13100
Epoch: 0187 train_loss= 0.19635 train_acc= 0.95356 val_loss= 0.27862 val_acc= 0.92802 time= 0.12995
Epoch: 0188 train_loss= 0.19778 train_acc= 0.95271 val_loss= 0.27715 val_acc= 0.92496 time= 0.16000
Epoch: 0189 train_loss= 0.20153 train_acc= 0.95356 val_loss= 0.27598 val_acc= 0.92496 time= 0.13800
Epoch: 0190 train_loss= 0.19768 train_acc= 0.95646 val_loss= 0.27556 val_acc= 0.92802 time= 0.13400
Epoch: 0191 train_loss= 0.19498 train_acc= 0.95560 val_loss= 0.27517 val_acc= 0.92649 time= 0.13400
Epoch: 0192 train_loss= 0.18761 train_acc= 0.95577 val_loss= 0.27519 val_acc= 0.92649 time= 0.15100
Epoch: 0193 train_loss= 0.19044 train_acc= 0.95526 val_loss= 0.27559 val_acc= 0.92802 time= 0.13025
Epoch: 0194 train_loss= 0.19190 train_acc= 0.95475 val_loss= 0.27619 val_acc= 0.92802 time= 0.13103
Epoch: 0195 train_loss= 0.20024 train_acc= 0.95407 val_loss= 0.27598 val_acc= 0.92802 time= 0.15610
Epoch: 0196 train_loss= 0.18717 train_acc= 0.95612 val_loss= 0.27503 val_acc= 0.92802 time= 0.13796
Epoch: 0197 train_loss= 0.17820 train_acc= 0.95731 val_loss= 0.27349 val_acc= 0.92802 time= 0.13104
Epoch: 0198 train_loss= 0.18466 train_acc= 0.95850 val_loss= 0.27151 val_acc= 0.92802 time= 0.13100
Epoch: 0199 train_loss= 0.18062 train_acc= 0.95748 val_loss= 0.26977 val_acc= 0.92649 time= 0.16196
Epoch: 0200 train_loss= 0.17759 train_acc= 0.95816 val_loss= 0.26806 val_acc= 0.92649 time= 0.13300
Epoch: 0201 train_loss= 0.17265 train_acc= 0.95867 val_loss= 0.26744 val_acc= 0.92496 time= 0.13500
Epoch: 0202 train_loss= 0.18209 train_acc= 0.95901 val_loss= 0.26758 val_acc= 0.92649 time= 0.13700
Epoch: 0203 train_loss= 0.17635 train_acc= 0.95901 val_loss= 0.26762 val_acc= 0.92802 time= 0.15204
Epoch: 0204 train_loss= 0.16578 train_acc= 0.96241 val_loss= 0.26745 val_acc= 0.92802 time= 0.13096
Epoch: 0205 train_loss= 0.17203 train_acc= 0.96003 val_loss= 0.26747 val_acc= 0.92956 time= 0.13100
Epoch: 0206 train_loss= 0.17263 train_acc= 0.96003 val_loss= 0.26751 val_acc= 0.92956 time= 0.15600
Epoch: 0207 train_loss= 0.17614 train_acc= 0.96156 val_loss= 0.26704 val_acc= 0.93109 time= 0.13005
Epoch: 0208 train_loss= 0.17550 train_acc= 0.95646 val_loss= 0.26588 val_acc= 0.93109 time= 0.13100
Epoch: 0209 train_loss= 0.16768 train_acc= 0.96122 val_loss= 0.26475 val_acc= 0.93109 time= 0.15815
Epoch: 0210 train_loss= 0.15805 train_acc= 0.96496 val_loss= 0.26327 val_acc= 0.92956 time= 0.14100
Epoch: 0211 train_loss= 0.16239 train_acc= 0.96394 val_loss= 0.26217 val_acc= 0.92956 time= 0.13400
Epoch: 0212 train_loss= 0.17560 train_acc= 0.95952 val_loss= 0.26126 val_acc= 0.93109 time= 0.13400
Epoch: 0213 train_loss= 0.16516 train_acc= 0.96309 val_loss= 0.26071 val_acc= 0.92956 time= 0.13603
Epoch: 0214 train_loss= 0.16536 train_acc= 0.96513 val_loss= 0.26063 val_acc= 0.92956 time= 0.15297
Epoch: 0215 train_loss= 0.15994 train_acc= 0.96496 val_loss= 0.26062 val_acc= 0.92802 time= 0.13005
Epoch: 0216 train_loss= 0.15645 train_acc= 0.96615 val_loss= 0.26003 val_acc= 0.92956 time= 0.13195
Epoch: 0217 train_loss= 0.15856 train_acc= 0.96462 val_loss= 0.25894 val_acc= 0.93109 time= 0.15500
Epoch: 0218 train_loss= 0.16381 train_acc= 0.96139 val_loss= 0.25770 val_acc= 0.93109 time= 0.13005
Epoch: 0219 train_loss= 0.16551 train_acc= 0.95867 val_loss= 0.25693 val_acc= 0.93109 time= 0.13200
Epoch: 0220 train_loss= 0.15716 train_acc= 0.96479 val_loss= 0.25566 val_acc= 0.93109 time= 0.15795
Epoch: 0221 train_loss= 0.15791 train_acc= 0.96105 val_loss= 0.25516 val_acc= 0.92956 time= 0.13300
Epoch: 0222 train_loss= 0.16195 train_acc= 0.96037 val_loss= 0.25481 val_acc= 0.93109 time= 0.13440
Epoch: 0223 train_loss= 0.14374 train_acc= 0.96870 val_loss= 0.25467 val_acc= 0.93262 time= 0.14200
Epoch: 0224 train_loss= 0.15561 train_acc= 0.96241 val_loss= 0.25458 val_acc= 0.93109 time= 0.14100
Epoch: 0225 train_loss= 0.15711 train_acc= 0.96173 val_loss= 0.25464 val_acc= 0.93109 time= 0.13004
Epoch: 0226 train_loss= 0.15414 train_acc= 0.96462 val_loss= 0.25494 val_acc= 0.93109 time= 0.13001
Epoch: 0227 train_loss= 0.14364 train_acc= 0.96632 val_loss= 0.25540 val_acc= 0.93415 time= 0.13398
Epoch: 0228 train_loss= 0.15068 train_acc= 0.96564 val_loss= 0.25591 val_acc= 0.93262 time= 0.15201
Early stopping...
Optimization Finished!
Test set results: cost= 0.29720 accuracy= 0.93030 time= 0.06001
17992
Test Precision, Recall and F1-Score...
              precision    recall  f1-score   support

           0     1.0000    0.7500    0.8571         8
           1     0.5000    0.3333    0.4000         6
           2     0.5000    1.0000    0.6667         1
           3     0.7500    0.9200    0.8263        75
           4     0.9000    1.0000    0.9474         9
           5     0.8367    0.9425    0.8865        87
           6     0.9583    0.9200    0.9388        25
           7     0.7857    0.8462    0.8148        13
           8     0.8333    0.9091    0.8696        11
           9     1.0000    0.1111    0.2000         9
          10     0.8800    0.6111    0.7213        36
          11     1.0000    0.9167    0.9565        12
          12     0.8511    0.9917    0.9160       121
          13     0.8000    0.6316    0.7059        19
          14     0.8276    0.8571    0.8421        28
          15     0.0000    0.0000    0.0000         4
          16     0.0000    0.0000    0.0000         4
          17     0.0000    0.0000    0.0000         3
          18     0.8571    0.6000    0.7059        10
          19     1.0000    1.0000    1.0000         2
          20     0.8333    0.5556    0.6667         9
          21     0.9048    0.9500    0.9268        20
          22     0.4000    0.4000    0.4000         5
          23     0.0000    0.0000    0.0000         1
          24     0.7222    0.7647    0.7429        17
          25     1.0000    0.8667    0.9286        15
          26     0.0000    0.0000    0.0000         1
          27     0.8889    0.6667    0.7619        12
          28     0.7000    0.6364    0.6667        11
          29     0.9629    0.9684    0.9656       696
          30     0.9565    1.0000    0.9778        22
          31     1.0000    1.0000    1.0000         3
          32     0.4706    0.8000    0.5926        10
          33     1.0000    0.6667    0.8000         3
          34     1.0000    1.0000    1.0000         1
          35     0.8642    0.8642    0.8642        81
          36     1.0000    0.3333    0.5000        12
          37     1.0000    0.7500    0.8571         4
          38     0.0000    0.0000    0.0000         1
          39     0.9781    0.9917    0.9849      1083
          40     1.0000    0.8000    0.8889         5
          41     0.0000    0.0000    0.0000         2
          42     0.8750    0.7778    0.8235         9
          43     1.0000    0.3333    0.5000         3
          44     0.8462    0.9167    0.8800        12
          45     0.0000    0.0000    0.0000         6
          46     1.0000    0.2857    0.4444         7
          47     0.6842    0.8667    0.7647        15
          48     0.8889    0.8889    0.8889         9
          49     0.0000    0.0000    0.0000         1
          50     1.0000    0.2000    0.3333         5
          51     1.0000    0.7500    0.8571         4

    accuracy                         0.9303      2568
   macro avg     0.7165    0.6226    0.6398      2568
weighted avg     0.9261    0.9303    0.9231      2568

Macro average Test Precision, Recall and F1-Score...
(0.7164552860634353, 0.6225718686078466, 0.6398370532514439, None)
Micro average Test Precision, Recall and F1-Score...
(0.9302959501557633, 0.9302959501557633, 0.9302959501557633, None)
embeddings:
8892 6532 2568
[[ 0.01326894  2.715223   -0.05120938 ...  0.12384033  0.47598293
   3.2188861 ]
 [ 0.1538347   1.187957    0.24811915 ...  0.5742227   0.72816783
   0.6845976 ]
 [ 0.05841291  1.225034    0.52004564 ...  0.18024875  0.17040844
   1.5958027 ]
 ...
 [ 0.05711704  0.3364981   0.45759726 ...  0.05913748  0.07512158
   0.63459265]
 [ 0.09209744  0.6732789   0.25878665 ...  0.07835294  0.11462606
   0.90682864]
 [ 0.4964905   0.35297275  0.37943962 ...  0.530378    0.52895033
   0.45888186]]
