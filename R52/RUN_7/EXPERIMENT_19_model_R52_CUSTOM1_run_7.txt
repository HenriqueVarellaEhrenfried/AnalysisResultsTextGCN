(5879, 300) (5879, 52) (2568, 300) (2568, 52) (15424, 300) (15424, 52)
17992
  (0, 7394)	6.686038286434835
  (0, 7579)	9.544554181485928
  (0, 8435)	1.1089956803115342
  (0, 9187)	1.4870258028519843
  (0, 9412)	3.4992585948383703
  (0, 9715)	8.687769937101656
  (0, 9722)	2.6831883644039674
  (0, 10649)	2.428921084638427
  (0, 10738)	0.09818243264420962
  (0, 10836)	3.739323224804961
  (0, 11937)	2.330442047497012
  (0, 12542)	3.606641355876964
  (0, 12888)	3.02851632033319
  (0, 13067)	4.35029811356276
  (0, 13073)	2.3388242585209373
  (0, 13236)	2.5284796776801453
  (0, 13573)	2.03853163893571
  (0, 13630)	1.7178555995344762
  (1, 6773)	4.6162200221746765
  (1, 7352)	2.48534630686257
  (1, 7394)	10.029057429652251
  (1, 8228)	3.3602874789180293
  (1, 8236)	11.429664621685571
  (1, 8707)	2.7241125791123393
  (1, 9657)	22.280113863795975
  :	:
  (17991, 6619)	5.00515582833163
  (17991, 6688)	2.5465482720906456
  (17991, 6690)	4.132423070796605
  (17991, 8122)	2.991346301610737
  (17991, 8579)	0.5254001830155217
  (17991, 9087)	5.452468046375295
  (17991, 9104)	3.2299256610547857
  (17991, 10380)	2.6292767444269107
  (17991, 10738)	0.09818243264420962
  (17991, 11118)	2.473542891137685
  (17991, 12137)	2.8079312509954106
  (17991, 12172)	4.065283689759292
  (17991, 12422)	4.74658184003792
  (17991, 12449)	6.0249872391466255
  (17991, 12450)	5.798847182840153
  (17991, 12762)	4.203374806768889
  (17991, 13101)	2.2203469947570738
  (17991, 13183)	4.231390464459422
  (17991, 13186)	2.330442047497012
  (17991, 13283)	1.2562305119428314
  (17991, 14115)	2.001260244138478
  (17991, 14362)	23.189205994155152
  (17991, 14446)	2.588071774882391
  (17991, 15151)	2.9569343040130085
  (17991, 15162)	2.6687238299637284
(17992, 17992)
(17992, 17992)
17992
Tensor("graphconvolution_2/SparseTensorDenseMatMul/SparseTensorDenseMatMul:0", shape=(None, 52), dtype=float32)
Epoch: 0001 train_loss= 3.95130 train_acc= 0.01599 val_loss= 3.93485 val_acc= 0.67228 time= 0.45400
Epoch: 0002 train_loss= 3.93504 train_acc= 0.62715 val_loss= 3.90420 val_acc= 0.67381 time= 0.17643
Epoch: 0003 train_loss= 3.90619 train_acc= 0.62000 val_loss= 3.86122 val_acc= 0.67075 time= 0.17000
Epoch: 0004 train_loss= 3.86228 train_acc= 0.63633 val_loss= 3.80533 val_acc= 0.66922 time= 0.19703
Epoch: 0005 train_loss= 3.80092 train_acc= 0.62477 val_loss= 3.73581 val_acc= 0.66156 time= 0.16797
Epoch: 0006 train_loss= 3.73528 train_acc= 0.62749 val_loss= 3.65227 val_acc= 0.65391 time= 0.16952
Epoch: 0007 train_loss= 3.64620 train_acc= 0.61847 val_loss= 3.55502 val_acc= 0.64165 time= 0.16500
Epoch: 0008 train_loss= 3.55485 train_acc= 0.61575 val_loss= 3.44533 val_acc= 0.62634 time= 0.16705
Epoch: 0009 train_loss= 3.42830 train_acc= 0.59857 val_loss= 3.32475 val_acc= 0.61715 time= 0.19301
Epoch: 0010 train_loss= 3.33618 train_acc= 0.60095 val_loss= 3.19623 val_acc= 0.60949 time= 0.17100
Epoch: 0011 train_loss= 3.20062 train_acc= 0.60452 val_loss= 3.06364 val_acc= 0.60337 time= 0.18391
Epoch: 0012 train_loss= 3.07936 train_acc= 0.57238 val_loss= 2.93132 val_acc= 0.59265 time= 0.16903
Epoch: 0013 train_loss= 2.91933 train_acc= 0.59245 val_loss= 2.80330 val_acc= 0.58499 time= 0.16800
Epoch: 0014 train_loss= 2.78855 train_acc= 0.56659 val_loss= 2.68354 val_acc= 0.57580 time= 0.17000
Epoch: 0015 train_loss= 2.71407 train_acc= 0.55639 val_loss= 2.57710 val_acc= 0.56508 time= 0.18900
Epoch: 0016 train_loss= 2.53953 train_acc= 0.57493 val_loss= 2.48743 val_acc= 0.56049 time= 0.16700
Epoch: 0017 train_loss= 2.50569 train_acc= 0.52237 val_loss= 2.41631 val_acc= 0.56815 time= 0.18300
Epoch: 0018 train_loss= 2.41193 train_acc= 0.54176 val_loss= 2.36150 val_acc= 0.58959 time= 0.16700
Epoch: 0019 train_loss= 2.35032 train_acc= 0.57272 val_loss= 2.31824 val_acc= 0.62787 time= 0.17061
Epoch: 0020 train_loss= 2.31742 train_acc= 0.59092 val_loss= 2.28157 val_acc= 0.67075 time= 0.17200
Epoch: 0021 train_loss= 2.30699 train_acc= 0.56965 val_loss= 2.24795 val_acc= 0.52680 time= 0.19323
Epoch: 0022 train_loss= 2.26505 train_acc= 0.52747 val_loss= 2.21466 val_acc= 0.46248 time= 0.16700
Epoch: 0023 train_loss= 2.23861 train_acc= 0.46351 val_loss= 2.17981 val_acc= 0.45636 time= 0.18505
Epoch: 0024 train_loss= 2.21870 train_acc= 0.45008 val_loss= 2.14269 val_acc= 0.45636 time= 0.16597
Epoch: 0025 train_loss= 2.18467 train_acc= 0.43579 val_loss= 2.10266 val_acc= 0.45636 time= 0.16504
Epoch: 0026 train_loss= 2.10686 train_acc= 0.43494 val_loss= 2.05948 val_acc= 0.45636 time= 0.19199
Epoch: 0027 train_loss= 2.08877 train_acc= 0.43460 val_loss= 2.01410 val_acc= 0.45636 time= 0.16797
Epoch: 0028 train_loss= 2.05104 train_acc= 0.43664 val_loss= 1.96775 val_acc= 0.45636 time= 0.17300
Epoch: 0029 train_loss= 1.96781 train_acc= 0.43766 val_loss= 1.92147 val_acc= 0.45636 time= 0.17700
Epoch: 0030 train_loss= 1.95362 train_acc= 0.44055 val_loss= 1.87661 val_acc= 0.46401 time= 0.17073
Epoch: 0031 train_loss= 1.87825 train_acc= 0.45076 val_loss= 1.83444 val_acc= 0.48392 time= 0.16803
Epoch: 0032 train_loss= 1.86767 train_acc= 0.46879 val_loss= 1.79516 val_acc= 0.51302 time= 0.19301
Epoch: 0033 train_loss= 1.86352 train_acc= 0.50502 val_loss= 1.75823 val_acc= 0.57580 time= 0.16699
Epoch: 0034 train_loss= 1.78569 train_acc= 0.58632 val_loss= 1.72290 val_acc= 0.62481 time= 0.18501
Epoch: 0035 train_loss= 1.82000 train_acc= 0.59857 val_loss= 1.68810 val_acc= 0.65237 time= 0.16800
Epoch: 0036 train_loss= 1.71722 train_acc= 0.61898 val_loss= 1.65384 val_acc= 0.66769 time= 0.16997
Epoch: 0037 train_loss= 1.69456 train_acc= 0.62153 val_loss= 1.61994 val_acc= 0.67534 time= 0.19573
Epoch: 0038 train_loss= 1.66151 train_acc= 0.64195 val_loss= 1.58635 val_acc= 0.67534 time= 0.17100
Epoch: 0039 train_loss= 1.63576 train_acc= 0.64195 val_loss= 1.55337 val_acc= 0.67534 time= 0.16810
Epoch: 0040 train_loss= 1.58236 train_acc= 0.64059 val_loss= 1.52154 val_acc= 0.67688 time= 0.16700
Epoch: 0041 train_loss= 1.54630 train_acc= 0.64943 val_loss= 1.49098 val_acc= 0.68300 time= 0.16600
Epoch: 0042 train_loss= 1.51214 train_acc= 0.64518 val_loss= 1.46178 val_acc= 0.68606 time= 0.16696
Epoch: 0043 train_loss= 1.50091 train_acc= 0.65079 val_loss= 1.43387 val_acc= 0.68913 time= 0.19304
Epoch: 0044 train_loss= 1.49141 train_acc= 0.65913 val_loss= 1.40708 val_acc= 0.68913 time= 0.16700
Epoch: 0045 train_loss= 1.45941 train_acc= 0.66491 val_loss= 1.38148 val_acc= 0.69678 time= 0.16896
Epoch: 0046 train_loss= 1.41497 train_acc= 0.67767 val_loss= 1.35713 val_acc= 0.70291 time= 0.18800
Epoch: 0047 train_loss= 1.39593 train_acc= 0.68141 val_loss= 1.33386 val_acc= 0.70444 time= 0.16900
Epoch: 0048 train_loss= 1.36278 train_acc= 0.67750 val_loss= 1.31156 val_acc= 0.70597 time= 0.16803
Epoch: 0049 train_loss= 1.35587 train_acc= 0.69570 val_loss= 1.28996 val_acc= 0.71516 time= 0.18997
Epoch: 0050 train_loss= 1.32841 train_acc= 0.69298 val_loss= 1.26922 val_acc= 0.71975 time= 0.16824
Epoch: 0051 train_loss= 1.30336 train_acc= 0.70862 val_loss= 1.24911 val_acc= 0.72435 time= 0.18101
Epoch: 0052 train_loss= 1.28586 train_acc= 0.71050 val_loss= 1.22963 val_acc= 0.72894 time= 0.16600
Epoch: 0053 train_loss= 1.27863 train_acc= 0.71679 val_loss= 1.21083 val_acc= 0.73201 time= 0.16900
Epoch: 0054 train_loss= 1.25750 train_acc= 0.71968 val_loss= 1.19266 val_acc= 0.73660 time= 0.17200
Epoch: 0055 train_loss= 1.25288 train_acc= 0.72393 val_loss= 1.17496 val_acc= 0.73813 time= 0.19300
Epoch: 0056 train_loss= 1.21640 train_acc= 0.72955 val_loss= 1.15772 val_acc= 0.74119 time= 0.16901
Epoch: 0057 train_loss= 1.18993 train_acc= 0.73244 val_loss= 1.14095 val_acc= 0.74273 time= 0.18099
Epoch: 0058 train_loss= 1.16692 train_acc= 0.73397 val_loss= 1.12469 val_acc= 0.74732 time= 0.16813
Epoch: 0059 train_loss= 1.16129 train_acc= 0.74519 val_loss= 1.10882 val_acc= 0.74885 time= 0.16701
Epoch: 0060 train_loss= 1.15199 train_acc= 0.74639 val_loss= 1.09325 val_acc= 0.75345 time= 0.17200
Epoch: 0061 train_loss= 1.13371 train_acc= 0.74826 val_loss= 1.07794 val_acc= 0.75651 time= 0.18800
Epoch: 0062 train_loss= 1.11381 train_acc= 0.75081 val_loss= 1.06290 val_acc= 0.76110 time= 0.17200
Epoch: 0063 train_loss= 1.10445 train_acc= 0.75404 val_loss= 1.04809 val_acc= 0.76723 time= 0.18800
Epoch: 0064 train_loss= 1.08196 train_acc= 0.75370 val_loss= 1.03363 val_acc= 0.77182 time= 0.17000
Epoch: 0065 train_loss= 1.06408 train_acc= 0.76663 val_loss= 1.01953 val_acc= 0.77642 time= 0.16800
Epoch: 0066 train_loss= 1.06667 train_acc= 0.76186 val_loss= 1.00563 val_acc= 0.77948 time= 0.18000
Epoch: 0067 train_loss= 1.03179 train_acc= 0.77088 val_loss= 0.99191 val_acc= 0.77948 time= 0.16606
Epoch: 0068 train_loss= 1.02804 train_acc= 0.77768 val_loss= 0.97841 val_acc= 0.78560 time= 0.17001
Epoch: 0069 train_loss= 1.02366 train_acc= 0.78177 val_loss= 0.96507 val_acc= 0.78560 time= 0.18096
Epoch: 0070 train_loss= 1.01050 train_acc= 0.76833 val_loss= 0.95167 val_acc= 0.79173 time= 0.17100
Epoch: 0071 train_loss= 0.98891 train_acc= 0.78721 val_loss= 0.93831 val_acc= 0.79632 time= 0.17002
Epoch: 0072 train_loss= 0.98015 train_acc= 0.78585 val_loss= 0.92527 val_acc= 0.80092 time= 0.19600
Epoch: 0073 train_loss= 0.96170 train_acc= 0.79265 val_loss= 0.91224 val_acc= 0.80858 time= 0.16900
Epoch: 0074 train_loss= 0.94672 train_acc= 0.79537 val_loss= 0.89958 val_acc= 0.81470 time= 0.18300
Epoch: 0075 train_loss= 0.94948 train_acc= 0.79384 val_loss= 0.88723 val_acc= 0.81776 time= 0.16800
Epoch: 0076 train_loss= 0.94539 train_acc= 0.79639 val_loss= 0.87520 val_acc= 0.82236 time= 0.16604
Epoch: 0077 train_loss= 0.91489 train_acc= 0.80048 val_loss= 0.86354 val_acc= 0.82389 time= 0.16899
Epoch: 0078 train_loss= 0.90111 train_acc= 0.80422 val_loss= 0.85196 val_acc= 0.82389 time= 0.18997
Epoch: 0079 train_loss= 0.88977 train_acc= 0.80303 val_loss= 0.84038 val_acc= 0.82389 time= 0.17109
Epoch: 0080 train_loss= 0.86767 train_acc= 0.81017 val_loss= 0.82893 val_acc= 0.82695 time= 0.16987
Epoch: 0081 train_loss= 0.87245 train_acc= 0.80337 val_loss= 0.81742 val_acc= 0.82542 time= 0.17004
Epoch: 0082 train_loss= 0.85552 train_acc= 0.81766 val_loss= 0.80588 val_acc= 0.82542 time= 0.16799
Epoch: 0083 train_loss= 0.84169 train_acc= 0.81510 val_loss= 0.79429 val_acc= 0.82695 time= 0.19100
Epoch: 0084 train_loss= 0.81903 train_acc= 0.81987 val_loss= 0.78289 val_acc= 0.83002 time= 0.16697
Epoch: 0085 train_loss= 0.82765 train_acc= 0.81476 val_loss= 0.77163 val_acc= 0.83002 time= 0.16900
Epoch: 0086 train_loss= 0.80712 train_acc= 0.81715 val_loss= 0.76077 val_acc= 0.83308 time= 0.18500
Epoch: 0087 train_loss= 0.79546 train_acc= 0.82718 val_loss= 0.75009 val_acc= 0.83308 time= 0.16700
Epoch: 0088 train_loss= 0.79545 train_acc= 0.81953 val_loss= 0.74000 val_acc= 0.83461 time= 0.17100
Epoch: 0089 train_loss= 0.79041 train_acc= 0.82259 val_loss= 0.73016 val_acc= 0.83614 time= 0.19500
Epoch: 0090 train_loss= 0.76733 train_acc= 0.82344 val_loss= 0.72043 val_acc= 0.83920 time= 0.16903
Epoch: 0091 train_loss= 0.74861 train_acc= 0.83092 val_loss= 0.71081 val_acc= 0.83920 time= 0.17597
Epoch: 0092 train_loss= 0.75763 train_acc= 0.83160 val_loss= 0.70144 val_acc= 0.84074 time= 0.16604
Epoch: 0093 train_loss= 0.73197 train_acc= 0.83671 val_loss= 0.69217 val_acc= 0.84380 time= 0.16800
Epoch: 0094 train_loss= 0.72621 train_acc= 0.82769 val_loss= 0.68325 val_acc= 0.84380 time= 0.16996
Epoch: 0095 train_loss= 0.71891 train_acc= 0.84028 val_loss= 0.67457 val_acc= 0.84533 time= 0.18913
Epoch: 0096 train_loss= 0.70472 train_acc= 0.83450 val_loss= 0.66620 val_acc= 0.84686 time= 0.17100
Epoch: 0097 train_loss= 0.70934 train_acc= 0.84164 val_loss= 0.65828 val_acc= 0.85758 time= 0.19000
Epoch: 0098 train_loss= 0.70324 train_acc= 0.84249 val_loss= 0.65053 val_acc= 0.85605 time= 0.17203
Epoch: 0099 train_loss= 0.68606 train_acc= 0.84317 val_loss= 0.64296 val_acc= 0.86064 time= 0.16797
Epoch: 0100 train_loss= 0.66902 train_acc= 0.84640 val_loss= 0.63556 val_acc= 0.86064 time= 0.17200
Epoch: 0101 train_loss= 0.66477 train_acc= 0.84725 val_loss= 0.62784 val_acc= 0.86677 time= 0.18718
Epoch: 0102 train_loss= 0.65469 train_acc= 0.85389 val_loss= 0.62016 val_acc= 0.86983 time= 0.16701
Epoch: 0103 train_loss= 0.64599 train_acc= 0.84589 val_loss= 0.61242 val_acc= 0.86677 time= 0.17799
Epoch: 0104 train_loss= 0.63191 train_acc= 0.85695 val_loss= 0.60485 val_acc= 0.86677 time= 0.16851
Epoch: 0105 train_loss= 0.64586 train_acc= 0.85304 val_loss= 0.59726 val_acc= 0.86830 time= 0.17000
Epoch: 0106 train_loss= 0.62410 train_acc= 0.85865 val_loss= 0.58954 val_acc= 0.87289 time= 0.19600
Epoch: 0107 train_loss= 0.62038 train_acc= 0.85899 val_loss= 0.58207 val_acc= 0.87749 time= 0.16900
Epoch: 0108 train_loss= 0.61596 train_acc= 0.85950 val_loss= 0.57488 val_acc= 0.88055 time= 0.17003
Epoch: 0109 train_loss= 0.61331 train_acc= 0.85695 val_loss= 0.56793 val_acc= 0.88208 time= 0.17649
Epoch: 0110 train_loss= 0.60441 train_acc= 0.85763 val_loss= 0.56105 val_acc= 0.88361 time= 0.16883
Epoch: 0111 train_loss= 0.58584 train_acc= 0.86307 val_loss= 0.55424 val_acc= 0.88668 time= 0.16600
Epoch: 0112 train_loss= 0.56517 train_acc= 0.87005 val_loss= 0.54743 val_acc= 0.88515 time= 0.18907
Epoch: 0113 train_loss= 0.59213 train_acc= 0.86307 val_loss= 0.54111 val_acc= 0.88821 time= 0.17083
Epoch: 0114 train_loss= 0.58518 train_acc= 0.86443 val_loss= 0.53532 val_acc= 0.88821 time= 0.18603
Epoch: 0115 train_loss= 0.56544 train_acc= 0.87073 val_loss= 0.53012 val_acc= 0.88821 time= 0.16900
Epoch: 0116 train_loss= 0.57257 train_acc= 0.87039 val_loss= 0.52492 val_acc= 0.88821 time= 0.16700
Epoch: 0117 train_loss= 0.55914 train_acc= 0.87124 val_loss= 0.51993 val_acc= 0.88821 time= 0.17200
Epoch: 0118 train_loss= 0.55394 train_acc= 0.87515 val_loss= 0.51468 val_acc= 0.88821 time= 0.18900
Epoch: 0119 train_loss= 0.53754 train_acc= 0.87124 val_loss= 0.50929 val_acc= 0.88974 time= 0.16700
Epoch: 0120 train_loss= 0.54468 train_acc= 0.87736 val_loss= 0.50441 val_acc= 0.89127 time= 0.16799
Epoch: 0121 train_loss= 0.52635 train_acc= 0.88042 val_loss= 0.49925 val_acc= 0.89127 time= 0.17100
Epoch: 0122 train_loss= 0.54177 train_acc= 0.87702 val_loss= 0.49397 val_acc= 0.89127 time= 0.17301
Epoch: 0123 train_loss= 0.52963 train_acc= 0.87838 val_loss= 0.48852 val_acc= 0.89127 time= 0.17600
Epoch: 0124 train_loss= 0.52619 train_acc= 0.87583 val_loss= 0.48310 val_acc= 0.88974 time= 0.16801
Epoch: 0125 train_loss= 0.51558 train_acc= 0.88314 val_loss= 0.47808 val_acc= 0.88974 time= 0.16800
Epoch: 0126 train_loss= 0.52135 train_acc= 0.88144 val_loss= 0.47327 val_acc= 0.88974 time= 0.18000
Epoch: 0127 train_loss= 0.49837 train_acc= 0.88910 val_loss= 0.46828 val_acc= 0.89127 time= 0.16800
Epoch: 0128 train_loss= 0.50498 train_acc= 0.88655 val_loss= 0.46338 val_acc= 0.89433 time= 0.16699
Epoch: 0129 train_loss= 0.48370 train_acc= 0.88655 val_loss= 0.45824 val_acc= 0.89433 time= 0.17600
Epoch: 0130 train_loss= 0.48364 train_acc= 0.88672 val_loss= 0.45349 val_acc= 0.89587 time= 0.17033
Epoch: 0131 train_loss= 0.47835 train_acc= 0.88655 val_loss= 0.44909 val_acc= 0.89587 time= 0.17000
Epoch: 0132 train_loss= 0.49219 train_acc= 0.89114 val_loss= 0.44510 val_acc= 0.89587 time= 0.18997
Epoch: 0133 train_loss= 0.46523 train_acc= 0.89930 val_loss= 0.44155 val_acc= 0.89587 time= 0.16900
Epoch: 0134 train_loss= 0.47154 train_acc= 0.88740 val_loss= 0.43814 val_acc= 0.89587 time= 0.16699
Epoch: 0135 train_loss= 0.46571 train_acc= 0.89284 val_loss= 0.43499 val_acc= 0.89587 time= 0.19361
Epoch: 0136 train_loss= 0.46626 train_acc= 0.88638 val_loss= 0.43200 val_acc= 0.89587 time= 0.16904
Epoch: 0137 train_loss= 0.45652 train_acc= 0.89284 val_loss= 0.42864 val_acc= 0.89893 time= 0.18100
Epoch: 0138 train_loss= 0.45039 train_acc= 0.89420 val_loss= 0.42536 val_acc= 0.90199 time= 0.16896
Epoch: 0139 train_loss= 0.46000 train_acc= 0.89539 val_loss= 0.42180 val_acc= 0.90352 time= 0.17000
Epoch: 0140 train_loss= 0.45677 train_acc= 0.89063 val_loss= 0.41832 val_acc= 0.90352 time= 0.17433
Epoch: 0141 train_loss= 0.44808 train_acc= 0.89539 val_loss= 0.41557 val_acc= 0.90199 time= 0.18989
Epoch: 0142 train_loss= 0.42591 train_acc= 0.90321 val_loss= 0.41289 val_acc= 0.90352 time= 0.16800
Epoch: 0143 train_loss= 0.44183 train_acc= 0.90321 val_loss= 0.41032 val_acc= 0.90352 time= 0.17208
Epoch: 0144 train_loss= 0.42601 train_acc= 0.90032 val_loss= 0.40774 val_acc= 0.90352 time= 0.16800
Epoch: 0145 train_loss= 0.42805 train_acc= 0.89420 val_loss= 0.40414 val_acc= 0.90199 time= 0.16700
Epoch: 0146 train_loss= 0.42750 train_acc= 0.90253 val_loss= 0.40084 val_acc= 0.90199 time= 0.19261
Epoch: 0147 train_loss= 0.42159 train_acc= 0.89828 val_loss= 0.39746 val_acc= 0.90046 time= 0.17203
Epoch: 0148 train_loss= 0.42758 train_acc= 0.89743 val_loss= 0.39384 val_acc= 0.90046 time= 0.17100
Epoch: 0149 train_loss= 0.42515 train_acc= 0.89811 val_loss= 0.38975 val_acc= 0.90046 time= 0.18640
Epoch: 0150 train_loss= 0.39290 train_acc= 0.91087 val_loss= 0.38589 val_acc= 0.90352 time= 0.16900
Epoch: 0151 train_loss= 0.40465 train_acc= 0.90373 val_loss= 0.38253 val_acc= 0.90352 time= 0.16800
Epoch: 0152 train_loss= 0.41369 train_acc= 0.90151 val_loss= 0.37967 val_acc= 0.90505 time= 0.19200
Epoch: 0153 train_loss= 0.41206 train_acc= 0.90696 val_loss= 0.37776 val_acc= 0.90352 time= 0.16700
Epoch: 0154 train_loss= 0.41060 train_acc= 0.90424 val_loss= 0.37571 val_acc= 0.90505 time= 0.17157
Epoch: 0155 train_loss= 0.40281 train_acc= 0.91257 val_loss= 0.37373 val_acc= 0.90352 time= 0.17200
Epoch: 0156 train_loss= 0.40334 train_acc= 0.90441 val_loss= 0.37146 val_acc= 0.90199 time= 0.17100
Epoch: 0157 train_loss= 0.40411 train_acc= 0.90270 val_loss= 0.36904 val_acc= 0.90199 time= 0.16900
Epoch: 0158 train_loss= 0.39216 train_acc= 0.90526 val_loss= 0.36689 val_acc= 0.90505 time= 0.19404
Epoch: 0159 train_loss= 0.36857 train_acc= 0.91886 val_loss= 0.36499 val_acc= 0.90505 time= 0.16696
Epoch: 0160 train_loss= 0.39487 train_acc= 0.90253 val_loss= 0.36285 val_acc= 0.90505 time= 0.18204
Epoch: 0161 train_loss= 0.36531 train_acc= 0.91614 val_loss= 0.36141 val_acc= 0.90199 time= 0.16799
Epoch: 0162 train_loss= 0.37113 train_acc= 0.91359 val_loss= 0.36009 val_acc= 0.90352 time= 0.16701
Epoch: 0163 train_loss= 0.38349 train_acc= 0.90662 val_loss= 0.35868 val_acc= 0.90199 time= 0.17322
Epoch: 0164 train_loss= 0.36394 train_acc= 0.91580 val_loss= 0.35671 val_acc= 0.90199 time= 0.19301
Epoch: 0165 train_loss= 0.36317 train_acc= 0.91631 val_loss= 0.35492 val_acc= 0.90199 time= 0.17200
Epoch: 0166 train_loss= 0.36206 train_acc= 0.91869 val_loss= 0.35270 val_acc= 0.90199 time= 0.17404
Epoch: 0167 train_loss= 0.36359 train_acc= 0.91478 val_loss= 0.35050 val_acc= 0.90505 time= 0.16701
Epoch: 0168 train_loss= 0.35528 train_acc= 0.91716 val_loss= 0.34858 val_acc= 0.90505 time= 0.16800
Epoch: 0169 train_loss= 0.35443 train_acc= 0.91614 val_loss= 0.34631 val_acc= 0.90812 time= 0.19098
Epoch: 0170 train_loss= 0.35666 train_acc= 0.91869 val_loss= 0.34321 val_acc= 0.90965 time= 0.16697
Epoch: 0171 train_loss= 0.35657 train_acc= 0.91937 val_loss= 0.33997 val_acc= 0.91118 time= 0.16700
Epoch: 0172 train_loss= 0.36605 train_acc= 0.91121 val_loss= 0.33687 val_acc= 0.91271 time= 0.19100
Epoch: 0173 train_loss= 0.35261 train_acc= 0.91376 val_loss= 0.33428 val_acc= 0.91118 time= 0.17100
Epoch: 0174 train_loss= 0.34693 train_acc= 0.92005 val_loss= 0.33260 val_acc= 0.91271 time= 0.17000
Epoch: 0175 train_loss= 0.35212 train_acc= 0.91427 val_loss= 0.33141 val_acc= 0.91271 time= 0.19200
Epoch: 0176 train_loss= 0.34687 train_acc= 0.91886 val_loss= 0.33034 val_acc= 0.91271 time= 0.16906
Epoch: 0177 train_loss= 0.34811 train_acc= 0.91716 val_loss= 0.32939 val_acc= 0.91118 time= 0.18000
Epoch: 0178 train_loss= 0.33524 train_acc= 0.91393 val_loss= 0.32833 val_acc= 0.91271 time= 0.16899
Epoch: 0179 train_loss= 0.32589 train_acc= 0.92448 val_loss= 0.32704 val_acc= 0.90965 time= 0.16696
Epoch: 0180 train_loss= 0.33240 train_acc= 0.91869 val_loss= 0.32641 val_acc= 0.91271 time= 0.19100
Epoch: 0181 train_loss= 0.32186 train_acc= 0.92346 val_loss= 0.32555 val_acc= 0.91271 time= 0.17000
Epoch: 0182 train_loss= 0.32664 train_acc= 0.92516 val_loss= 0.32438 val_acc= 0.91424 time= 0.17100
Epoch: 0183 train_loss= 0.32106 train_acc= 0.92431 val_loss= 0.32310 val_acc= 0.91424 time= 0.17204
Epoch: 0184 train_loss= 0.31383 train_acc= 0.92499 val_loss= 0.32143 val_acc= 0.91424 time= 0.17000
Epoch: 0185 train_loss= 0.31709 train_acc= 0.92822 val_loss= 0.31968 val_acc= 0.91424 time= 0.16805
Epoch: 0186 train_loss= 0.31847 train_acc= 0.92448 val_loss= 0.31838 val_acc= 0.91424 time= 0.17100
Epoch: 0187 train_loss= 0.31407 train_acc= 0.92329 val_loss= 0.31700 val_acc= 0.91424 time= 0.18900
Epoch: 0188 train_loss= 0.32185 train_acc= 0.92635 val_loss= 0.31566 val_acc= 0.91577 time= 0.16705
Epoch: 0189 train_loss= 0.30800 train_acc= 0.92533 val_loss= 0.31476 val_acc= 0.91577 time= 0.18619
Epoch: 0190 train_loss= 0.32115 train_acc= 0.92482 val_loss= 0.31407 val_acc= 0.91424 time= 0.16988
Epoch: 0191 train_loss= 0.30395 train_acc= 0.92652 val_loss= 0.31297 val_acc= 0.91577 time= 0.16800
Epoch: 0192 train_loss= 0.30814 train_acc= 0.92397 val_loss= 0.31139 val_acc= 0.91577 time= 0.19200
Epoch: 0193 train_loss= 0.31237 train_acc= 0.92227 val_loss= 0.30942 val_acc= 0.91577 time= 0.16902
Epoch: 0194 train_loss= 0.28815 train_acc= 0.93026 val_loss= 0.30686 val_acc= 0.91424 time= 0.16903
Epoch: 0195 train_loss= 0.29622 train_acc= 0.93077 val_loss= 0.30462 val_acc= 0.91577 time= 0.16897
Epoch: 0196 train_loss= 0.30278 train_acc= 0.92567 val_loss= 0.30245 val_acc= 0.91577 time= 0.16600
Epoch: 0197 train_loss= 0.29284 train_acc= 0.92890 val_loss= 0.30012 val_acc= 0.91577 time= 0.17000
Epoch: 0198 train_loss= 0.30373 train_acc= 0.92533 val_loss= 0.29780 val_acc= 0.91577 time= 0.19620
Epoch: 0199 train_loss= 0.29745 train_acc= 0.92244 val_loss= 0.29622 val_acc= 0.91730 time= 0.16980
Epoch: 0200 train_loss= 0.29762 train_acc= 0.92686 val_loss= 0.29479 val_acc= 0.91884 time= 0.18580
Epoch: 0201 train_loss= 0.29056 train_acc= 0.93196 val_loss= 0.29396 val_acc= 0.91884 time= 0.16601
Epoch: 0202 train_loss= 0.29765 train_acc= 0.92448 val_loss= 0.29332 val_acc= 0.91884 time= 0.16800
Epoch: 0203 train_loss= 0.28451 train_acc= 0.93145 val_loss= 0.29247 val_acc= 0.92037 time= 0.17098
Epoch: 0204 train_loss= 0.28056 train_acc= 0.93128 val_loss= 0.29143 val_acc= 0.92037 time= 0.18901
Epoch: 0205 train_loss= 0.28901 train_acc= 0.93043 val_loss= 0.29072 val_acc= 0.92037 time= 0.16705
Epoch: 0206 train_loss= 0.27646 train_acc= 0.93434 val_loss= 0.29061 val_acc= 0.92037 time= 0.17100
Epoch: 0207 train_loss= 0.28409 train_acc= 0.93281 val_loss= 0.29025 val_acc= 0.92037 time= 0.17143
Epoch: 0208 train_loss= 0.28355 train_acc= 0.93417 val_loss= 0.28953 val_acc= 0.92190 time= 0.17000
Epoch: 0209 train_loss= 0.28056 train_acc= 0.92958 val_loss= 0.28831 val_acc= 0.92343 time= 0.18903
Epoch: 0210 train_loss= 0.27305 train_acc= 0.93740 val_loss= 0.28692 val_acc= 0.92343 time= 0.16597
Epoch: 0211 train_loss= 0.27789 train_acc= 0.93468 val_loss= 0.28595 val_acc= 0.92343 time= 0.16903
Epoch: 0212 train_loss= 0.27378 train_acc= 0.92856 val_loss= 0.28434 val_acc= 0.92037 time= 0.18797
Epoch: 0213 train_loss= 0.26527 train_acc= 0.93519 val_loss= 0.28239 val_acc= 0.92343 time= 0.16800
Epoch: 0214 train_loss= 0.26957 train_acc= 0.92941 val_loss= 0.28103 val_acc= 0.92190 time= 0.17100
Epoch: 0215 train_loss= 0.27184 train_acc= 0.93349 val_loss= 0.28072 val_acc= 0.92190 time= 0.19600
Epoch: 0216 train_loss= 0.26305 train_acc= 0.93570 val_loss= 0.28024 val_acc= 0.92190 time= 0.17100
Epoch: 0217 train_loss= 0.25237 train_acc= 0.94013 val_loss= 0.28037 val_acc= 0.92190 time= 0.18700
Epoch: 0218 train_loss= 0.27147 train_acc= 0.93247 val_loss= 0.28013 val_acc= 0.91884 time= 0.16703
Epoch: 0219 train_loss= 0.25744 train_acc= 0.93400 val_loss= 0.27968 val_acc= 0.92037 time= 0.16997
Epoch: 0220 train_loss= 0.24577 train_acc= 0.94098 val_loss= 0.27967 val_acc= 0.92037 time= 0.17103
Epoch: 0221 train_loss= 0.26269 train_acc= 0.93502 val_loss= 0.27932 val_acc= 0.92037 time= 0.17400
Epoch: 0222 train_loss= 0.26896 train_acc= 0.93213 val_loss= 0.27885 val_acc= 0.92190 time= 0.16801
Epoch: 0223 train_loss= 0.24501 train_acc= 0.94166 val_loss= 0.27833 val_acc= 0.92343 time= 0.18596
Epoch: 0224 train_loss= 0.24150 train_acc= 0.94047 val_loss= 0.27777 val_acc= 0.92496 time= 0.17000
Epoch: 0225 train_loss= 0.24330 train_acc= 0.93638 val_loss= 0.27742 val_acc= 0.92496 time= 0.16900
Epoch: 0226 train_loss= 0.25233 train_acc= 0.93672 val_loss= 0.27683 val_acc= 0.92343 time= 0.17103
Epoch: 0227 train_loss= 0.25342 train_acc= 0.93877 val_loss= 0.27580 val_acc= 0.92190 time= 0.18800
Epoch: 0228 train_loss= 0.24180 train_acc= 0.94251 val_loss= 0.27517 val_acc= 0.92190 time= 0.16800
Epoch: 0229 train_loss= 0.26152 train_acc= 0.93621 val_loss= 0.27438 val_acc= 0.92343 time= 0.18500
Epoch: 0230 train_loss= 0.23347 train_acc= 0.94115 val_loss= 0.27349 val_acc= 0.92649 time= 0.16800
Epoch: 0231 train_loss= 0.24868 train_acc= 0.93740 val_loss= 0.27308 val_acc= 0.92496 time= 0.16897
Epoch: 0232 train_loss= 0.24426 train_acc= 0.94064 val_loss= 0.27224 val_acc= 0.92496 time= 0.19600
Epoch: 0233 train_loss= 0.24008 train_acc= 0.93536 val_loss= 0.27136 val_acc= 0.92496 time= 0.17000
Epoch: 0234 train_loss= 0.23345 train_acc= 0.94387 val_loss= 0.27058 val_acc= 0.92496 time= 0.17167
Epoch: 0235 train_loss= 0.23990 train_acc= 0.94336 val_loss= 0.27003 val_acc= 0.92343 time= 0.16803
Epoch: 0236 train_loss= 0.21880 train_acc= 0.95033 val_loss= 0.26957 val_acc= 0.92343 time= 0.16597
Epoch: 0237 train_loss= 0.23523 train_acc= 0.94404 val_loss= 0.26904 val_acc= 0.92343 time= 0.16700
Epoch: 0238 train_loss= 0.22806 train_acc= 0.94421 val_loss= 0.26792 val_acc= 0.92190 time= 0.19311
Epoch: 0239 train_loss= 0.23092 train_acc= 0.93791 val_loss= 0.26625 val_acc= 0.92343 time= 0.16617
Epoch: 0240 train_loss= 0.22561 train_acc= 0.93808 val_loss= 0.26450 val_acc= 0.92496 time= 0.19296
Epoch: 0241 train_loss= 0.23679 train_acc= 0.94149 val_loss= 0.26281 val_acc= 0.92649 time= 0.17000
Epoch: 0242 train_loss= 0.21145 train_acc= 0.94761 val_loss= 0.26159 val_acc= 0.92802 time= 0.17100
Epoch: 0243 train_loss= 0.22911 train_acc= 0.94710 val_loss= 0.26093 val_acc= 0.92802 time= 0.17100
Epoch: 0244 train_loss= 0.22480 train_acc= 0.94472 val_loss= 0.26057 val_acc= 0.92649 time= 0.18800
Epoch: 0245 train_loss= 0.21722 train_acc= 0.95271 val_loss= 0.26044 val_acc= 0.92649 time= 0.16706
Epoch: 0246 train_loss= 0.22548 train_acc= 0.94693 val_loss= 0.26054 val_acc= 0.92496 time= 0.16799
Epoch: 0247 train_loss= 0.22712 train_acc= 0.94863 val_loss= 0.26038 val_acc= 0.92496 time= 0.16800
Epoch: 0248 train_loss= 0.21305 train_acc= 0.94540 val_loss= 0.25977 val_acc= 0.92802 time= 0.16601
Epoch: 0249 train_loss= 0.21837 train_acc= 0.94523 val_loss= 0.25899 val_acc= 0.92649 time= 0.19804
Epoch: 0250 train_loss= 0.21482 train_acc= 0.94829 val_loss= 0.25817 val_acc= 0.92649 time= 0.16900
Epoch: 0251 train_loss= 0.21624 train_acc= 0.94455 val_loss= 0.25754 val_acc= 0.92649 time= 0.17000
Epoch: 0252 train_loss= 0.21651 train_acc= 0.95186 val_loss= 0.25688 val_acc= 0.92802 time= 0.18900
Epoch: 0253 train_loss= 0.21900 train_acc= 0.94353 val_loss= 0.25629 val_acc= 0.92802 time= 0.16913
Epoch: 0254 train_loss= 0.20999 train_acc= 0.95067 val_loss= 0.25604 val_acc= 0.92802 time= 0.16808
Epoch: 0255 train_loss= 0.21393 train_acc= 0.94710 val_loss= 0.25576 val_acc= 0.92956 time= 0.19200
Epoch: 0256 train_loss= 0.21976 train_acc= 0.94489 val_loss= 0.25539 val_acc= 0.93109 time= 0.16708
Epoch: 0257 train_loss= 0.20078 train_acc= 0.94778 val_loss= 0.25566 val_acc= 0.93109 time= 0.18896
Epoch: 0258 train_loss= 0.21218 train_acc= 0.94693 val_loss= 0.25573 val_acc= 0.92956 time= 0.17037
Epoch: 0259 train_loss= 0.20769 train_acc= 0.94897 val_loss= 0.25542 val_acc= 0.92649 time= 0.17000
Epoch: 0260 train_loss= 0.20431 train_acc= 0.95016 val_loss= 0.25539 val_acc= 0.92649 time= 0.17297
Epoch: 0261 train_loss= 0.20002 train_acc= 0.95152 val_loss= 0.25558 val_acc= 0.92802 time= 0.18800
Early stopping...
Optimization Finished!
Test set results: cost= 0.30922 accuracy= 0.92251 time= 0.07400
17992
Test Precision, Recall and F1-Score...
              precision    recall  f1-score   support

           0     1.0000    1.0000    1.0000         8
           1     1.0000    0.3333    0.5000         6
           2     0.0000    0.0000    0.0000         1
           3     0.6789    0.9867    0.8043        75
           4     1.0000    1.0000    1.0000         9
           5     0.8125    0.8966    0.8525        87
           6     0.9200    0.9200    0.9200        25
           7     0.6875    0.8462    0.7586        13
           8     0.9091    0.9091    0.9091        11
           9     0.0000    0.0000    0.0000         9
          10     0.8846    0.6389    0.7419        36
          11     1.0000    0.9167    0.9565        12
          12     0.8511    0.9917    0.9160       121
          13     0.8571    0.6316    0.7273        19
          14     0.7500    0.8571    0.8000        28
          15     0.0000    0.0000    0.0000         4
          16     0.0000    0.0000    0.0000         4
          17     0.0000    0.0000    0.0000         3
          18     1.0000    0.3000    0.4615        10
          19     1.0000    1.0000    1.0000         2
          20     0.0000    0.0000    0.0000         9
          21     0.9048    0.9500    0.9268        20
          22     0.5714    0.8000    0.6667         5
          23     0.0000    0.0000    0.0000         1
          24     0.5417    0.7647    0.6341        17
          25     0.8000    0.8000    0.8000        15
          26     0.0000    0.0000    0.0000         1
          27     1.0000    0.4167    0.5882        12
          28     0.8750    0.6364    0.7368        11
          29     0.9601    0.9670    0.9635       696
          30     0.8800    1.0000    0.9362        22
          31     0.0000    0.0000    0.0000         3
          32     0.6923    0.9000    0.7826        10
          33     1.0000    0.6667    0.8000         3
          34     0.0000    0.0000    0.0000         1
          35     0.8718    0.8395    0.8553        81
          36     1.0000    0.3333    0.5000        12
          37     1.0000    0.5000    0.6667         4
          38     0.0000    0.0000    0.0000         1
          39     0.9729    0.9926    0.9826      1083
          40     1.0000    0.2000    0.3333         5
          41     0.0000    0.0000    0.0000         2
          42     1.0000    0.7778    0.8750         9
          43     0.0000    0.0000    0.0000         3
          44     0.6000    0.7500    0.6667        12
          45     0.0000    0.0000    0.0000         6
          46     1.0000    0.2857    0.4444         7
          47     0.8667    0.8667    0.8667        15
          48     1.0000    0.8889    0.9412         9
          49     0.0000    0.0000    0.0000         1
          50     1.0000    0.2000    0.3333         5
          51     1.0000    0.7500    0.8571         4

    accuracy                         0.9225      2568
   macro avg     0.6324    0.5291    0.5482      2568
weighted avg     0.9125    0.9225    0.9111      2568

Macro average Test Precision, Recall and F1-Score...
(0.6324489649404911, 0.5291089709350992, 0.5481772704471334, None)
Micro average Test Precision, Recall and F1-Score...
(0.9225077881619937, 0.9225077881619937, 0.9225077881619937, None)
embeddings:
8892 6532 2568
[[-0.10239642  0.68722034  0.67550707 ...  0.27102584 -0.22279555
  -0.15303844]
 [ 0.06089268  0.16372775  0.1871118  ...  0.0998029   0.11415729
  -0.00782987]
 [ 0.15920262  0.31118527  0.70255214 ...  0.06277053  0.15343188
   0.20431185]
 ...
 [-0.00788959  0.05837872  0.28077197 ...  0.13598476  0.22351672
  -0.02031799]
 [ 0.07932856  0.18344253  0.30812165 ...  0.08119886  0.10765588
   0.11181474]
 [ 0.28225908  0.16291203  0.13383257 ...  0.23266625  0.19520934
   0.25270188]]
