(5879, 300) (5879, 52) (2568, 300) (2568, 52) (15424, 300) (15424, 52)
17992
  (0, 7394)	6.686038286434835
  (0, 7579)	9.544554181485928
  (0, 8435)	1.1089956803115342
  (0, 9187)	1.4870258028519843
  (0, 9412)	3.4992585948383703
  (0, 9715)	8.687769937101656
  (0, 9722)	2.6831883644039674
  (0, 10649)	2.428921084638427
  (0, 10738)	0.09818243264420962
  (0, 10836)	3.739323224804961
  (0, 11937)	2.330442047497012
  (0, 12542)	3.606641355876964
  (0, 12888)	3.02851632033319
  (0, 13067)	4.35029811356276
  (0, 13073)	2.3388242585209373
  (0, 13236)	2.5284796776801453
  (0, 13573)	2.03853163893571
  (0, 13630)	1.7178555995344762
  (1, 6773)	4.6162200221746765
  (1, 7352)	2.48534630686257
  (1, 7394)	10.029057429652251
  (1, 8228)	3.3602874789180293
  (1, 8236)	11.429664621685571
  (1, 8707)	2.7241125791123393
  (1, 9657)	22.280113863795975
  :	:
  (17991, 6619)	5.00515582833163
  (17991, 6688)	2.5465482720906456
  (17991, 6690)	4.132423070796605
  (17991, 8122)	2.991346301610737
  (17991, 8579)	0.5254001830155217
  (17991, 9087)	5.452468046375295
  (17991, 9104)	3.2299256610547857
  (17991, 10380)	2.6292767444269107
  (17991, 10738)	0.09818243264420962
  (17991, 11118)	2.473542891137685
  (17991, 12137)	2.8079312509954106
  (17991, 12172)	4.065283689759292
  (17991, 12422)	4.74658184003792
  (17991, 12449)	6.0249872391466255
  (17991, 12450)	5.798847182840153
  (17991, 12762)	4.203374806768889
  (17991, 13101)	2.2203469947570738
  (17991, 13183)	4.231390464459422
  (17991, 13186)	2.330442047497012
  (17991, 13283)	1.2562305119428314
  (17991, 14115)	2.001260244138478
  (17991, 14362)	23.189205994155152
  (17991, 14446)	2.588071774882391
  (17991, 15151)	2.9569343040130085
  (17991, 15162)	2.6687238299637284
(17992, 17992)
(17992, 17992)
17992
Tensor("graphconvolution_2/SparseTensorDenseMatMul/SparseTensorDenseMatMul:0", shape=(None, 52), dtype=float32)
Epoch: 0001 train_loss= 3.95122 train_acc= 0.01565 val_loss= 3.92733 val_acc= 0.66769 time= 0.44507
Epoch: 0002 train_loss= 3.92756 train_acc= 0.65742 val_loss= 3.88927 val_acc= 0.65697 time= 0.18301
Epoch: 0003 train_loss= 3.89001 train_acc= 0.65215 val_loss= 3.83637 val_acc= 0.64625 time= 0.17039
Epoch: 0004 train_loss= 3.83741 train_acc= 0.63684 val_loss= 3.76769 val_acc= 0.63093 time= 0.17000
Epoch: 0005 train_loss= 3.76758 train_acc= 0.62545 val_loss= 3.68242 val_acc= 0.59418 time= 0.19700
Epoch: 0006 train_loss= 3.68302 train_acc= 0.59466 val_loss= 3.58033 val_acc= 0.56508 time= 0.16873
Epoch: 0007 train_loss= 3.58209 train_acc= 0.56659 val_loss= 3.46202 val_acc= 0.54671 time= 0.16801
Epoch: 0008 train_loss= 3.45997 train_acc= 0.52730 val_loss= 3.32930 val_acc= 0.51149 time= 0.16600
Epoch: 0009 train_loss= 3.33691 train_acc= 0.50366 val_loss= 3.18550 val_acc= 0.49464 time= 0.16899
Epoch: 0010 train_loss= 3.18936 train_acc= 0.48971 val_loss= 3.03512 val_acc= 0.48545 time= 0.17104
Epoch: 0011 train_loss= 3.04221 train_acc= 0.46505 val_loss= 2.88350 val_acc= 0.47167 time= 0.18697
Epoch: 0012 train_loss= 2.87536 train_acc= 0.45229 val_loss= 2.73574 val_acc= 0.46554 time= 0.17300
Epoch: 0013 train_loss= 2.73684 train_acc= 0.44293 val_loss= 2.59802 val_acc= 0.46248 time= 0.17203
Epoch: 0014 train_loss= 2.60529 train_acc= 0.44055 val_loss= 2.47703 val_acc= 0.46095 time= 0.18400
Epoch: 0015 train_loss= 2.48319 train_acc= 0.44276 val_loss= 2.37783 val_acc= 0.45942 time= 0.16800
Epoch: 0016 train_loss= 2.37240 train_acc= 0.43851 val_loss= 2.30200 val_acc= 0.45942 time= 0.16900
Epoch: 0017 train_loss= 2.30419 train_acc= 0.43698 val_loss= 2.24679 val_acc= 0.45942 time= 0.18701
Epoch: 0018 train_loss= 2.26275 train_acc= 0.43596 val_loss= 2.20613 val_acc= 0.45942 time= 0.16599
Epoch: 0019 train_loss= 2.20510 train_acc= 0.43630 val_loss= 2.17254 val_acc= 0.45789 time= 0.17797
Epoch: 0020 train_loss= 2.19216 train_acc= 0.43409 val_loss= 2.13991 val_acc= 0.45636 time= 0.16900
Epoch: 0021 train_loss= 2.15089 train_acc= 0.43358 val_loss= 2.10358 val_acc= 0.45636 time= 0.17100
Epoch: 0022 train_loss= 2.10365 train_acc= 0.43409 val_loss= 2.06153 val_acc= 0.45942 time= 0.18803
Epoch: 0023 train_loss= 2.07388 train_acc= 0.43545 val_loss= 2.01387 val_acc= 0.46248 time= 0.16731
Epoch: 0024 train_loss= 2.02717 train_acc= 0.43681 val_loss= 1.96219 val_acc= 0.46554 time= 0.16705
Epoch: 0025 train_loss= 1.98944 train_acc= 0.44089 val_loss= 1.90886 val_acc= 0.47014 time= 0.18698
Epoch: 0026 train_loss= 1.92719 train_acc= 0.44599 val_loss= 1.85622 val_acc= 0.48392 time= 0.16801
Epoch: 0027 train_loss= 1.88057 train_acc= 0.46130 val_loss= 1.80631 val_acc= 0.50536 time= 0.16696
Epoch: 0028 train_loss= 1.82843 train_acc= 0.49481 val_loss= 1.76050 val_acc= 0.52986 time= 0.19297
Epoch: 0029 train_loss= 1.78938 train_acc= 0.52237 val_loss= 1.71910 val_acc= 0.56815 time= 0.17100
Epoch: 0030 train_loss= 1.74037 train_acc= 0.55979 val_loss= 1.68142 val_acc= 0.60949 time= 0.16900
Epoch: 0031 train_loss= 1.70326 train_acc= 0.59500 val_loss= 1.64609 val_acc= 0.63553 time= 0.18205
Epoch: 0032 train_loss= 1.67843 train_acc= 0.61728 val_loss= 1.61165 val_acc= 0.65697 time= 0.16741
Epoch: 0033 train_loss= 1.63872 train_acc= 0.63956 val_loss= 1.57727 val_acc= 0.67075 time= 0.16904
Epoch: 0034 train_loss= 1.60737 train_acc= 0.65045 val_loss= 1.54284 val_acc= 0.68453 time= 0.18001
Epoch: 0035 train_loss= 1.56121 train_acc= 0.66678 val_loss= 1.50866 val_acc= 0.69066 time= 0.16700
Epoch: 0036 train_loss= 1.53671 train_acc= 0.67188 val_loss= 1.47524 val_acc= 0.69372 time= 0.19471
Epoch: 0037 train_loss= 1.49680 train_acc= 0.67375 val_loss= 1.44314 val_acc= 0.69678 time= 0.17000
Epoch: 0038 train_loss= 1.46749 train_acc= 0.67035 val_loss= 1.41263 val_acc= 0.69832 time= 0.17119
Epoch: 0039 train_loss= 1.44183 train_acc= 0.67784 val_loss= 1.38384 val_acc= 0.69985 time= 0.18800
Epoch: 0040 train_loss= 1.40772 train_acc= 0.68175 val_loss= 1.35667 val_acc= 0.70138 time= 0.16722
Epoch: 0041 train_loss= 1.38853 train_acc= 0.68770 val_loss= 1.33077 val_acc= 0.70597 time= 0.16700
Epoch: 0042 train_loss= 1.35567 train_acc= 0.68855 val_loss= 1.30595 val_acc= 0.70597 time= 0.17000
Epoch: 0043 train_loss= 1.33137 train_acc= 0.69859 val_loss= 1.28202 val_acc= 0.70750 time= 0.16806
Epoch: 0044 train_loss= 1.30687 train_acc= 0.70658 val_loss= 1.25875 val_acc= 0.71363 time= 0.16907
Epoch: 0045 train_loss= 1.28698 train_acc= 0.71407 val_loss= 1.23606 val_acc= 0.71822 time= 0.19300
Epoch: 0046 train_loss= 1.25758 train_acc= 0.72274 val_loss= 1.21390 val_acc= 0.72588 time= 0.17004
Epoch: 0047 train_loss= 1.23937 train_acc= 0.72478 val_loss= 1.19232 val_acc= 0.73201 time= 0.16699
Epoch: 0048 train_loss= 1.22174 train_acc= 0.73057 val_loss= 1.17132 val_acc= 0.73354 time= 0.17876
Epoch: 0049 train_loss= 1.19702 train_acc= 0.73737 val_loss= 1.15093 val_acc= 0.73660 time= 0.16899
Epoch: 0050 train_loss= 1.17669 train_acc= 0.74349 val_loss= 1.13116 val_acc= 0.74426 time= 0.16700
Epoch: 0051 train_loss= 1.15320 train_acc= 0.74894 val_loss= 1.11201 val_acc= 0.75038 time= 0.18901
Epoch: 0052 train_loss= 1.12981 train_acc= 0.75268 val_loss= 1.09345 val_acc= 0.75651 time= 0.16994
Epoch: 0053 train_loss= 1.11146 train_acc= 0.75812 val_loss= 1.07540 val_acc= 0.76263 time= 0.17100
Epoch: 0054 train_loss= 1.09656 train_acc= 0.76169 val_loss= 1.05778 val_acc= 0.76876 time= 0.19300
Epoch: 0055 train_loss= 1.07955 train_acc= 0.76799 val_loss= 1.04048 val_acc= 0.77029 time= 0.16901
Epoch: 0056 train_loss= 1.05793 train_acc= 0.77292 val_loss= 1.02344 val_acc= 0.77489 time= 0.17099
Epoch: 0057 train_loss= 1.03964 train_acc= 0.77972 val_loss= 1.00660 val_acc= 0.78407 time= 0.17400
Epoch: 0058 train_loss= 1.02493 train_acc= 0.78653 val_loss= 0.98991 val_acc= 0.78867 time= 0.16800
Epoch: 0059 train_loss= 1.00266 train_acc= 0.78670 val_loss= 0.97338 val_acc= 0.79326 time= 0.18501
Epoch: 0060 train_loss= 0.98887 train_acc= 0.79741 val_loss= 0.95698 val_acc= 0.79632 time= 0.16700
Epoch: 0061 train_loss= 0.96734 train_acc= 0.79775 val_loss= 0.94069 val_acc= 0.79786 time= 0.17299
Epoch: 0062 train_loss= 0.95343 train_acc= 0.80592 val_loss= 0.92453 val_acc= 0.80551 time= 0.19200
Epoch: 0063 train_loss= 0.93874 train_acc= 0.81051 val_loss= 0.90850 val_acc= 0.81164 time= 0.16900
Epoch: 0064 train_loss= 0.92251 train_acc= 0.80881 val_loss= 0.89270 val_acc= 0.81317 time= 0.17000
Epoch: 0065 train_loss= 0.90471 train_acc= 0.81289 val_loss= 0.87717 val_acc= 0.81623 time= 0.18800
Epoch: 0066 train_loss= 0.88477 train_acc= 0.82089 val_loss= 0.86185 val_acc= 0.81930 time= 0.16900
Epoch: 0067 train_loss= 0.88093 train_acc= 0.82225 val_loss= 0.84676 val_acc= 0.82542 time= 0.16800
Epoch: 0068 train_loss= 0.85593 train_acc= 0.82497 val_loss= 0.83196 val_acc= 0.83308 time= 0.18801
Epoch: 0069 train_loss= 0.83882 train_acc= 0.83296 val_loss= 0.81739 val_acc= 0.83461 time= 0.16999
Epoch: 0070 train_loss= 0.82117 train_acc= 0.83654 val_loss= 0.80302 val_acc= 0.83614 time= 0.17044
Epoch: 0071 train_loss= 0.81075 train_acc= 0.84011 val_loss= 0.78894 val_acc= 0.83920 time= 0.17000
Epoch: 0072 train_loss= 0.79514 train_acc= 0.84011 val_loss= 0.77507 val_acc= 0.84380 time= 0.16801
Epoch: 0073 train_loss= 0.77765 train_acc= 0.84402 val_loss= 0.76156 val_acc= 0.84686 time= 0.16863
Epoch: 0074 train_loss= 0.76271 train_acc= 0.85134 val_loss= 0.74829 val_acc= 0.84992 time= 0.18600
Epoch: 0075 train_loss= 0.75130 train_acc= 0.84861 val_loss= 0.73533 val_acc= 0.85145 time= 0.16900
Epoch: 0076 train_loss= 0.73170 train_acc= 0.85440 val_loss= 0.72263 val_acc= 0.85452 time= 0.17000
Epoch: 0077 train_loss= 0.72705 train_acc= 0.85491 val_loss= 0.71015 val_acc= 0.85758 time= 0.17796
Epoch: 0078 train_loss= 0.70017 train_acc= 0.85950 val_loss= 0.69784 val_acc= 0.85911 time= 0.17097
Epoch: 0079 train_loss= 0.69250 train_acc= 0.86137 val_loss= 0.68575 val_acc= 0.86217 time= 0.17337
Epoch: 0080 train_loss= 0.68026 train_acc= 0.86239 val_loss= 0.67389 val_acc= 0.86217 time= 0.18803
Epoch: 0081 train_loss= 0.67093 train_acc= 0.86647 val_loss= 0.66229 val_acc= 0.86524 time= 0.16700
Epoch: 0082 train_loss= 0.65497 train_acc= 0.86732 val_loss= 0.65088 val_acc= 0.86524 time= 0.17300
Epoch: 0083 train_loss= 0.64638 train_acc= 0.87005 val_loss= 0.63971 val_acc= 0.86677 time= 0.16500
Epoch: 0084 train_loss= 0.63366 train_acc= 0.86886 val_loss= 0.62886 val_acc= 0.86830 time= 0.16600
Epoch: 0085 train_loss= 0.62161 train_acc= 0.87243 val_loss= 0.61831 val_acc= 0.86983 time= 0.16603
Epoch: 0086 train_loss= 0.61344 train_acc= 0.87583 val_loss= 0.60807 val_acc= 0.87289 time= 0.16949
Epoch: 0087 train_loss= 0.59197 train_acc= 0.87583 val_loss= 0.59816 val_acc= 0.87136 time= 0.19400
Epoch: 0088 train_loss= 0.58752 train_acc= 0.87923 val_loss= 0.58846 val_acc= 0.87902 time= 0.17701
Epoch: 0089 train_loss= 0.57094 train_acc= 0.88127 val_loss= 0.57904 val_acc= 0.88055 time= 0.16599
Epoch: 0090 train_loss= 0.56452 train_acc= 0.88467 val_loss= 0.56989 val_acc= 0.88055 time= 0.16707
Epoch: 0091 train_loss= 0.55959 train_acc= 0.88689 val_loss= 0.56091 val_acc= 0.88361 time= 0.18708
Epoch: 0092 train_loss= 0.54655 train_acc= 0.89046 val_loss= 0.55217 val_acc= 0.88515 time= 0.16499
Epoch: 0093 train_loss= 0.54226 train_acc= 0.89012 val_loss= 0.54344 val_acc= 0.88668 time= 0.16701
Epoch: 0094 train_loss= 0.53079 train_acc= 0.89063 val_loss= 0.53488 val_acc= 0.88668 time= 0.19123
Epoch: 0095 train_loss= 0.51682 train_acc= 0.89403 val_loss= 0.52654 val_acc= 0.88821 time= 0.17026
Epoch: 0096 train_loss= 0.50750 train_acc= 0.89828 val_loss= 0.51834 val_acc= 0.88974 time= 0.17200
Epoch: 0097 train_loss= 0.49694 train_acc= 0.89471 val_loss= 0.51031 val_acc= 0.89127 time= 0.16704
Epoch: 0098 train_loss= 0.49344 train_acc= 0.89828 val_loss= 0.50249 val_acc= 0.88974 time= 0.16711
Epoch: 0099 train_loss= 0.48655 train_acc= 0.89743 val_loss= 0.49494 val_acc= 0.88974 time= 0.17004
Epoch: 0100 train_loss= 0.47446 train_acc= 0.90304 val_loss= 0.48763 val_acc= 0.89127 time= 0.18507
Epoch: 0101 train_loss= 0.47168 train_acc= 0.90185 val_loss= 0.48048 val_acc= 0.89433 time= 0.16797
Epoch: 0102 train_loss= 0.46115 train_acc= 0.90441 val_loss= 0.47365 val_acc= 0.89587 time= 0.17000
Epoch: 0103 train_loss= 0.45460 train_acc= 0.90662 val_loss= 0.46699 val_acc= 0.89587 time= 0.19100
Epoch: 0104 train_loss= 0.44205 train_acc= 0.90560 val_loss= 0.46069 val_acc= 0.89587 time= 0.17100
Epoch: 0105 train_loss= 0.43782 train_acc= 0.91155 val_loss= 0.45448 val_acc= 0.89587 time= 0.17103
Epoch: 0106 train_loss= 0.43422 train_acc= 0.91444 val_loss= 0.44865 val_acc= 0.89893 time= 0.18697
Epoch: 0107 train_loss= 0.42012 train_acc= 0.91274 val_loss= 0.44273 val_acc= 0.89893 time= 0.16803
Epoch: 0108 train_loss= 0.41850 train_acc= 0.91444 val_loss= 0.43700 val_acc= 0.89893 time= 0.17097
Epoch: 0109 train_loss= 0.40915 train_acc= 0.91529 val_loss= 0.43146 val_acc= 0.89893 time= 0.18509
Epoch: 0110 train_loss= 0.39856 train_acc= 0.91648 val_loss= 0.42595 val_acc= 0.90046 time= 0.16800
Epoch: 0111 train_loss= 0.39656 train_acc= 0.92090 val_loss= 0.42019 val_acc= 0.90046 time= 0.19100
Epoch: 0112 train_loss= 0.38789 train_acc= 0.91869 val_loss= 0.41435 val_acc= 0.90046 time= 0.17100
Epoch: 0113 train_loss= 0.38085 train_acc= 0.92176 val_loss= 0.40873 val_acc= 0.90046 time= 0.17000
Epoch: 0114 train_loss= 0.36833 train_acc= 0.92278 val_loss= 0.40322 val_acc= 0.90199 time= 0.18700
Epoch: 0115 train_loss= 0.37006 train_acc= 0.92380 val_loss= 0.39808 val_acc= 0.90505 time= 0.16800
Epoch: 0116 train_loss= 0.36293 train_acc= 0.92567 val_loss= 0.39356 val_acc= 0.90658 time= 0.16700
Epoch: 0117 train_loss= 0.35721 train_acc= 0.92975 val_loss= 0.38966 val_acc= 0.90812 time= 0.16700
Epoch: 0118 train_loss= 0.35199 train_acc= 0.92788 val_loss= 0.38608 val_acc= 0.90812 time= 0.16800
Epoch: 0119 train_loss= 0.34639 train_acc= 0.93128 val_loss= 0.38258 val_acc= 0.90812 time= 0.17212
Epoch: 0120 train_loss= 0.34163 train_acc= 0.93349 val_loss= 0.37957 val_acc= 0.90658 time= 0.18900
Epoch: 0121 train_loss= 0.34475 train_acc= 0.92890 val_loss= 0.37627 val_acc= 0.90505 time= 0.17005
Epoch: 0122 train_loss= 0.33138 train_acc= 0.93264 val_loss= 0.37268 val_acc= 0.90352 time= 0.17002
Epoch: 0123 train_loss= 0.32393 train_acc= 0.93315 val_loss= 0.36886 val_acc= 0.90505 time= 0.18500
Epoch: 0124 train_loss= 0.31629 train_acc= 0.93553 val_loss= 0.36464 val_acc= 0.90658 time= 0.16800
Epoch: 0125 train_loss= 0.32142 train_acc= 0.93264 val_loss= 0.36014 val_acc= 0.90658 time= 0.17008
Epoch: 0126 train_loss= 0.31177 train_acc= 0.93434 val_loss= 0.35562 val_acc= 0.90965 time= 0.17397
Epoch: 0127 train_loss= 0.30861 train_acc= 0.93757 val_loss= 0.35201 val_acc= 0.91118 time= 0.16700
Epoch: 0128 train_loss= 0.29963 train_acc= 0.93604 val_loss= 0.34837 val_acc= 0.91118 time= 0.17300
Epoch: 0129 train_loss= 0.29823 train_acc= 0.94166 val_loss= 0.34511 val_acc= 0.91271 time= 0.18500
Epoch: 0130 train_loss= 0.29777 train_acc= 0.93808 val_loss= 0.34133 val_acc= 0.91424 time= 0.16903
Epoch: 0131 train_loss= 0.28815 train_acc= 0.94404 val_loss= 0.33779 val_acc= 0.91577 time= 0.16972
Epoch: 0132 train_loss= 0.28057 train_acc= 0.94540 val_loss= 0.33462 val_acc= 0.91730 time= 0.18400
Epoch: 0133 train_loss= 0.28394 train_acc= 0.94455 val_loss= 0.33188 val_acc= 0.91730 time= 0.16800
Epoch: 0134 train_loss= 0.27473 train_acc= 0.94268 val_loss= 0.32954 val_acc= 0.91730 time= 0.18500
Epoch: 0135 train_loss= 0.26932 train_acc= 0.94574 val_loss= 0.32780 val_acc= 0.91730 time= 0.16600
Epoch: 0136 train_loss= 0.27031 train_acc= 0.94472 val_loss= 0.32599 val_acc= 0.91730 time= 0.17055
Epoch: 0137 train_loss= 0.26145 train_acc= 0.94846 val_loss= 0.32410 val_acc= 0.91271 time= 0.19245
Epoch: 0138 train_loss= 0.25908 train_acc= 0.94812 val_loss= 0.32216 val_acc= 0.91730 time= 0.17000
Epoch: 0139 train_loss= 0.25444 train_acc= 0.94948 val_loss= 0.31990 val_acc= 0.91884 time= 0.16807
Epoch: 0140 train_loss= 0.25930 train_acc= 0.94761 val_loss= 0.31773 val_acc= 0.92037 time= 0.16799
Epoch: 0141 train_loss= 0.24907 train_acc= 0.95118 val_loss= 0.31509 val_acc= 0.91884 time= 0.16901
Epoch: 0142 train_loss= 0.24257 train_acc= 0.95152 val_loss= 0.31252 val_acc= 0.91884 time= 0.16900
Epoch: 0143 train_loss= 0.24182 train_acc= 0.95339 val_loss= 0.30950 val_acc= 0.91884 time= 0.18600
Epoch: 0144 train_loss= 0.23669 train_acc= 0.95339 val_loss= 0.30659 val_acc= 0.91884 time= 0.17097
Epoch: 0145 train_loss= 0.23315 train_acc= 0.95356 val_loss= 0.30377 val_acc= 0.92343 time= 0.17300
Epoch: 0146 train_loss= 0.22927 train_acc= 0.95697 val_loss= 0.30126 val_acc= 0.92496 time= 0.18900
Epoch: 0147 train_loss= 0.22982 train_acc= 0.95356 val_loss= 0.29947 val_acc= 0.92190 time= 0.16703
Epoch: 0148 train_loss= 0.22595 train_acc= 0.95594 val_loss= 0.29804 val_acc= 0.92037 time= 0.16800
Epoch: 0149 train_loss= 0.22279 train_acc= 0.95629 val_loss= 0.29684 val_acc= 0.92037 time= 0.18400
Epoch: 0150 train_loss= 0.21529 train_acc= 0.95782 val_loss= 0.29618 val_acc= 0.92037 time= 0.16700
Epoch: 0151 train_loss= 0.21952 train_acc= 0.95509 val_loss= 0.29532 val_acc= 0.91884 time= 0.17000
Epoch: 0152 train_loss= 0.21141 train_acc= 0.95612 val_loss= 0.29407 val_acc= 0.92037 time= 0.17401
Epoch: 0153 train_loss= 0.20604 train_acc= 0.96003 val_loss= 0.29262 val_acc= 0.92190 time= 0.17396
Epoch: 0154 train_loss= 0.20319 train_acc= 0.96173 val_loss= 0.29131 val_acc= 0.92190 time= 0.17282
Epoch: 0155 train_loss= 0.20113 train_acc= 0.96207 val_loss= 0.28970 val_acc= 0.92343 time= 0.18803
Epoch: 0156 train_loss= 0.19684 train_acc= 0.96258 val_loss= 0.28768 val_acc= 0.92496 time= 0.16900
Epoch: 0157 train_loss= 0.19653 train_acc= 0.96139 val_loss= 0.28510 val_acc= 0.92649 time= 0.18601
Epoch: 0158 train_loss= 0.19669 train_acc= 0.95765 val_loss= 0.28247 val_acc= 0.92496 time= 0.16799
Epoch: 0159 train_loss= 0.19385 train_acc= 0.96309 val_loss= 0.28004 val_acc= 0.92496 time= 0.16625
Epoch: 0160 train_loss= 0.18604 train_acc= 0.96632 val_loss= 0.27775 val_acc= 0.92496 time= 0.18699
Epoch: 0161 train_loss= 0.18913 train_acc= 0.96394 val_loss= 0.27605 val_acc= 0.92496 time= 0.17000
Epoch: 0162 train_loss= 0.18692 train_acc= 0.96530 val_loss= 0.27434 val_acc= 0.92496 time= 0.17000
Epoch: 0163 train_loss= 0.18490 train_acc= 0.96632 val_loss= 0.27214 val_acc= 0.92649 time= 0.16900
Epoch: 0164 train_loss= 0.18247 train_acc= 0.96224 val_loss= 0.27058 val_acc= 0.92649 time= 0.16807
Epoch: 0165 train_loss= 0.18107 train_acc= 0.96343 val_loss= 0.26917 val_acc= 0.92649 time= 0.17100
Epoch: 0166 train_loss= 0.17244 train_acc= 0.96496 val_loss= 0.26818 val_acc= 0.92649 time= 0.18501
Epoch: 0167 train_loss= 0.17533 train_acc= 0.96462 val_loss= 0.26729 val_acc= 0.92649 time= 0.16699
Epoch: 0168 train_loss= 0.17698 train_acc= 0.96411 val_loss= 0.26692 val_acc= 0.92802 time= 0.16897
Epoch: 0169 train_loss= 0.17124 train_acc= 0.96836 val_loss= 0.26693 val_acc= 0.92802 time= 0.18600
Epoch: 0170 train_loss= 0.17195 train_acc= 0.96904 val_loss= 0.26669 val_acc= 0.92649 time= 0.17000
Epoch: 0171 train_loss= 0.16643 train_acc= 0.97040 val_loss= 0.26628 val_acc= 0.92802 time= 0.17200
Epoch: 0172 train_loss= 0.16097 train_acc= 0.97074 val_loss= 0.26591 val_acc= 0.92802 time= 0.18800
Epoch: 0173 train_loss= 0.15897 train_acc= 0.96887 val_loss= 0.26572 val_acc= 0.92649 time= 0.16903
Epoch: 0174 train_loss= 0.15927 train_acc= 0.96972 val_loss= 0.26539 val_acc= 0.92649 time= 0.18310
Epoch: 0175 train_loss= 0.16103 train_acc= 0.96853 val_loss= 0.26449 val_acc= 0.92802 time= 0.16899
Epoch: 0176 train_loss= 0.15654 train_acc= 0.97142 val_loss= 0.26311 val_acc= 0.92802 time= 0.16701
Epoch: 0177 train_loss= 0.15127 train_acc= 0.96938 val_loss= 0.26115 val_acc= 0.92802 time= 0.16500
Epoch: 0178 train_loss= 0.15489 train_acc= 0.97125 val_loss= 0.25896 val_acc= 0.92649 time= 0.16897
Epoch: 0179 train_loss= 0.15036 train_acc= 0.97295 val_loss= 0.25736 val_acc= 0.92649 time= 0.17300
Epoch: 0180 train_loss= 0.14968 train_acc= 0.97193 val_loss= 0.25598 val_acc= 0.92956 time= 0.18925
Epoch: 0181 train_loss= 0.14555 train_acc= 0.97227 val_loss= 0.25517 val_acc= 0.93109 time= 0.16704
Epoch: 0182 train_loss= 0.14373 train_acc= 0.97381 val_loss= 0.25433 val_acc= 0.93109 time= 0.17100
Epoch: 0183 train_loss= 0.14181 train_acc= 0.97398 val_loss= 0.25415 val_acc= 0.93109 time= 0.18500
Epoch: 0184 train_loss= 0.14087 train_acc= 0.97602 val_loss= 0.25370 val_acc= 0.93568 time= 0.16699
Epoch: 0185 train_loss= 0.13982 train_acc= 0.97227 val_loss= 0.25335 val_acc= 0.93568 time= 0.17101
Epoch: 0186 train_loss= 0.13918 train_acc= 0.97534 val_loss= 0.25288 val_acc= 0.93874 time= 0.18804
Epoch: 0187 train_loss= 0.13619 train_acc= 0.97840 val_loss= 0.25207 val_acc= 0.93874 time= 0.17081
Epoch: 0188 train_loss= 0.13762 train_acc= 0.97483 val_loss= 0.25100 val_acc= 0.93415 time= 0.17300
Epoch: 0189 train_loss= 0.13466 train_acc= 0.97585 val_loss= 0.25024 val_acc= 0.93415 time= 0.18801
Epoch: 0190 train_loss= 0.13329 train_acc= 0.97585 val_loss= 0.24957 val_acc= 0.93568 time= 0.16604
Epoch: 0191 train_loss= 0.13003 train_acc= 0.97636 val_loss= 0.24939 val_acc= 0.93568 time= 0.17900
Epoch: 0192 train_loss= 0.12786 train_acc= 0.97772 val_loss= 0.24946 val_acc= 0.93262 time= 0.16819
Epoch: 0193 train_loss= 0.12611 train_acc= 0.97636 val_loss= 0.24954 val_acc= 0.93262 time= 0.17000
Epoch: 0194 train_loss= 0.12845 train_acc= 0.97585 val_loss= 0.25002 val_acc= 0.93415 time= 0.18903
Epoch: 0195 train_loss= 0.12371 train_acc= 0.97704 val_loss= 0.24970 val_acc= 0.93109 time= 0.17122
Epoch: 0196 train_loss= 0.12098 train_acc= 0.97925 val_loss= 0.24874 val_acc= 0.93262 time= 0.17082
Epoch: 0197 train_loss= 0.12384 train_acc= 0.97772 val_loss= 0.24777 val_acc= 0.93415 time= 0.18600
Epoch: 0198 train_loss= 0.11782 train_acc= 0.98027 val_loss= 0.24636 val_acc= 0.93415 time= 0.16800
Epoch: 0199 train_loss= 0.12064 train_acc= 0.97738 val_loss= 0.24492 val_acc= 0.93568 time= 0.16802
Epoch: 0200 train_loss= 0.11908 train_acc= 0.97755 val_loss= 0.24383 val_acc= 0.93568 time= 0.18803
Epoch: 0201 train_loss= 0.11560 train_acc= 0.97704 val_loss= 0.24303 val_acc= 0.94028 time= 0.16700
Epoch: 0202 train_loss= 0.11586 train_acc= 0.97772 val_loss= 0.24257 val_acc= 0.93874 time= 0.16822
Epoch: 0203 train_loss= 0.11374 train_acc= 0.97942 val_loss= 0.24264 val_acc= 0.93721 time= 0.17697
Epoch: 0204 train_loss= 0.11319 train_acc= 0.97959 val_loss= 0.24270 val_acc= 0.93721 time= 0.17000
Epoch: 0205 train_loss= 0.11108 train_acc= 0.98095 val_loss= 0.24210 val_acc= 0.93721 time= 0.17100
Epoch: 0206 train_loss= 0.11221 train_acc= 0.97925 val_loss= 0.24175 val_acc= 0.93721 time= 0.18303
Epoch: 0207 train_loss= 0.11111 train_acc= 0.98061 val_loss= 0.24103 val_acc= 0.93721 time= 0.16702
Epoch: 0208 train_loss= 0.10992 train_acc= 0.98299 val_loss= 0.24040 val_acc= 0.93874 time= 0.16601
Epoch: 0209 train_loss= 0.10715 train_acc= 0.98146 val_loss= 0.23960 val_acc= 0.93874 time= 0.18799
Epoch: 0210 train_loss= 0.10453 train_acc= 0.98265 val_loss= 0.23910 val_acc= 0.93874 time= 0.17106
Epoch: 0211 train_loss= 0.10280 train_acc= 0.98265 val_loss= 0.23868 val_acc= 0.94181 time= 0.17270
Epoch: 0212 train_loss= 0.10391 train_acc= 0.98061 val_loss= 0.23854 val_acc= 0.94181 time= 0.18900
Epoch: 0213 train_loss= 0.10390 train_acc= 0.98146 val_loss= 0.23805 val_acc= 0.94028 time= 0.16900
Epoch: 0214 train_loss= 0.10220 train_acc= 0.98248 val_loss= 0.23742 val_acc= 0.93874 time= 0.17003
Epoch: 0215 train_loss= 0.09888 train_acc= 0.98333 val_loss= 0.23699 val_acc= 0.94028 time= 0.17300
Epoch: 0216 train_loss= 0.09765 train_acc= 0.98248 val_loss= 0.23699 val_acc= 0.93874 time= 0.16900
Epoch: 0217 train_loss= 0.10149 train_acc= 0.98282 val_loss= 0.23670 val_acc= 0.94028 time= 0.16900
Epoch: 0218 train_loss= 0.09741 train_acc= 0.98299 val_loss= 0.23654 val_acc= 0.93874 time= 0.18501
Epoch: 0219 train_loss= 0.09607 train_acc= 0.98299 val_loss= 0.23653 val_acc= 0.94028 time= 0.16800
Epoch: 0220 train_loss= 0.09535 train_acc= 0.98316 val_loss= 0.23660 val_acc= 0.94028 time= 0.19193
Epoch: 0221 train_loss= 0.09761 train_acc= 0.98435 val_loss= 0.23690 val_acc= 0.93874 time= 0.17100
Epoch: 0222 train_loss= 0.09161 train_acc= 0.98384 val_loss= 0.23723 val_acc= 0.93721 time= 0.16865
Early stopping...
Optimization Finished!
Test set results: cost= 0.26654 accuracy= 0.93497 time= 0.07700
17992
Test Precision, Recall and F1-Score...
              precision    recall  f1-score   support

           0     1.0000    1.0000    1.0000         8
           1     0.6667    0.3333    0.4444         6
           2     1.0000    1.0000    1.0000         1
           3     0.7634    0.9467    0.8452        75
           4     1.0000    1.0000    1.0000         9
           5     0.8100    0.9310    0.8663        87
           6     0.8846    0.9200    0.9020        25
           7     0.8000    0.9231    0.8571        13
           8     0.8333    0.9091    0.8696        11
           9     1.0000    0.3333    0.5000         9
          10     0.9231    0.6667    0.7742        36
          11     1.0000    0.9167    0.9565        12
          12     0.8392    0.9917    0.9091       121
          13     0.8750    0.7368    0.8000        19
          14     0.8621    0.8929    0.8772        28
          15     1.0000    0.7500    0.8571         4
          16     0.0000    0.0000    0.0000         4
          17     0.0000    0.0000    0.0000         3
          18     1.0000    1.0000    1.0000        10
          19     1.0000    1.0000    1.0000         2
          20     0.8000    0.4444    0.5714         9
          21     0.9048    0.9500    0.9268        20
          22     0.4286    0.6000    0.5000         5
          23     0.0000    0.0000    0.0000         1
          24     0.7222    0.7647    0.7429        17
          25     1.0000    0.8667    0.9286        15
          26     0.0000    0.0000    0.0000         1
          27     1.0000    0.7500    0.8571        12
          28     1.0000    0.7273    0.8421        11
          29     0.9669    0.9655    0.9662       696
          30     1.0000    1.0000    1.0000        22
          31     1.0000    1.0000    1.0000         3
          32     0.7692    1.0000    0.8696        10
          33     1.0000    0.6667    0.8000         3
          34     0.0000    0.0000    0.0000         1
          35     0.8553    0.8025    0.8280        81
          36     1.0000    0.3333    0.5000        12
          37     1.0000    0.7500    0.8571         4
          38     0.0000    0.0000    0.0000         1
          39     0.9763    0.9908    0.9835      1083
          40     0.6667    0.8000    0.7273         5
          41     0.0000    0.0000    0.0000         2
          42     0.8889    0.8889    0.8889         9
          43     0.0000    0.0000    0.0000         3
          44     0.8182    0.7500    0.7826        12
          45     0.5000    0.1667    0.2500         6
          46     1.0000    0.2857    0.4444         7
          47     0.9286    0.8667    0.8966        15
          48     1.0000    0.8889    0.9412         9
          49     0.0000    0.0000    0.0000         1
          50     0.5000    0.2000    0.2857         5
          51     1.0000    0.7500    0.8571         4

    accuracy                         0.9350      2568
   macro avg     0.7304    0.6435    0.6674      2568
weighted avg     0.9321    0.9350    0.9294      2568

Macro average Test Precision, Recall and F1-Score...
(0.7304417281077658, 0.6434609932943426, 0.6674227789676751, None)
Micro average Test Precision, Recall and F1-Score...
(0.9349688473520249, 0.9349688473520249, 0.9349688473520249, None)
embeddings:
8892 6532 2568
[[-0.02989305  1.3273168   0.16894537 ...  0.17992994 -0.08445961
   0.38406742]
 [ 0.12311023  0.5423884   0.09113641 ...  0.13236365  0.20400998
   0.2120494 ]
 [ 0.05735693  0.43822894  0.05839155 ...  0.15631129  0.2252489
   0.18092856]
 ...
 [ 0.20564957  0.04040067  0.11954718 ...  0.12847836  0.10679559
   0.03636359]
 [ 0.06429313  0.14752701  0.07342488 ...  0.09238345  0.10593411
   0.09760907]
 [ 0.26529112  0.3688024   0.23356676 ...  0.19053867  0.2549164
   0.21598047]]
