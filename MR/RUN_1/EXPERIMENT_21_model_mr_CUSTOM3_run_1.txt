(6398, 300) (6398, 2) (3554, 300) (3554, 2) (25872, 300) (25872, 2)
29426
  (0, 10623)	6.18339884402439
  (0, 13919)	0.5465010749888104
  (0, 14559)	1.1115554606675069
  (0, 15700)	3.7569884009179986
  (0, 18226)	1.5195310253612764
  (0, 18467)	4.04333268052812
  (0, 19338)	7.328531148327393
  (0, 22286)	6.789534647594706
  (0, 23328)	1.9258537664551136
  (1, 7795)	5.147306912337615
  (1, 8008)	5.36241829195456
  (1, 9081)	2.030213781779356
  (1, 9548)	1.8885902192574975
  (1, 9842)	5.487127339313642
  (1, 10712)	7.077216720046487
  (1, 11167)	4.763581790865857
  (1, 11240)	1.9780280286087861
  (1, 12074)	8.581294116822761
  (1, 12204)	3.001693660045025
  (1, 13383)	8.175829008714597
  (1, 13384)	1.1367531124051018
  (1, 13919)	2.732505374944052
  (1, 14559)	0.5557777303337534
  (1, 15052)	2.8176716418105427
  (1, 15552)	3.1786167349504817
  :	:
  (29423, 20674)	1.2821726541119611
  (29423, 21548)	2.0777547265483562
  (29423, 21594)	4.71009310591487
  (29423, 22686)	1.3489223175957803
  (29423, 23714)	0.7656835847875705
  (29423, 24605)	6.18339884402439
  (29424, 9508)	7.665003384948606
  (29424, 12204)	1.5008468300225124
  (29424, 12719)	8.175829008714597
  (29424, 13792)	7.19499975570287
  (29424, 14440)	2.1419437457226627
  (29424, 14647)	4.23101618046346
  (29424, 14666)	6.384069539486542
  (29424, 14849)	2.730529451817914
  (29424, 15098)	3.941722504117337
  (29424, 15191)	8.175829008714597
  (29424, 16855)	7.665003384948606
  (29424, 18226)	1.5195310253612764
  (29424, 19164)	4.983981856234315
  (29424, 22983)	4.630050398241334
  (29424, 24152)	4.168495823482126
  (29425, 8194)	6.278709023828715
  (29425, 13921)	5.249089606647557
  (29425, 19699)	0.6764057181223682
  (29425, 22407)	4.855600689586108
(29426, 29426)
(29426, 29426)
29426
Tensor("graphconvolution_2/SparseTensorDenseMatMul/SparseTensorDenseMatMul:0", shape=(None, 2), dtype=float32)
Epoch: 0001 train_loss= 0.69314 train_acc= 0.49984 val_loss= 0.69177 val_acc= 0.71127 time= 0.36824
Epoch: 0002 train_loss= 0.69075 train_acc= 0.79478 val_loss= 0.68821 val_acc= 0.69014 time= 0.09208
Epoch: 0003 train_loss= 0.68490 train_acc= 0.76774 val_loss= 0.68213 val_acc= 0.69155 time= 0.07541
Epoch: 0004 train_loss= 0.67492 train_acc= 0.76930 val_loss= 0.67351 val_acc= 0.70000 time= 0.07603
Epoch: 0005 train_loss= 0.66071 train_acc= 0.79087 val_loss= 0.66229 val_acc= 0.72535 time= 0.07500
Epoch: 0006 train_loss= 0.64238 train_acc= 0.80963 val_loss= 0.64848 val_acc= 0.73803 time= 0.07300
Epoch: 0007 train_loss= 0.61992 train_acc= 0.82885 val_loss= 0.63234 val_acc= 0.74930 time= 0.09100
Epoch: 0008 train_loss= 0.59348 train_acc= 0.84620 val_loss= 0.61437 val_acc= 0.75634 time= 0.07200
Epoch: 0009 train_loss= 0.56411 train_acc= 0.85339 val_loss= 0.59530 val_acc= 0.77324 time= 0.07600
Epoch: 0010 train_loss= 0.53260 train_acc= 0.86418 val_loss= 0.57601 val_acc= 0.77746 time= 0.07200
Epoch: 0011 train_loss= 0.49895 train_acc= 0.86887 val_loss= 0.55741 val_acc= 0.77746 time= 0.07199
Epoch: 0012 train_loss= 0.46887 train_acc= 0.87449 val_loss= 0.54032 val_acc= 0.77887 time= 0.07400
Epoch: 0013 train_loss= 0.43201 train_acc= 0.88012 val_loss= 0.52535 val_acc= 0.77887 time= 0.07400
Epoch: 0014 train_loss= 0.40273 train_acc= 0.88090 val_loss= 0.51313 val_acc= 0.77183 time= 0.08100
Epoch: 0015 train_loss= 0.37421 train_acc= 0.88090 val_loss= 0.50393 val_acc= 0.77042 time= 0.07200
Epoch: 0016 train_loss= 0.34907 train_acc= 0.88465 val_loss= 0.49792 val_acc= 0.77183 time= 0.07100
Epoch: 0017 train_loss= 0.32382 train_acc= 0.88778 val_loss= 0.49499 val_acc= 0.77465 time= 0.07205
Epoch: 0018 train_loss= 0.30517 train_acc= 0.89075 val_loss= 0.49511 val_acc= 0.77887 time= 0.07403
Epoch: 0019 train_loss= 0.28214 train_acc= 0.89887 val_loss= 0.49823 val_acc= 0.77746 time= 0.07297
Epoch: 0020 train_loss= 0.26617 train_acc= 0.90169 val_loss= 0.50331 val_acc= 0.78028 time= 0.08808
Epoch: 0021 train_loss= 0.24962 train_acc= 0.90685 val_loss= 0.51052 val_acc= 0.78169 time= 0.07203
Epoch: 0022 train_loss= 0.23721 train_acc= 0.91279 val_loss= 0.51975 val_acc= 0.78310 time= 0.08000
Early stopping...
Optimization Finished!
Test set results: cost= 0.52294 accuracy= 0.76140 time= 0.03100
29426
Test Precision, Recall and F1-Score...
              precision    recall  f1-score   support

           0     0.7531    0.7777    0.7652      1777
           1     0.7702    0.7451    0.7574      1777

    accuracy                         0.7614      3554
   macro avg     0.7617    0.7614    0.7613      3554
weighted avg     0.7617    0.7614    0.7613      3554

Macro average Test Precision, Recall and F1-Score...
(0.761674378202903, 0.7613956105796287, 0.7613320459895949, None)
Micro average Test Precision, Recall and F1-Score...
(0.7613956105796286, 0.7613956105796286, 0.7613956105796287, None)
embeddings:
18764 7108 3554
[[ 0.0099436   0.01891851 -0.00720895 ...  0.07680039  0.08145504
   0.08578676]
 [ 0.06000128  0.10148647  0.09740702 ...  0.04734842 -0.00306138
   0.03023373]
 [-0.03249857 -0.04693792 -0.04035444 ...  0.15388271  0.15279838
   0.12619804]
 ...
 [-0.04807686 -0.10388953 -0.08309733 ...  0.08413691  0.17265746
  -0.08853015]
 [ 0.05821704  0.11856528  0.08323015 ...  0.02385259  0.04169723
   0.03361272]
 [ 0.15454198  0.22453132  0.2024178  ...  0.07686341  0.1163253
   0.06996708]]
