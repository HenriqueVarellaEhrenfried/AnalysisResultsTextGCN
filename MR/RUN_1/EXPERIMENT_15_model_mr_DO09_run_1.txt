(6398, 300) (6398, 2) (3554, 300) (3554, 2) (25872, 300) (25872, 2)
29426
  (0, 10623)	6.18339884402439
  (0, 13919)	0.5465010749888104
  (0, 14559)	1.1115554606675069
  (0, 15700)	3.7569884009179986
  (0, 18226)	1.5195310253612764
  (0, 18467)	4.04333268052812
  (0, 19338)	7.328531148327393
  (0, 22286)	6.789534647594706
  (0, 23328)	1.9258537664551136
  (1, 7795)	5.147306912337615
  (1, 8008)	5.36241829195456
  (1, 9081)	2.030213781779356
  (1, 9548)	1.8885902192574975
  (1, 9842)	5.487127339313642
  (1, 10712)	7.077216720046487
  (1, 11167)	4.763581790865857
  (1, 11240)	1.9780280286087861
  (1, 12074)	8.581294116822761
  (1, 12204)	3.001693660045025
  (1, 13383)	8.175829008714597
  (1, 13384)	1.1367531124051018
  (1, 13919)	2.732505374944052
  (1, 14559)	0.5557777303337534
  (1, 15052)	2.8176716418105427
  (1, 15552)	3.1786167349504817
  :	:
  (29423, 20674)	1.2821726541119611
  (29423, 21548)	2.0777547265483562
  (29423, 21594)	4.71009310591487
  (29423, 22686)	1.3489223175957803
  (29423, 23714)	0.7656835847875705
  (29423, 24605)	6.18339884402439
  (29424, 9508)	7.665003384948606
  (29424, 12204)	1.5008468300225124
  (29424, 12719)	8.175829008714597
  (29424, 13792)	7.19499975570287
  (29424, 14440)	2.1419437457226627
  (29424, 14647)	4.23101618046346
  (29424, 14666)	6.384069539486542
  (29424, 14849)	2.730529451817914
  (29424, 15098)	3.941722504117337
  (29424, 15191)	8.175829008714597
  (29424, 16855)	7.665003384948606
  (29424, 18226)	1.5195310253612764
  (29424, 19164)	4.983981856234315
  (29424, 22983)	4.630050398241334
  (29424, 24152)	4.168495823482126
  (29425, 8194)	6.278709023828715
  (29425, 13921)	5.249089606647557
  (29425, 19699)	0.6764057181223682
  (29425, 22407)	4.855600689586108
(29426, 29426)
(29426, 29426)
29426
Tensor("graphconvolution_2/SparseTensorDenseMatMul/SparseTensorDenseMatMul:0", shape=(None, 2), dtype=float32)
Epoch: 0001 train_loss= 0.69315 train_acc= 0.50313 val_loss= 0.69172 val_acc= 0.75070 time= 0.36797
Epoch: 0002 train_loss= 0.69063 train_acc= 0.81791 val_loss= 0.68800 val_acc= 0.73803 time= 0.07620
Epoch: 0003 train_loss= 0.68456 train_acc= 0.81479 val_loss= 0.68179 val_acc= 0.73662 time= 0.08397
Epoch: 0004 train_loss= 0.67451 train_acc= 0.82557 val_loss= 0.67304 val_acc= 0.73521 time= 0.07600
Epoch: 0005 train_loss= 0.66015 train_acc= 0.83260 val_loss= 0.66167 val_acc= 0.74648 time= 0.07304
Epoch: 0006 train_loss= 0.64191 train_acc= 0.84183 val_loss= 0.64780 val_acc= 0.75493 time= 0.07296
Epoch: 0007 train_loss= 0.61889 train_acc= 0.84526 val_loss= 0.63182 val_acc= 0.75211 time= 0.08100
Epoch: 0008 train_loss= 0.59369 train_acc= 0.85402 val_loss= 0.61418 val_acc= 0.76338 time= 0.07204
Epoch: 0009 train_loss= 0.56458 train_acc= 0.86089 val_loss= 0.59553 val_acc= 0.77183 time= 0.07201
Epoch: 0010 train_loss= 0.53366 train_acc= 0.86527 val_loss= 0.57661 val_acc= 0.77324 time= 0.08298
Epoch: 0011 train_loss= 0.50167 train_acc= 0.86840 val_loss= 0.55828 val_acc= 0.76901 time= 0.07201
Epoch: 0012 train_loss= 0.46848 train_acc= 0.86824 val_loss= 0.54126 val_acc= 0.76901 time= 0.07196
Epoch: 0013 train_loss= 0.43513 train_acc= 0.87606 val_loss= 0.52633 val_acc= 0.76901 time= 0.08204
Epoch: 0014 train_loss= 0.40500 train_acc= 0.87559 val_loss= 0.51411 val_acc= 0.77324 time= 0.07201
Epoch: 0015 train_loss= 0.37554 train_acc= 0.88590 val_loss= 0.50487 val_acc= 0.77183 time= 0.07199
Epoch: 0016 train_loss= 0.34892 train_acc= 0.88168 val_loss= 0.49872 val_acc= 0.77887 time= 0.07496
Epoch: 0017 train_loss= 0.32801 train_acc= 0.88481 val_loss= 0.49575 val_acc= 0.77887 time= 0.08103
Epoch: 0018 train_loss= 0.30422 train_acc= 0.89247 val_loss= 0.49590 val_acc= 0.78028 time= 0.07800
Epoch: 0019 train_loss= 0.28387 train_acc= 0.89637 val_loss= 0.49856 val_acc= 0.77887 time= 0.07300
Epoch: 0020 train_loss= 0.26773 train_acc= 0.90184 val_loss= 0.50399 val_acc= 0.77746 time= 0.07800
Epoch: 0021 train_loss= 0.25159 train_acc= 0.90778 val_loss= 0.51091 val_acc= 0.77887 time= 0.07226
Epoch: 0022 train_loss= 0.23748 train_acc= 0.90778 val_loss= 0.51912 val_acc= 0.78310 time= 0.07135
Early stopping...
Optimization Finished!
Test set results: cost= 0.52236 accuracy= 0.76365 time= 0.03099
29426
Test Precision, Recall and F1-Score...
              precision    recall  f1-score   support

           0     0.7596    0.7715    0.7655      1777
           1     0.7679    0.7558    0.7618      1777

    accuracy                         0.7636      3554
   macro avg     0.7637    0.7636    0.7636      3554
weighted avg     0.7637    0.7636    0.7636      3554

Macro average Test Precision, Recall and F1-Score...
(0.7637120697383071, 0.7636465953854812, 0.7636319240368985, None)
Micro average Test Precision, Recall and F1-Score...
(0.7636465953854812, 0.7636465953854812, 0.7636465953854811, None)
embeddings:
18764 7108 3554
[[ 0.01882352  0.07675141 -0.00999228 ...  0.08430861  0.06845456
  -0.02182054]
 [ 0.13025676  0.02352954  0.10584785 ...  0.00375082  0.01194986
   0.06260353]
 [-0.04397482  0.15246114 -0.04276641 ...  0.16235593  0.12835024
  -0.0449413 ]
 ...
 [-0.09149431  0.16346858 -0.00505774 ... -0.00649696  0.04905818
  -0.06228142]
 [ 0.10961661  0.03368194  0.10552448 ...  0.01860295  0.01427392
   0.08308037]
 [ 0.1864527   0.08280256  0.1739809  ...  0.0851661   0.09423338
   0.1911185 ]]
