(6398, 300) (6398, 2) (3554, 300) (3554, 2) (25872, 300) (25872, 2)
29426
  (0, 10623)	6.18339884402439
  (0, 13919)	0.5465010749888104
  (0, 14559)	1.1115554606675069
  (0, 15700)	3.7569884009179986
  (0, 18226)	1.5195310253612764
  (0, 18467)	4.04333268052812
  (0, 19338)	7.328531148327393
  (0, 22286)	6.789534647594706
  (0, 23328)	1.9258537664551136
  (1, 7795)	5.147306912337615
  (1, 8008)	5.36241829195456
  (1, 9081)	2.030213781779356
  (1, 9548)	1.8885902192574975
  (1, 9842)	5.487127339313642
  (1, 10712)	7.077216720046487
  (1, 11167)	4.763581790865857
  (1, 11240)	1.9780280286087861
  (1, 12074)	8.581294116822761
  (1, 12204)	3.001693660045025
  (1, 13383)	8.175829008714597
  (1, 13384)	1.1367531124051018
  (1, 13919)	2.732505374944052
  (1, 14559)	0.5557777303337534
  (1, 15052)	2.8176716418105427
  (1, 15552)	3.1786167349504817
  :	:
  (29423, 20674)	1.2821726541119611
  (29423, 21548)	2.0777547265483562
  (29423, 21594)	4.71009310591487
  (29423, 22686)	1.3489223175957803
  (29423, 23714)	0.7656835847875705
  (29423, 24605)	6.18339884402439
  (29424, 9508)	7.665003384948606
  (29424, 12204)	1.5008468300225124
  (29424, 12719)	8.175829008714597
  (29424, 13792)	7.19499975570287
  (29424, 14440)	2.1419437457226627
  (29424, 14647)	4.23101618046346
  (29424, 14666)	6.384069539486542
  (29424, 14849)	2.730529451817914
  (29424, 15098)	3.941722504117337
  (29424, 15191)	8.175829008714597
  (29424, 16855)	7.665003384948606
  (29424, 18226)	1.5195310253612764
  (29424, 19164)	4.983981856234315
  (29424, 22983)	4.630050398241334
  (29424, 24152)	4.168495823482126
  (29425, 8194)	6.278709023828715
  (29425, 13921)	5.249089606647557
  (29425, 19699)	0.6764057181223682
  (29425, 22407)	4.855600689586108
(29426, 29426)
(29426, 29426)
29426
Tensor("graphconvolution_2/SparseTensorDenseMatMul/SparseTensorDenseMatMul:0", shape=(None, 2), dtype=float32)
Epoch: 0001 train_loss= 0.69317 train_acc= 0.49781 val_loss= 0.69173 val_acc= 0.75915 time= 0.37115
Epoch: 0002 train_loss= 0.69081 train_acc= 0.81838 val_loss= 0.68809 val_acc= 0.74507 time= 0.07600
Epoch: 0003 train_loss= 0.68506 train_acc= 0.82307 val_loss= 0.68188 val_acc= 0.73944 time= 0.07500
Epoch: 0004 train_loss= 0.67502 train_acc= 0.82917 val_loss= 0.67311 val_acc= 0.75211 time= 0.08419
Epoch: 0005 train_loss= 0.66093 train_acc= 0.83370 val_loss= 0.66176 val_acc= 0.75775 time= 0.07097
Epoch: 0006 train_loss= 0.64243 train_acc= 0.83761 val_loss= 0.64791 val_acc= 0.75634 time= 0.07303
Epoch: 0007 train_loss= 0.61931 train_acc= 0.84964 val_loss= 0.63182 val_acc= 0.75775 time= 0.07206
Epoch: 0008 train_loss= 0.59369 train_acc= 0.85152 val_loss= 0.61395 val_acc= 0.76620 time= 0.07200
Epoch: 0009 train_loss= 0.56487 train_acc= 0.85636 val_loss= 0.59505 val_acc= 0.76761 time= 0.09400
Epoch: 0010 train_loss= 0.53352 train_acc= 0.86074 val_loss= 0.57590 val_acc= 0.77324 time= 0.07396
Epoch: 0011 train_loss= 0.50067 train_acc= 0.86558 val_loss= 0.55738 val_acc= 0.77324 time= 0.07404
Epoch: 0012 train_loss= 0.46775 train_acc= 0.87371 val_loss= 0.54032 val_acc= 0.77465 time= 0.07200
Epoch: 0013 train_loss= 0.43398 train_acc= 0.87215 val_loss= 0.52543 val_acc= 0.77465 time= 0.07209
Epoch: 0014 train_loss= 0.40161 train_acc= 0.87809 val_loss= 0.51323 val_acc= 0.77606 time= 0.07208
Epoch: 0015 train_loss= 0.37319 train_acc= 0.88418 val_loss= 0.50402 val_acc= 0.77606 time= 0.07296
Epoch: 0016 train_loss= 0.34981 train_acc= 0.88731 val_loss= 0.49804 val_acc= 0.77887 time= 0.08857
Epoch: 0017 train_loss= 0.32582 train_acc= 0.88856 val_loss= 0.49523 val_acc= 0.78028 time= 0.07300
Epoch: 0018 train_loss= 0.30335 train_acc= 0.89450 val_loss= 0.49544 val_acc= 0.77746 time= 0.07206
Epoch: 0019 train_loss= 0.28367 train_acc= 0.89716 val_loss= 0.49828 val_acc= 0.77746 time= 0.07208
Epoch: 0020 train_loss= 0.26889 train_acc= 0.89903 val_loss= 0.50353 val_acc= 0.77887 time= 0.07203
Epoch: 0021 train_loss= 0.25215 train_acc= 0.90216 val_loss= 0.51092 val_acc= 0.78028 time= 0.07300
Epoch: 0022 train_loss= 0.23818 train_acc= 0.91060 val_loss= 0.52034 val_acc= 0.78310 time= 0.08700
Early stopping...
Optimization Finished!
Test set results: cost= 0.52357 accuracy= 0.76280 time= 0.03200
29426
Test Precision, Recall and F1-Score...
              precision    recall  f1-score   support

           0     0.7627    0.7631    0.7629      1777
           1     0.7630    0.7625    0.7627      1777

    accuracy                         0.7628      3554
   macro avg     0.7628    0.7628    0.7628      3554
weighted avg     0.7628    0.7628    0.7628      3554

Macro average Test Precision, Recall and F1-Score...
(0.7628025593084649, 0.7628024760832864, 0.7628024573041621, None)
Micro average Test Precision, Recall and F1-Score...
(0.7628024760832864, 0.7628024760832864, 0.7628024760832864, None)
embeddings:
18764 7108 3554
[[ 0.04727595  0.08781473 -0.01341877 ... -0.00156078 -0.00968949
   0.09207945]
 [ 0.01291851 -0.00033323  0.10678511 ...  0.12827222  0.07301136
   0.02088835]
 [ 0.15353552  0.1596465  -0.04019937 ... -0.04699562 -0.04343515
   0.1745173 ]
 ...
 [ 0.1235811   0.11306116 -0.08491153 ... -0.08591021 -0.07189024
  -0.00709461]
 [ 0.04355345  0.03299522  0.10557108 ...  0.13964775  0.09675378
   0.0190252 ]
 [ 0.09616929  0.10168944  0.1887091  ...  0.2480614   0.19622192
   0.09460582]]
