(6398, 300) (6398, 2) (3554, 300) (3554, 2) (25872, 300) (25872, 2)
29426
  (0, 10623)	6.18339884402439
  (0, 13919)	0.5465010749888104
  (0, 14559)	1.1115554606675069
  (0, 15700)	3.7569884009179986
  (0, 18226)	1.5195310253612764
  (0, 18467)	4.04333268052812
  (0, 19338)	7.328531148327393
  (0, 22286)	6.789534647594706
  (0, 23328)	1.9258537664551136
  (1, 7795)	5.147306912337615
  (1, 8008)	5.36241829195456
  (1, 9081)	2.030213781779356
  (1, 9548)	1.8885902192574975
  (1, 9842)	5.487127339313642
  (1, 10712)	7.077216720046487
  (1, 11167)	4.763581790865857
  (1, 11240)	1.9780280286087861
  (1, 12074)	8.581294116822761
  (1, 12204)	3.001693660045025
  (1, 13383)	8.175829008714597
  (1, 13384)	1.1367531124051018
  (1, 13919)	2.732505374944052
  (1, 14559)	0.5557777303337534
  (1, 15052)	2.8176716418105427
  (1, 15552)	3.1786167349504817
  :	:
  (29423, 20674)	1.2821726541119611
  (29423, 21548)	2.0777547265483562
  (29423, 21594)	4.71009310591487
  (29423, 22686)	1.3489223175957803
  (29423, 23714)	0.7656835847875705
  (29423, 24605)	6.18339884402439
  (29424, 9508)	7.665003384948606
  (29424, 12204)	1.5008468300225124
  (29424, 12719)	8.175829008714597
  (29424, 13792)	7.19499975570287
  (29424, 14440)	2.1419437457226627
  (29424, 14647)	4.23101618046346
  (29424, 14666)	6.384069539486542
  (29424, 14849)	2.730529451817914
  (29424, 15098)	3.941722504117337
  (29424, 15191)	8.175829008714597
  (29424, 16855)	7.665003384948606
  (29424, 18226)	1.5195310253612764
  (29424, 19164)	4.983981856234315
  (29424, 22983)	4.630050398241334
  (29424, 24152)	4.168495823482126
  (29425, 8194)	6.278709023828715
  (29425, 13921)	5.249089606647557
  (29425, 19699)	0.6764057181223682
  (29425, 22407)	4.855600689586108
(29426, 29426)
(29426, 29426)
29426
Tensor("graphconvolution_2/SparseTensorDenseMatMul/SparseTensorDenseMatMul:0", shape=(None, 2), dtype=float32)
Epoch: 0001 train_loss= 0.69317 train_acc= 0.50000 val_loss= 0.68473 val_acc= 0.48451 time= 0.38526
Epoch: 0002 train_loss= 0.67753 train_acc= 0.50375 val_loss= 0.67117 val_acc= 0.50845 time= 0.07638
Epoch: 0003 train_loss= 0.62586 train_acc= 0.54611 val_loss= 0.59690 val_acc= 0.76761 time= 0.07597
Epoch: 0004 train_loss= 0.52631 train_acc= 0.87668 val_loss= 0.55163 val_acc= 0.71972 time= 0.07503
Epoch: 0005 train_loss= 0.43107 train_acc= 0.84870 val_loss= 0.50090 val_acc= 0.76901 time= 0.09000
Epoch: 0006 train_loss= 0.32486 train_acc= 0.88809 val_loss= 0.50290 val_acc= 0.77183 time= 0.07701
Epoch: 0007 train_loss= 0.25746 train_acc= 0.90106 val_loss= 0.56734 val_acc= 0.74930 time= 0.07204
Early stopping...
Optimization Finished!
Test set results: cost= 0.57686 accuracy= 0.74817 time= 0.03097
29426
Test Precision, Recall and F1-Score...
              precision    recall  f1-score   support

           0     0.7049    0.8537    0.7722      1777
           1     0.8146    0.6427    0.7185      1777

    accuracy                         0.7482      3554
   macro avg     0.7597    0.7482    0.7453      3554
weighted avg     0.7597    0.7482    0.7453      3554

Macro average Test Precision, Recall and F1-Score...
(0.7597381462488533, 0.7481710748452448, 0.745335797220417, None)
Micro average Test Precision, Recall and F1-Score...
(0.7481710748452448, 0.7481710748452448, 0.7481710748452447, None)
embeddings:
18764 7108 3554
[[ 0.00111063 -0.05159423 -0.00237043 ...  0.03867451 -0.03355176
  -0.03365664]
 [ 0.1412775  -0.124201    0.14148594 ... -0.02736568 -0.04707841
  -0.05561208]
 [-0.05627768 -0.06624521 -0.05649117 ...  0.14083925  0.12613188
  -0.06344602]
 ...
 [-0.04398084 -0.27644303 -0.3148859  ... -0.00769922  0.19003403
  -0.13822724]
 [ 0.13766396 -0.09948086  0.13069077 ...  0.01703123 -0.07808264
  -0.02328423]
 [ 0.2089017  -0.23268594  0.2586339  ...  0.08472236 -0.09103736
  -0.02034963]]
