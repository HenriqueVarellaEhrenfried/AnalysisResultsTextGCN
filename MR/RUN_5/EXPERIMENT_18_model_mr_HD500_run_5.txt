(6398, 300) (6398, 2) (3554, 300) (3554, 2) (25872, 300) (25872, 2)
29426
  (0, 10623)	6.18339884402439
  (0, 13919)	0.5465010749888104
  (0, 14559)	1.1115554606675069
  (0, 15700)	3.7569884009179986
  (0, 18226)	1.5195310253612764
  (0, 18467)	4.04333268052812
  (0, 19338)	7.328531148327393
  (0, 22286)	6.789534647594706
  (0, 23328)	1.9258537664551136
  (1, 7795)	5.147306912337615
  (1, 8008)	5.36241829195456
  (1, 9081)	2.030213781779356
  (1, 9548)	1.8885902192574975
  (1, 9842)	5.487127339313642
  (1, 10712)	7.077216720046487
  (1, 11167)	4.763581790865857
  (1, 11240)	1.9780280286087861
  (1, 12074)	8.581294116822761
  (1, 12204)	3.001693660045025
  (1, 13383)	8.175829008714597
  (1, 13384)	1.1367531124051018
  (1, 13919)	2.732505374944052
  (1, 14559)	0.5557777303337534
  (1, 15052)	2.8176716418105427
  (1, 15552)	3.1786167349504817
  :	:
  (29423, 20674)	1.2821726541119611
  (29423, 21548)	2.0777547265483562
  (29423, 21594)	4.71009310591487
  (29423, 22686)	1.3489223175957803
  (29423, 23714)	0.7656835847875705
  (29423, 24605)	6.18339884402439
  (29424, 9508)	7.665003384948606
  (29424, 12204)	1.5008468300225124
  (29424, 12719)	8.175829008714597
  (29424, 13792)	7.19499975570287
  (29424, 14440)	2.1419437457226627
  (29424, 14647)	4.23101618046346
  (29424, 14666)	6.384069539486542
  (29424, 14849)	2.730529451817914
  (29424, 15098)	3.941722504117337
  (29424, 15191)	8.175829008714597
  (29424, 16855)	7.665003384948606
  (29424, 18226)	1.5195310253612764
  (29424, 19164)	4.983981856234315
  (29424, 22983)	4.630050398241334
  (29424, 24152)	4.168495823482126
  (29425, 8194)	6.278709023828715
  (29425, 13921)	5.249089606647557
  (29425, 19699)	0.6764057181223682
  (29425, 22407)	4.855600689586108
(29426, 29426)
(29426, 29426)
29426
Tensor("graphconvolution_2/SparseTensorDenseMatMul/SparseTensorDenseMatMul:0", shape=(None, 2), dtype=float32)
Epoch: 0001 train_loss= 0.69314 train_acc= 0.50219 val_loss= 0.68972 val_acc= 0.68873 time= 0.47551
Epoch: 0002 train_loss= 0.68654 train_acc= 0.80697 val_loss= 0.67975 val_acc= 0.63099 time= 0.12016
Epoch: 0003 train_loss= 0.66904 train_acc= 0.72851 val_loss= 0.66434 val_acc= 0.65493 time= 0.12103
Epoch: 0004 train_loss= 0.64153 train_acc= 0.76024 val_loss= 0.64226 val_acc= 0.71408 time= 0.11527
Epoch: 0005 train_loss= 0.60317 train_acc= 0.82338 val_loss= 0.61417 val_acc= 0.74789 time= 0.11401
Epoch: 0006 train_loss= 0.55528 train_acc= 0.86293 val_loss= 0.58301 val_acc= 0.77324 time= 0.11400
Epoch: 0007 train_loss= 0.50133 train_acc= 0.88700 val_loss= 0.55275 val_acc= 0.77465 time= 0.12900
Epoch: 0008 train_loss= 0.44458 train_acc= 0.89278 val_loss= 0.52689 val_acc= 0.77042 time= 0.11400
Epoch: 0009 train_loss= 0.38919 train_acc= 0.89716 val_loss= 0.50843 val_acc= 0.77042 time= 0.11400
Epoch: 0010 train_loss= 0.33892 train_acc= 0.90388 val_loss= 0.49951 val_acc= 0.77465 time= 0.11506
Epoch: 0011 train_loss= 0.29596 train_acc= 0.90778 val_loss= 0.50058 val_acc= 0.77324 time= 0.11500
Epoch: 0012 train_loss= 0.25874 train_acc= 0.91435 val_loss= 0.51154 val_acc= 0.77183 time= 0.12400
Epoch: 0013 train_loss= 0.22844 train_acc= 0.92013 val_loss= 0.53033 val_acc= 0.77465 time= 0.11500
Epoch: 0014 train_loss= 0.20264 train_acc= 0.92998 val_loss= 0.55530 val_acc= 0.77465 time= 0.11507
Early stopping...
Optimization Finished!
Test set results: cost= 0.55078 accuracy= 0.75971 time= 0.04406
29426
Test Precision, Recall and F1-Score...
              precision    recall  f1-score   support

           0     0.7477    0.7839    0.7654      1777
           1     0.7729    0.7355    0.7537      1777

    accuracy                         0.7597      3554
   macro avg     0.7603    0.7597    0.7596      3554
weighted avg     0.7603    0.7597    0.7596      3554

Macro average Test Precision, Recall and F1-Score...
(0.7603170839400153, 0.7597073719752392, 0.7595665868157218, None)
Micro average Test Precision, Recall and F1-Score...
(0.7597073719752392, 0.7597073719752392, 0.7597073719752392, None)
embeddings:
18764 7108 3554
[[-1.5383954e-03  6.5767616e-02 -8.8838860e-04 ... -1.9128900e-03
   6.3442163e-02  7.4701637e-02]
 [ 5.0467316e-02  9.2375251e-03  7.6250777e-02 ...  6.2452685e-02
   4.1429885e-05 -1.3877039e-03]
 [-1.5546952e-02  1.2887189e-01 -2.7711798e-02 ... -2.4181476e-02
   1.2321858e-01  1.3130148e-01]
 ...
 [-4.4541627e-02  1.3688055e-01 -7.7883609e-02 ... -7.8972965e-02
  -6.6117705e-03  1.7284435e-01]
 [ 4.8983794e-02  1.8602785e-02  8.9355990e-02 ...  8.3121344e-02
   1.4198191e-02  2.5283162e-02]
 [ 9.0559252e-02  9.0544596e-02  1.8206930e-01 ...  1.2635276e-01
   8.3644047e-02  7.0387162e-02]]
