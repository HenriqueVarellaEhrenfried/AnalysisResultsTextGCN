(6398, 300) (6398, 2) (3554, 300) (3554, 2) (25872, 300) (25872, 2)
29426
  (0, 10623)	6.18339884402439
  (0, 13919)	0.5465010749888104
  (0, 14559)	1.1115554606675069
  (0, 15700)	3.7569884009179986
  (0, 18226)	1.5195310253612764
  (0, 18467)	4.04333268052812
  (0, 19338)	7.328531148327393
  (0, 22286)	6.789534647594706
  (0, 23328)	1.9258537664551136
  (1, 7795)	5.147306912337615
  (1, 8008)	5.36241829195456
  (1, 9081)	2.030213781779356
  (1, 9548)	1.8885902192574975
  (1, 9842)	5.487127339313642
  (1, 10712)	7.077216720046487
  (1, 11167)	4.763581790865857
  (1, 11240)	1.9780280286087861
  (1, 12074)	8.581294116822761
  (1, 12204)	3.001693660045025
  (1, 13383)	8.175829008714597
  (1, 13384)	1.1367531124051018
  (1, 13919)	2.732505374944052
  (1, 14559)	0.5557777303337534
  (1, 15052)	2.8176716418105427
  (1, 15552)	3.1786167349504817
  :	:
  (29423, 20674)	1.2821726541119611
  (29423, 21548)	2.0777547265483562
  (29423, 21594)	4.71009310591487
  (29423, 22686)	1.3489223175957803
  (29423, 23714)	0.7656835847875705
  (29423, 24605)	6.18339884402439
  (29424, 9508)	7.665003384948606
  (29424, 12204)	1.5008468300225124
  (29424, 12719)	8.175829008714597
  (29424, 13792)	7.19499975570287
  (29424, 14440)	2.1419437457226627
  (29424, 14647)	4.23101618046346
  (29424, 14666)	6.384069539486542
  (29424, 14849)	2.730529451817914
  (29424, 15098)	3.941722504117337
  (29424, 15191)	8.175829008714597
  (29424, 16855)	7.665003384948606
  (29424, 18226)	1.5195310253612764
  (29424, 19164)	4.983981856234315
  (29424, 22983)	4.630050398241334
  (29424, 24152)	4.168495823482126
  (29425, 8194)	6.278709023828715
  (29425, 13921)	5.249089606647557
  (29425, 19699)	0.6764057181223682
  (29425, 22407)	4.855600689586108
(29426, 29426)
(29426, 29426)
29426
Tensor("graphconvolution_2/SparseTensorDenseMatMul/SparseTensorDenseMatMul:0", shape=(None, 2), dtype=float32)
Epoch: 0001 train_loss= 0.69313 train_acc= 0.50172 val_loss= 0.69096 val_acc= 0.70141 time= 0.37658
Epoch: 0002 train_loss= 0.68922 train_acc= 0.79603 val_loss= 0.68535 val_acc= 0.67887 time= 0.07600
Epoch: 0003 train_loss= 0.67983 train_acc= 0.77118 val_loss= 0.67687 val_acc= 0.68310 time= 0.07499
Epoch: 0004 train_loss= 0.66550 train_acc= 0.78243 val_loss= 0.66542 val_acc= 0.70563 time= 0.08008
Epoch: 0005 train_loss= 0.64615 train_acc= 0.80494 val_loss= 0.65101 val_acc= 0.73099 time= 0.07204
Epoch: 0006 train_loss= 0.62252 train_acc= 0.83417 val_loss= 0.63397 val_acc= 0.74085 time= 0.07309
Epoch: 0007 train_loss= 0.59424 train_acc= 0.84464 val_loss= 0.61481 val_acc= 0.75211 time= 0.07922
Epoch: 0008 train_loss= 0.56125 train_acc= 0.85902 val_loss= 0.59434 val_acc= 0.76197 time= 0.07200
Epoch: 0009 train_loss= 0.52654 train_acc= 0.87480 val_loss= 0.57370 val_acc= 0.77324 time= 0.07400
Epoch: 0010 train_loss= 0.49059 train_acc= 0.88106 val_loss= 0.55393 val_acc= 0.77606 time= 0.07900
Epoch: 0011 train_loss= 0.45318 train_acc= 0.88059 val_loss= 0.53611 val_acc= 0.78169 time= 0.07200
Epoch: 0012 train_loss= 0.41686 train_acc= 0.88809 val_loss= 0.52116 val_acc= 0.77465 time= 0.07297
Epoch: 0013 train_loss= 0.38421 train_acc= 0.89403 val_loss= 0.50963 val_acc= 0.77465 time= 0.08403
Epoch: 0014 train_loss= 0.35222 train_acc= 0.89559 val_loss= 0.50193 val_acc= 0.77746 time= 0.07297
Epoch: 0015 train_loss= 0.32416 train_acc= 0.89544 val_loss= 0.49816 val_acc= 0.78169 time= 0.07210
Epoch: 0016 train_loss= 0.29857 train_acc= 0.90466 val_loss= 0.49814 val_acc= 0.77606 time= 0.07997
Epoch: 0017 train_loss= 0.27602 train_acc= 0.90544 val_loss= 0.50164 val_acc= 0.77606 time= 0.07200
Epoch: 0018 train_loss= 0.25601 train_acc= 0.91185 val_loss= 0.50844 val_acc= 0.77887 time= 0.07252
Epoch: 0019 train_loss= 0.23740 train_acc= 0.91607 val_loss= 0.51791 val_acc= 0.77887 time= 0.08111
Epoch: 0020 train_loss= 0.22035 train_acc= 0.92107 val_loss= 0.52954 val_acc= 0.78028 time= 0.07100
Early stopping...
Optimization Finished!
Test set results: cost= 0.52851 accuracy= 0.76027 time= 0.03100
29426
Test Precision, Recall and F1-Score...
              precision    recall  f1-score   support

           0     0.7509    0.7788    0.7646      1777
           1     0.7703    0.7417    0.7557      1777

    accuracy                         0.7603      3554
   macro avg     0.7606    0.7603    0.7602      3554
weighted avg     0.7606    0.7603    0.7602      3554

Macro average Test Precision, Recall and F1-Score...
(0.7606296495847462, 0.7602701181767023, 0.7601874144660146, None)
Micro average Test Precision, Recall and F1-Score...
(0.7602701181767023, 0.7602701181767023, 0.7602701181767023, None)
embeddings:
18764 7108 3554
[[-5.20365406e-03  3.76921333e-03  9.36183408e-02 ...  8.19102302e-02
  -9.08191130e-03  5.61348051e-02]
 [ 7.44585022e-02  1.16416849e-01  1.06080901e-04 ...  2.88977334e-03
   1.33196935e-01  2.55875513e-02]
 [-2.46017985e-02 -4.82056662e-02  1.42708614e-01 ...  1.32076502e-01
  -4.71955910e-02  1.28901213e-01]
 ...
 [-4.84889150e-02 -6.82071373e-02  1.19669296e-01 ...  8.53462070e-02
  -7.15162605e-02  1.05534412e-01]
 [ 7.39790872e-02  1.41328692e-01  3.76768038e-02 ...  3.05273551e-02
   1.55708402e-01  2.08427310e-02]
 [ 1.24513246e-01  2.76438862e-01  1.05078101e-01 ...  8.87411460e-02
   2.71625012e-01  6.12147190e-02]]
