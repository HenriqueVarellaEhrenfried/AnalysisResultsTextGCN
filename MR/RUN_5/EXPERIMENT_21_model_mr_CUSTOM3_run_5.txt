(6398, 300) (6398, 2) (3554, 300) (3554, 2) (25872, 300) (25872, 2)
29426
  (0, 10623)	6.18339884402439
  (0, 13919)	0.5465010749888104
  (0, 14559)	1.1115554606675069
  (0, 15700)	3.7569884009179986
  (0, 18226)	1.5195310253612764
  (0, 18467)	4.04333268052812
  (0, 19338)	7.328531148327393
  (0, 22286)	6.789534647594706
  (0, 23328)	1.9258537664551136
  (1, 7795)	5.147306912337615
  (1, 8008)	5.36241829195456
  (1, 9081)	2.030213781779356
  (1, 9548)	1.8885902192574975
  (1, 9842)	5.487127339313642
  (1, 10712)	7.077216720046487
  (1, 11167)	4.763581790865857
  (1, 11240)	1.9780280286087861
  (1, 12074)	8.581294116822761
  (1, 12204)	3.001693660045025
  (1, 13383)	8.175829008714597
  (1, 13384)	1.1367531124051018
  (1, 13919)	2.732505374944052
  (1, 14559)	0.5557777303337534
  (1, 15052)	2.8176716418105427
  (1, 15552)	3.1786167349504817
  :	:
  (29423, 20674)	1.2821726541119611
  (29423, 21548)	2.0777547265483562
  (29423, 21594)	4.71009310591487
  (29423, 22686)	1.3489223175957803
  (29423, 23714)	0.7656835847875705
  (29423, 24605)	6.18339884402439
  (29424, 9508)	7.665003384948606
  (29424, 12204)	1.5008468300225124
  (29424, 12719)	8.175829008714597
  (29424, 13792)	7.19499975570287
  (29424, 14440)	2.1419437457226627
  (29424, 14647)	4.23101618046346
  (29424, 14666)	6.384069539486542
  (29424, 14849)	2.730529451817914
  (29424, 15098)	3.941722504117337
  (29424, 15191)	8.175829008714597
  (29424, 16855)	7.665003384948606
  (29424, 18226)	1.5195310253612764
  (29424, 19164)	4.983981856234315
  (29424, 22983)	4.630050398241334
  (29424, 24152)	4.168495823482126
  (29425, 8194)	6.278709023828715
  (29425, 13921)	5.249089606647557
  (29425, 19699)	0.6764057181223682
  (29425, 22407)	4.855600689586108
(29426, 29426)
(29426, 29426)
29426
Tensor("graphconvolution_2/SparseTensorDenseMatMul/SparseTensorDenseMatMul:0", shape=(None, 2), dtype=float32)
Epoch: 0001 train_loss= 0.69318 train_acc= 0.49609 val_loss= 0.69174 val_acc= 0.73662 time= 0.37497
Epoch: 0002 train_loss= 0.69070 train_acc= 0.81666 val_loss= 0.68813 val_acc= 0.74085 time= 0.08111
Epoch: 0003 train_loss= 0.68492 train_acc= 0.82729 val_loss= 0.68192 val_acc= 0.74085 time= 0.07500
Epoch: 0004 train_loss= 0.67485 train_acc= 0.83417 val_loss= 0.67309 val_acc= 0.74648 time= 0.08938
Epoch: 0005 train_loss= 0.66034 train_acc= 0.83448 val_loss= 0.66162 val_acc= 0.75352 time= 0.07301
Epoch: 0006 train_loss= 0.64263 train_acc= 0.84433 val_loss= 0.64763 val_acc= 0.75775 time= 0.07159
Epoch: 0007 train_loss= 0.61942 train_acc= 0.84886 val_loss= 0.63148 val_acc= 0.75915 time= 0.07194
Epoch: 0008 train_loss= 0.59266 train_acc= 0.85542 val_loss= 0.61363 val_acc= 0.76761 time= 0.07201
Epoch: 0009 train_loss= 0.56368 train_acc= 0.85792 val_loss= 0.59476 val_acc= 0.76479 time= 0.08700
Epoch: 0010 train_loss= 0.53113 train_acc= 0.86433 val_loss= 0.57567 val_acc= 0.76338 time= 0.07496
Epoch: 0011 train_loss= 0.49842 train_acc= 0.86449 val_loss= 0.55725 val_acc= 0.76620 time= 0.07807
Epoch: 0012 train_loss= 0.46541 train_acc= 0.86933 val_loss= 0.54033 val_acc= 0.76338 time= 0.07600
Epoch: 0013 train_loss= 0.43282 train_acc= 0.87621 val_loss= 0.52562 val_acc= 0.76620 time= 0.07200
Epoch: 0014 train_loss= 0.39991 train_acc= 0.88090 val_loss= 0.51349 val_acc= 0.76620 time= 0.07203
Epoch: 0015 train_loss= 0.37748 train_acc= 0.88012 val_loss= 0.50447 val_acc= 0.77324 time= 0.07297
Epoch: 0016 train_loss= 0.34753 train_acc= 0.88653 val_loss= 0.49858 val_acc= 0.77746 time= 0.08600
Epoch: 0017 train_loss= 0.32413 train_acc= 0.89231 val_loss= 0.49587 val_acc= 0.77606 time= 0.07150
Epoch: 0018 train_loss= 0.30394 train_acc= 0.89215 val_loss= 0.49607 val_acc= 0.78028 time= 0.07203
Epoch: 0019 train_loss= 0.28233 train_acc= 0.90106 val_loss= 0.49908 val_acc= 0.78028 time= 0.07199
Epoch: 0020 train_loss= 0.26711 train_acc= 0.90059 val_loss= 0.50462 val_acc= 0.77887 time= 0.07309
Epoch: 0021 train_loss= 0.25369 train_acc= 0.90435 val_loss= 0.51137 val_acc= 0.77887 time= 0.08507
Epoch: 0022 train_loss= 0.23499 train_acc= 0.90841 val_loss= 0.52030 val_acc= 0.78169 time= 0.07404
Early stopping...
Optimization Finished!
Test set results: cost= 0.52534 accuracy= 0.76224 time= 0.02999
29426
Test Precision, Recall and F1-Score...
              precision    recall  f1-score   support

           0     0.7586    0.7693    0.7639      1777
           1     0.7660    0.7552    0.7606      1777

    accuracy                         0.7622      3554
   macro avg     0.7623    0.7622    0.7622      3554
weighted avg     0.7623    0.7622    0.7622      3554

Macro average Test Precision, Recall and F1-Score...
(0.7622916444944481, 0.7622397298818233, 0.7622279645021639, None)
Micro average Test Precision, Recall and F1-Score...
(0.7622397298818233, 0.7622397298818233, 0.7622397298818234, None)
embeddings:
18764 7108 3554
[[ 0.06052622 -0.00654534 -0.00043406 ...  0.09884182 -0.00529911
  -0.00354196]
 [-0.00217747  0.06380343  0.0851831  ...  0.00464327  0.1322326
   0.14460391]
 [ 0.1327918  -0.0277001  -0.04606985 ...  0.16589393 -0.05252028
  -0.03863942]
 ...
 [ 0.13481668 -0.05123901 -0.00846636 ...  0.12536746 -0.06220568
  -0.01692365]
 [ 0.037212    0.04949019  0.13173646 ...  0.02613742  0.10453376
   0.11530463]
 [ 0.08020744  0.138009    0.19710916 ...  0.11859269  0.20810574
   0.16393006]]
