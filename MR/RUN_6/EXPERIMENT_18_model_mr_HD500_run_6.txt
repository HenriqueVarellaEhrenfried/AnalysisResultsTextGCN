(6398, 300) (6398, 2) (3554, 300) (3554, 2) (25872, 300) (25872, 2)
29426
  (0, 10623)	6.18339884402439
  (0, 13919)	0.5465010749888104
  (0, 14559)	1.1115554606675069
  (0, 15700)	3.7569884009179986
  (0, 18226)	1.5195310253612764
  (0, 18467)	4.04333268052812
  (0, 19338)	7.328531148327393
  (0, 22286)	6.789534647594706
  (0, 23328)	1.9258537664551136
  (1, 7795)	5.147306912337615
  (1, 8008)	5.36241829195456
  (1, 9081)	2.030213781779356
  (1, 9548)	1.8885902192574975
  (1, 9842)	5.487127339313642
  (1, 10712)	7.077216720046487
  (1, 11167)	4.763581790865857
  (1, 11240)	1.9780280286087861
  (1, 12074)	8.581294116822761
  (1, 12204)	3.001693660045025
  (1, 13383)	8.175829008714597
  (1, 13384)	1.1367531124051018
  (1, 13919)	2.732505374944052
  (1, 14559)	0.5557777303337534
  (1, 15052)	2.8176716418105427
  (1, 15552)	3.1786167349504817
  :	:
  (29423, 20674)	1.2821726541119611
  (29423, 21548)	2.0777547265483562
  (29423, 21594)	4.71009310591487
  (29423, 22686)	1.3489223175957803
  (29423, 23714)	0.7656835847875705
  (29423, 24605)	6.18339884402439
  (29424, 9508)	7.665003384948606
  (29424, 12204)	1.5008468300225124
  (29424, 12719)	8.175829008714597
  (29424, 13792)	7.19499975570287
  (29424, 14440)	2.1419437457226627
  (29424, 14647)	4.23101618046346
  (29424, 14666)	6.384069539486542
  (29424, 14849)	2.730529451817914
  (29424, 15098)	3.941722504117337
  (29424, 15191)	8.175829008714597
  (29424, 16855)	7.665003384948606
  (29424, 18226)	1.5195310253612764
  (29424, 19164)	4.983981856234315
  (29424, 22983)	4.630050398241334
  (29424, 24152)	4.168495823482126
  (29425, 8194)	6.278709023828715
  (29425, 13921)	5.249089606647557
  (29425, 19699)	0.6764057181223682
  (29425, 22407)	4.855600689586108
(29426, 29426)
(29426, 29426)
29426
Tensor("graphconvolution_2/SparseTensorDenseMatMul/SparseTensorDenseMatMul:0", shape=(None, 2), dtype=float32)
Epoch: 0001 train_loss= 0.69315 train_acc= 0.49625 val_loss= 0.69019 val_acc= 0.68310 time= 0.47807
Epoch: 0002 train_loss= 0.68742 train_acc= 0.81150 val_loss= 0.68125 val_acc= 0.63662 time= 0.12897
Epoch: 0003 train_loss= 0.67162 train_acc= 0.73367 val_loss= 0.66680 val_acc= 0.65493 time= 0.11700
Epoch: 0004 train_loss= 0.64598 train_acc= 0.76415 val_loss= 0.64573 val_acc= 0.70986 time= 0.11500
Epoch: 0005 train_loss= 0.60946 train_acc= 0.82135 val_loss= 0.61845 val_acc= 0.74648 time= 0.11700
Epoch: 0006 train_loss= 0.56270 train_acc= 0.86136 val_loss= 0.58754 val_acc= 0.76901 time= 0.11706
Epoch: 0007 train_loss= 0.50921 train_acc= 0.88606 val_loss= 0.55680 val_acc= 0.77465 time= 0.11500
Epoch: 0008 train_loss= 0.45225 train_acc= 0.89262 val_loss= 0.53003 val_acc= 0.77042 time= 0.11500
Epoch: 0009 train_loss= 0.39596 train_acc= 0.89669 val_loss= 0.51041 val_acc= 0.77042 time= 0.11703
Epoch: 0010 train_loss= 0.34545 train_acc= 0.90247 val_loss= 0.50019 val_acc= 0.76901 time= 0.11600
Epoch: 0011 train_loss= 0.30045 train_acc= 0.90888 val_loss= 0.50006 val_acc= 0.77183 time= 0.11901
Epoch: 0012 train_loss= 0.26360 train_acc= 0.91107 val_loss= 0.50964 val_acc= 0.77606 time= 0.11808
Epoch: 0013 train_loss= 0.23172 train_acc= 0.92185 val_loss= 0.52810 val_acc= 0.77324 time= 0.11590
Epoch: 0014 train_loss= 0.20500 train_acc= 0.92576 val_loss= 0.55264 val_acc= 0.77324 time= 0.11699
Early stopping...
Optimization Finished!
Test set results: cost= 0.54840 accuracy= 0.75999 time= 0.04500
29426
Test Precision, Recall and F1-Score...
              precision    recall  f1-score   support

           0     0.7465    0.7873    0.7664      1777
           1     0.7750    0.7327    0.7533      1777

    accuracy                         0.7600      3554
   macro avg     0.7608    0.7600    0.7598      3554
weighted avg     0.7608    0.7600    0.7598      3554

Macro average Test Precision, Recall and F1-Score...
(0.7607657417289221, 0.7599887450759708, 0.7598098230266797, None)
Micro average Test Precision, Recall and F1-Score...
(0.7599887450759707, 0.7599887450759707, 0.7599887450759707, None)
embeddings:
18764 7108 3554
[[ 5.19303307e-02  5.13174534e-02  1.94295049e-02 ...  5.40156960e-02
   1.06006647e-02 -7.32057262e-04]
 [-8.71305354e-04  8.56964663e-03  1.89820968e-03 ... -3.44945583e-05
  -8.79184809e-05  8.55358765e-02]
 [ 9.73471999e-02  8.97948816e-02  1.20384833e-02 ...  9.94052514e-02
   3.85239646e-02 -3.09494678e-02]
 ...
 [ 1.07786477e-01  9.94483232e-02  7.81449154e-02 ...  1.03435166e-01
  -1.36698866e-02 -3.21510131e-04]
 [ 1.83334723e-02  1.82865597e-02  5.55387000e-03 ...  1.22478902e-02
   9.91902221e-03  1.16007231e-01]
 [ 6.59184828e-02  5.96240498e-02  1.19284019e-02 ...  5.59228770e-02
   2.96835098e-02  1.94082290e-01]]
