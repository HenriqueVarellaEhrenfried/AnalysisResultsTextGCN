(6398, 300) (6398, 2) (3554, 300) (3554, 2) (25872, 300) (25872, 2)
29426
  (0, 10623)	6.18339884402439
  (0, 13919)	0.5465010749888104
  (0, 14559)	1.1115554606675069
  (0, 15700)	3.7569884009179986
  (0, 18226)	1.5195310253612764
  (0, 18467)	4.04333268052812
  (0, 19338)	7.328531148327393
  (0, 22286)	6.789534647594706
  (0, 23328)	1.9258537664551136
  (1, 7795)	5.147306912337615
  (1, 8008)	5.36241829195456
  (1, 9081)	2.030213781779356
  (1, 9548)	1.8885902192574975
  (1, 9842)	5.487127339313642
  (1, 10712)	7.077216720046487
  (1, 11167)	4.763581790865857
  (1, 11240)	1.9780280286087861
  (1, 12074)	8.581294116822761
  (1, 12204)	3.001693660045025
  (1, 13383)	8.175829008714597
  (1, 13384)	1.1367531124051018
  (1, 13919)	2.732505374944052
  (1, 14559)	0.5557777303337534
  (1, 15052)	2.8176716418105427
  (1, 15552)	3.1786167349504817
  :	:
  (29423, 20674)	1.2821726541119611
  (29423, 21548)	2.0777547265483562
  (29423, 21594)	4.71009310591487
  (29423, 22686)	1.3489223175957803
  (29423, 23714)	0.7656835847875705
  (29423, 24605)	6.18339884402439
  (29424, 9508)	7.665003384948606
  (29424, 12204)	1.5008468300225124
  (29424, 12719)	8.175829008714597
  (29424, 13792)	7.19499975570287
  (29424, 14440)	2.1419437457226627
  (29424, 14647)	4.23101618046346
  (29424, 14666)	6.384069539486542
  (29424, 14849)	2.730529451817914
  (29424, 15098)	3.941722504117337
  (29424, 15191)	8.175829008714597
  (29424, 16855)	7.665003384948606
  (29424, 18226)	1.5195310253612764
  (29424, 19164)	4.983981856234315
  (29424, 22983)	4.630050398241334
  (29424, 24152)	4.168495823482126
  (29425, 8194)	6.278709023828715
  (29425, 13921)	5.249089606647557
  (29425, 19699)	0.6764057181223682
  (29425, 22407)	4.855600689586108
(29426, 29426)
(29426, 29426)
29426
Tensor("graphconvolution_2/SparseTensorDenseMatMul/SparseTensorDenseMatMul:0", shape=(None, 2), dtype=float32)
Epoch: 0001 train_loss= 0.69315 train_acc= 0.51016 val_loss= 0.69158 val_acc= 0.74366 time= 0.36904
Epoch: 0002 train_loss= 0.69041 train_acc= 0.80853 val_loss= 0.68758 val_acc= 0.72254 time= 0.08107
Epoch: 0003 train_loss= 0.68399 train_acc= 0.79947 val_loss= 0.68106 val_acc= 0.71690 time= 0.07547
Epoch: 0004 train_loss= 0.67352 train_acc= 0.80072 val_loss= 0.67200 val_acc= 0.72535 time= 0.07557
Epoch: 0005 train_loss= 0.65854 train_acc= 0.81010 val_loss= 0.66039 val_acc= 0.73662 time= 0.07503
Epoch: 0006 train_loss= 0.63978 train_acc= 0.82323 val_loss= 0.64633 val_acc= 0.73380 time= 0.07638
Epoch: 0007 train_loss= 0.61558 train_acc= 0.83964 val_loss= 0.63014 val_acc= 0.74930 time= 0.07450
Epoch: 0008 train_loss= 0.58969 train_acc= 0.84964 val_loss= 0.61230 val_acc= 0.75211 time= 0.07500
Epoch: 0009 train_loss= 0.56053 train_acc= 0.85808 val_loss= 0.59349 val_acc= 0.75775 time= 0.07907
Epoch: 0010 train_loss= 0.52876 train_acc= 0.86152 val_loss= 0.57442 val_acc= 0.76620 time= 0.07600
Epoch: 0011 train_loss= 0.49661 train_acc= 0.86527 val_loss= 0.55606 val_acc= 0.77183 time= 0.07200
Epoch: 0012 train_loss= 0.46363 train_acc= 0.87012 val_loss= 0.53917 val_acc= 0.77606 time= 0.07708
Epoch: 0013 train_loss= 0.43118 train_acc= 0.87902 val_loss= 0.52448 val_acc= 0.78169 time= 0.07404
Epoch: 0014 train_loss= 0.40302 train_acc= 0.87856 val_loss= 0.51249 val_acc= 0.77606 time= 0.07068
Epoch: 0015 train_loss= 0.37273 train_acc= 0.88184 val_loss= 0.50357 val_acc= 0.77606 time= 0.07400
Epoch: 0016 train_loss= 0.34780 train_acc= 0.88199 val_loss= 0.49779 val_acc= 0.78169 time= 0.07300
Epoch: 0017 train_loss= 0.32285 train_acc= 0.88856 val_loss= 0.49510 val_acc= 0.78028 time= 0.07696
Epoch: 0018 train_loss= 0.30039 train_acc= 0.89497 val_loss= 0.49528 val_acc= 0.77887 time= 0.07112
Epoch: 0019 train_loss= 0.28310 train_acc= 0.89731 val_loss= 0.49816 val_acc= 0.77887 time= 0.07802
Epoch: 0020 train_loss= 0.26823 train_acc= 0.89934 val_loss= 0.50363 val_acc= 0.77746 time= 0.07199
Epoch: 0021 train_loss= 0.24968 train_acc= 0.90685 val_loss= 0.51150 val_acc= 0.77606 time= 0.07739
Epoch: 0022 train_loss= 0.23452 train_acc= 0.91435 val_loss= 0.52068 val_acc= 0.77746 time= 0.07703
Early stopping...
Optimization Finished!
Test set results: cost= 0.52445 accuracy= 0.76027 time= 0.03101
29426
Test Precision, Recall and F1-Score...
              precision    recall  f1-score   support

           0     0.7448    0.7918    0.7676      1777
           1     0.7778    0.7288    0.7525      1777

    accuracy                         0.7603      3554
   macro avg     0.7613    0.7603    0.7600      3554
weighted avg     0.7613    0.7603    0.7600      3554

Macro average Test Precision, Recall and F1-Score...
(0.7613081583436269, 0.7602701181767023, 0.7600318012497967, None)
Micro average Test Precision, Recall and F1-Score...
(0.7602701181767023, 0.7602701181767023, 0.7602701181767023, None)
embeddings:
18764 7108 3554
[[ 9.11161397e-03  2.72560660e-02  8.91933218e-03 ...  7.64816329e-02
   1.08167492e-01  8.12775940e-02]
 [ 9.69664529e-02 -1.16109056e-02  8.91973227e-02 ...  1.23403566e-02
   2.93261129e-02 -1.09436363e-02]
 [-4.26161774e-02  1.30881995e-01 -6.42691255e-02 ...  1.53578371e-01
   1.75181270e-01  1.39430150e-01]
 ...
 [-1.39028416e-04  1.24576934e-01 -7.89778773e-03 ... -2.62323208e-03
   1.19698495e-01  1.13771372e-01]
 [ 1.11388251e-01  5.02889715e-02  1.14038765e-01 ...  3.13333347e-02
   3.37823294e-02  1.42840389e-02]
 [ 2.07701713e-01  6.58857077e-02  2.10108861e-01 ...  7.38941357e-02
   4.64361124e-02  5.61454147e-02]]
