(6398, 300) (6398, 2) (3554, 300) (3554, 2) (25872, 300) (25872, 2)
29426
  (0, 10623)	6.18339884402439
  (0, 13919)	0.5465010749888104
  (0, 14559)	1.1115554606675069
  (0, 15700)	3.7569884009179986
  (0, 18226)	1.5195310253612764
  (0, 18467)	4.04333268052812
  (0, 19338)	7.328531148327393
  (0, 22286)	6.789534647594706
  (0, 23328)	1.9258537664551136
  (1, 7795)	5.147306912337615
  (1, 8008)	5.36241829195456
  (1, 9081)	2.030213781779356
  (1, 9548)	1.8885902192574975
  (1, 9842)	5.487127339313642
  (1, 10712)	7.077216720046487
  (1, 11167)	4.763581790865857
  (1, 11240)	1.9780280286087861
  (1, 12074)	8.581294116822761
  (1, 12204)	3.001693660045025
  (1, 13383)	8.175829008714597
  (1, 13384)	1.1367531124051018
  (1, 13919)	2.732505374944052
  (1, 14559)	0.5557777303337534
  (1, 15052)	2.8176716418105427
  (1, 15552)	3.1786167349504817
  :	:
  (29423, 20674)	1.2821726541119611
  (29423, 21548)	2.0777547265483562
  (29423, 21594)	4.71009310591487
  (29423, 22686)	1.3489223175957803
  (29423, 23714)	0.7656835847875705
  (29423, 24605)	6.18339884402439
  (29424, 9508)	7.665003384948606
  (29424, 12204)	1.5008468300225124
  (29424, 12719)	8.175829008714597
  (29424, 13792)	7.19499975570287
  (29424, 14440)	2.1419437457226627
  (29424, 14647)	4.23101618046346
  (29424, 14666)	6.384069539486542
  (29424, 14849)	2.730529451817914
  (29424, 15098)	3.941722504117337
  (29424, 15191)	8.175829008714597
  (29424, 16855)	7.665003384948606
  (29424, 18226)	1.5195310253612764
  (29424, 19164)	4.983981856234315
  (29424, 22983)	4.630050398241334
  (29424, 24152)	4.168495823482126
  (29425, 8194)	6.278709023828715
  (29425, 13921)	5.249089606647557
  (29425, 19699)	0.6764057181223682
  (29425, 22407)	4.855600689586108
(29426, 29426)
(29426, 29426)
29426
Tensor("graphconvolution_2/SparseTensorDenseMatMul/SparseTensorDenseMatMul:0", shape=(None, 2), dtype=float32)
Epoch: 0001 train_loss= 0.69313 train_acc= 0.50953 val_loss= 0.69169 val_acc= 0.68451 time= 0.37000
Epoch: 0002 train_loss= 0.69057 train_acc= 0.75852 val_loss= 0.68797 val_acc= 0.68451 time= 0.07900
Epoch: 0003 train_loss= 0.68441 train_acc= 0.76227 val_loss= 0.68174 val_acc= 0.68873 time= 0.07703
Epoch: 0004 train_loss= 0.67401 train_acc= 0.77962 val_loss= 0.67299 val_acc= 0.70563 time= 0.08001
Epoch: 0005 train_loss= 0.65975 train_acc= 0.79853 val_loss= 0.66168 val_acc= 0.72676 time= 0.07299
Epoch: 0006 train_loss= 0.64057 train_acc= 0.81713 val_loss= 0.64780 val_acc= 0.73803 time= 0.07905
Epoch: 0007 train_loss= 0.61853 train_acc= 0.83120 val_loss= 0.63169 val_acc= 0.74789 time= 0.07687
Epoch: 0008 train_loss= 0.59251 train_acc= 0.84730 val_loss= 0.61381 val_acc= 0.75775 time= 0.07299
Epoch: 0009 train_loss= 0.56167 train_acc= 0.85058 val_loss= 0.59482 val_acc= 0.76197 time= 0.07400
Epoch: 0010 train_loss= 0.53183 train_acc= 0.86543 val_loss= 0.57568 val_acc= 0.77465 time= 0.07607
Epoch: 0011 train_loss= 0.49672 train_acc= 0.86590 val_loss= 0.55723 val_acc= 0.78169 time= 0.07502
Epoch: 0012 train_loss= 0.46507 train_acc= 0.87183 val_loss= 0.54031 val_acc= 0.78451 time= 0.07398
Epoch: 0013 train_loss= 0.43343 train_acc= 0.87777 val_loss= 0.52550 val_acc= 0.78028 time= 0.07401
Epoch: 0014 train_loss= 0.40032 train_acc= 0.88012 val_loss= 0.51343 val_acc= 0.78169 time= 0.07499
Epoch: 0015 train_loss= 0.37451 train_acc= 0.88246 val_loss= 0.50445 val_acc= 0.78310 time= 0.07308
Epoch: 0016 train_loss= 0.34909 train_acc= 0.88356 val_loss= 0.49863 val_acc= 0.78451 time= 0.07464
Epoch: 0017 train_loss= 0.32398 train_acc= 0.89090 val_loss= 0.49594 val_acc= 0.78169 time= 0.07709
Epoch: 0018 train_loss= 0.30180 train_acc= 0.89653 val_loss= 0.49628 val_acc= 0.78310 time= 0.07601
Epoch: 0019 train_loss= 0.28189 train_acc= 0.90059 val_loss= 0.49915 val_acc= 0.78169 time= 0.07306
Epoch: 0020 train_loss= 0.26611 train_acc= 0.90059 val_loss= 0.50440 val_acc= 0.78169 time= 0.07600
Epoch: 0021 train_loss= 0.25126 train_acc= 0.90466 val_loss= 0.51163 val_acc= 0.78028 time= 0.07900
Epoch: 0022 train_loss= 0.23657 train_acc= 0.90903 val_loss= 0.52061 val_acc= 0.78169 time= 0.07208
Early stopping...
Optimization Finished!
Test set results: cost= 0.52181 accuracy= 0.76083 time= 0.03301
29426
Test Precision, Recall and F1-Score...
              precision    recall  f1-score   support

           0     0.7554    0.7715    0.7634      1777
           1     0.7665    0.7501    0.7582      1777

    accuracy                         0.7608      3554
   macro avg     0.7610    0.7608    0.7608      3554
weighted avg     0.7610    0.7608    0.7608      3554

Macro average Test Precision, Recall and F1-Score...
(0.7609521953815958, 0.7608328643781654, 0.7608055190272405, None)
Micro average Test Precision, Recall and F1-Score...
(0.7608328643781654, 0.7608328643781654, 0.7608328643781654, None)
embeddings:
18764 7108 3554
[[ 0.09216597  0.0714865   0.06707489 ... -0.01137099  0.0996091
  -0.01593978]
 [-0.00702892  0.02681104  0.02149447 ...  0.13167948  0.01020932
   0.00535072]
 [ 0.16219202  0.17245154  0.16936901 ... -0.02944704  0.16660097
  -0.00730571]
 ...
 [ 0.15115818  0.08959763  0.13193524 ... -0.10470252  0.07154453
  -0.06725969]
 [ 0.02596883  0.04856575  0.0257581  ...  0.12344615  0.03407098
   0.03777146]
 [ 0.07054367  0.11721495  0.08527587 ...  0.22325729  0.12025274
   0.08491431]]
