(6398, 300) (6398, 2) (3554, 300) (3554, 2) (25872, 300) (25872, 2)
29426
  (0, 10623)	6.18339884402439
  (0, 13919)	0.5465010749888104
  (0, 14559)	1.1115554606675069
  (0, 15700)	3.7569884009179986
  (0, 18226)	1.5195310253612764
  (0, 18467)	4.04333268052812
  (0, 19338)	7.328531148327393
  (0, 22286)	6.789534647594706
  (0, 23328)	1.9258537664551136
  (1, 7795)	5.147306912337615
  (1, 8008)	5.36241829195456
  (1, 9081)	2.030213781779356
  (1, 9548)	1.8885902192574975
  (1, 9842)	5.487127339313642
  (1, 10712)	7.077216720046487
  (1, 11167)	4.763581790865857
  (1, 11240)	1.9780280286087861
  (1, 12074)	8.581294116822761
  (1, 12204)	3.001693660045025
  (1, 13383)	8.175829008714597
  (1, 13384)	1.1367531124051018
  (1, 13919)	2.732505374944052
  (1, 14559)	0.5557777303337534
  (1, 15052)	2.8176716418105427
  (1, 15552)	3.1786167349504817
  :	:
  (29423, 20674)	1.2821726541119611
  (29423, 21548)	2.0777547265483562
  (29423, 21594)	4.71009310591487
  (29423, 22686)	1.3489223175957803
  (29423, 23714)	0.7656835847875705
  (29423, 24605)	6.18339884402439
  (29424, 9508)	7.665003384948606
  (29424, 12204)	1.5008468300225124
  (29424, 12719)	8.175829008714597
  (29424, 13792)	7.19499975570287
  (29424, 14440)	2.1419437457226627
  (29424, 14647)	4.23101618046346
  (29424, 14666)	6.384069539486542
  (29424, 14849)	2.730529451817914
  (29424, 15098)	3.941722504117337
  (29424, 15191)	8.175829008714597
  (29424, 16855)	7.665003384948606
  (29424, 18226)	1.5195310253612764
  (29424, 19164)	4.983981856234315
  (29424, 22983)	4.630050398241334
  (29424, 24152)	4.168495823482126
  (29425, 8194)	6.278709023828715
  (29425, 13921)	5.249089606647557
  (29425, 19699)	0.6764057181223682
  (29425, 22407)	4.855600689586108
(29426, 29426)
(29426, 29426)
29426
Tensor("graphconvolution_2/SparseTensorDenseMatMul/SparseTensorDenseMatMul:0", shape=(None, 2), dtype=float32)
Epoch: 0001 train_loss= 0.69314 train_acc= 0.50063 val_loss= 0.69158 val_acc= 0.70282 time= 0.36915
Epoch: 0002 train_loss= 0.69041 train_acc= 0.79150 val_loss= 0.68765 val_acc= 0.70000 time= 0.07697
Epoch: 0003 train_loss= 0.68397 train_acc= 0.78712 val_loss= 0.68116 val_acc= 0.70986 time= 0.07601
Epoch: 0004 train_loss= 0.67368 train_acc= 0.79791 val_loss= 0.67216 val_acc= 0.72676 time= 0.07500
Epoch: 0005 train_loss= 0.65899 train_acc= 0.81338 val_loss= 0.66066 val_acc= 0.73944 time= 0.07600
Epoch: 0006 train_loss= 0.63931 train_acc= 0.83307 val_loss= 0.64667 val_acc= 0.73944 time= 0.07271
Epoch: 0007 train_loss= 0.61752 train_acc= 0.83292 val_loss= 0.63042 val_acc= 0.75634 time= 0.07201
Epoch: 0008 train_loss= 0.59095 train_acc= 0.85292 val_loss= 0.61251 val_acc= 0.76056 time= 0.07197
Epoch: 0009 train_loss= 0.56051 train_acc= 0.86183 val_loss= 0.59365 val_acc= 0.77042 time= 0.07203
Epoch: 0010 train_loss= 0.52985 train_acc= 0.86636 val_loss= 0.57469 val_acc= 0.77324 time= 0.07197
Epoch: 0011 train_loss= 0.49612 train_acc= 0.86480 val_loss= 0.55637 val_acc= 0.77183 time= 0.07224
Epoch: 0012 train_loss= 0.46410 train_acc= 0.86855 val_loss= 0.53959 val_acc= 0.77606 time= 0.07197
Epoch: 0013 train_loss= 0.43151 train_acc= 0.87402 val_loss= 0.52492 val_acc= 0.77183 time= 0.07208
Epoch: 0014 train_loss= 0.40142 train_acc= 0.87746 val_loss= 0.51290 val_acc= 0.77324 time= 0.07597
Epoch: 0015 train_loss= 0.37189 train_acc= 0.88278 val_loss= 0.50396 val_acc= 0.77746 time= 0.07417
Epoch: 0016 train_loss= 0.34522 train_acc= 0.88762 val_loss= 0.49817 val_acc= 0.78028 time= 0.07240
Epoch: 0017 train_loss= 0.32272 train_acc= 0.89090 val_loss= 0.49553 val_acc= 0.78028 time= 0.07400
Epoch: 0018 train_loss= 0.30272 train_acc= 0.89465 val_loss= 0.49579 val_acc= 0.78169 time= 0.07497
Epoch: 0019 train_loss= 0.28179 train_acc= 0.89559 val_loss= 0.49875 val_acc= 0.78169 time= 0.07503
Epoch: 0020 train_loss= 0.26579 train_acc= 0.89872 val_loss= 0.50422 val_acc= 0.78169 time= 0.07300
Epoch: 0021 train_loss= 0.25249 train_acc= 0.90216 val_loss= 0.51176 val_acc= 0.78310 time= 0.07212
Epoch: 0022 train_loss= 0.23573 train_acc= 0.90700 val_loss= 0.52250 val_acc= 0.78451 time= 0.07200
Early stopping...
Optimization Finished!
Test set results: cost= 0.52617 accuracy= 0.75943 time= 0.03101
29426
Test Precision, Recall and F1-Score...
              precision    recall  f1-score   support

           0     0.7437    0.7918    0.7670      1777
           1     0.7774    0.7271    0.7514      1777

    accuracy                         0.7594      3554
   macro avg     0.7605    0.7594    0.7592      3554
weighted avg     0.7605    0.7594    0.7592      3554

Macro average Test Precision, Recall and F1-Score...
(0.7605170799591923, 0.7594259988745076, 0.7591738456742998, None)
Micro average Test Precision, Recall and F1-Score...
(0.7594259988745076, 0.7594259988745076, 0.7594259988745077, None)
embeddings:
18764 7108 3554
[[ 0.10192268 -0.00542613  0.07019432 ...  0.06394224 -0.01915535
   0.07451879]
 [-0.00950237  0.09696649  0.01113803 ...  0.0205626   0.09562507
   0.04055909]
 [ 0.17464572 -0.04626607  0.14894027 ...  0.16073586 -0.04088967
   0.14055552]
 ...
 [ 0.10752513 -0.08264172  0.13508731 ...  0.07092956 -0.06618386
   0.12702172]
 [ 0.02737119  0.14642522  0.04988335 ...  0.05107409  0.11501739
   0.01575236]
 [ 0.10541815  0.18706992  0.0538977  ...  0.07516307  0.2037035
   0.07892381]]
