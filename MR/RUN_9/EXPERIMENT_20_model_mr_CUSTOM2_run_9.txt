(6398, 300) (6398, 2) (3554, 300) (3554, 2) (25872, 300) (25872, 2)
29426
  (0, 10623)	6.18339884402439
  (0, 13919)	0.5465010749888104
  (0, 14559)	1.1115554606675069
  (0, 15700)	3.7569884009179986
  (0, 18226)	1.5195310253612764
  (0, 18467)	4.04333268052812
  (0, 19338)	7.328531148327393
  (0, 22286)	6.789534647594706
  (0, 23328)	1.9258537664551136
  (1, 7795)	5.147306912337615
  (1, 8008)	5.36241829195456
  (1, 9081)	2.030213781779356
  (1, 9548)	1.8885902192574975
  (1, 9842)	5.487127339313642
  (1, 10712)	7.077216720046487
  (1, 11167)	4.763581790865857
  (1, 11240)	1.9780280286087861
  (1, 12074)	8.581294116822761
  (1, 12204)	3.001693660045025
  (1, 13383)	8.175829008714597
  (1, 13384)	1.1367531124051018
  (1, 13919)	2.732505374944052
  (1, 14559)	0.5557777303337534
  (1, 15052)	2.8176716418105427
  (1, 15552)	3.1786167349504817
  :	:
  (29423, 20674)	1.2821726541119611
  (29423, 21548)	2.0777547265483562
  (29423, 21594)	4.71009310591487
  (29423, 22686)	1.3489223175957803
  (29423, 23714)	0.7656835847875705
  (29423, 24605)	6.18339884402439
  (29424, 9508)	7.665003384948606
  (29424, 12204)	1.5008468300225124
  (29424, 12719)	8.175829008714597
  (29424, 13792)	7.19499975570287
  (29424, 14440)	2.1419437457226627
  (29424, 14647)	4.23101618046346
  (29424, 14666)	6.384069539486542
  (29424, 14849)	2.730529451817914
  (29424, 15098)	3.941722504117337
  (29424, 15191)	8.175829008714597
  (29424, 16855)	7.665003384948606
  (29424, 18226)	1.5195310253612764
  (29424, 19164)	4.983981856234315
  (29424, 22983)	4.630050398241334
  (29424, 24152)	4.168495823482126
  (29425, 8194)	6.278709023828715
  (29425, 13921)	5.249089606647557
  (29425, 19699)	0.6764057181223682
  (29425, 22407)	4.855600689586108
(29426, 29426)
(29426, 29426)
29426
Tensor("graphconvolution_2/SparseTensorDenseMatMul/SparseTensorDenseMatMul:0", shape=(None, 2), dtype=float32)
Epoch: 0001 train_loss= 0.69316 train_acc= 0.48984 val_loss= 0.68285 val_acc= 0.54366 time= 0.36794
Epoch: 0002 train_loss= 0.67432 train_acc= 0.58940 val_loss= 0.66276 val_acc= 0.51972 time= 0.07700
Epoch: 0003 train_loss= 0.61365 train_acc= 0.57158 val_loss= 0.59032 val_acc= 0.72817 time= 0.07505
Epoch: 0004 train_loss= 0.51358 train_acc= 0.85324 val_loss= 0.53600 val_acc= 0.73803 time= 0.07400
Epoch: 0005 train_loss= 0.40492 train_acc= 0.86887 val_loss= 0.51603 val_acc= 0.75775 time= 0.07393
Epoch: 0006 train_loss= 0.32265 train_acc= 0.87183 val_loss= 0.51176 val_acc= 0.76197 time= 0.07596
Epoch: 0007 train_loss= 0.25299 train_acc= 0.89716 val_loss= 0.54333 val_acc= 0.76620 time= 0.07604
Epoch: 0008 train_loss= 0.20970 train_acc= 0.91263 val_loss= 0.60903 val_acc= 0.76761 time= 0.07500
Early stopping...
Optimization Finished!
Test set results: cost= 0.60153 accuracy= 0.76252 time= 0.03199
29426
Test Precision, Recall and F1-Score...
              precision    recall  f1-score   support

           0     0.7871    0.7198    0.7519      1777
           1     0.7418    0.8053    0.7723      1777

    accuracy                         0.7625      3554
   macro avg     0.7645    0.7625    0.7621      3554
weighted avg     0.7645    0.7625    0.7621      3554

Macro average Test Precision, Recall and F1-Score...
(0.7644560354109343, 0.7625211029825549, 0.7620859194283671, None)
Micro average Test Precision, Recall and F1-Score...
(0.7625211029825548, 0.7625211029825548, 0.7625211029825548, None)
embeddings:
18764 7108 3554
[[-0.02281272 -0.00591132  0.0302431  ... -0.02035472 -0.02886202
   0.03963038]
 [-0.09395973 -0.09997547 -0.0401751  ... -0.01460108  0.21520606
   0.23734643]
 [ 0.08601593 -0.10488121  0.22594193 ... -0.05217238 -0.03464896
  -0.04843029]
 ...
 [ 0.3321834  -0.01832053 -0.00980693 ... -0.00612595 -0.00062055
  -0.00121199]
 [-0.04589321 -0.07517505  0.0358405  ...  0.06381819  0.217391
   0.16512586]
 [-0.12170322 -0.22802539  0.08234817 ...  0.07832899  0.4236029
   0.38339803]]
