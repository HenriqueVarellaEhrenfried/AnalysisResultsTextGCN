(6398, 300) (6398, 2) (3554, 300) (3554, 2) (25872, 300) (25872, 2)
29426
  (0, 10623)	6.18339884402439
  (0, 13919)	0.5465010749888104
  (0, 14559)	1.1115554606675069
  (0, 15700)	3.7569884009179986
  (0, 18226)	1.5195310253612764
  (0, 18467)	4.04333268052812
  (0, 19338)	7.328531148327393
  (0, 22286)	6.789534647594706
  (0, 23328)	1.9258537664551136
  (1, 7795)	5.147306912337615
  (1, 8008)	5.36241829195456
  (1, 9081)	2.030213781779356
  (1, 9548)	1.8885902192574975
  (1, 9842)	5.487127339313642
  (1, 10712)	7.077216720046487
  (1, 11167)	4.763581790865857
  (1, 11240)	1.9780280286087861
  (1, 12074)	8.581294116822761
  (1, 12204)	3.001693660045025
  (1, 13383)	8.175829008714597
  (1, 13384)	1.1367531124051018
  (1, 13919)	2.732505374944052
  (1, 14559)	0.5557777303337534
  (1, 15052)	2.8176716418105427
  (1, 15552)	3.1786167349504817
  :	:
  (29423, 20674)	1.2821726541119611
  (29423, 21548)	2.0777547265483562
  (29423, 21594)	4.71009310591487
  (29423, 22686)	1.3489223175957803
  (29423, 23714)	0.7656835847875705
  (29423, 24605)	6.18339884402439
  (29424, 9508)	7.665003384948606
  (29424, 12204)	1.5008468300225124
  (29424, 12719)	8.175829008714597
  (29424, 13792)	7.19499975570287
  (29424, 14440)	2.1419437457226627
  (29424, 14647)	4.23101618046346
  (29424, 14666)	6.384069539486542
  (29424, 14849)	2.730529451817914
  (29424, 15098)	3.941722504117337
  (29424, 15191)	8.175829008714597
  (29424, 16855)	7.665003384948606
  (29424, 18226)	1.5195310253612764
  (29424, 19164)	4.983981856234315
  (29424, 22983)	4.630050398241334
  (29424, 24152)	4.168495823482126
  (29425, 8194)	6.278709023828715
  (29425, 13921)	5.249089606647557
  (29425, 19699)	0.6764057181223682
  (29425, 22407)	4.855600689586108
(29426, 29426)
(29426, 29426)
29426
Tensor("graphconvolution_2/SparseTensorDenseMatMul/SparseTensorDenseMatMul:0", shape=(None, 2), dtype=float32)
Epoch: 0001 train_loss= 0.69317 train_acc= 0.49500 val_loss= 0.69167 val_acc= 0.75634 time= 0.36619
Epoch: 0002 train_loss= 0.69066 train_acc= 0.82073 val_loss= 0.68786 val_acc= 0.74507 time= 0.07600
Epoch: 0003 train_loss= 0.68457 train_acc= 0.82432 val_loss= 0.68145 val_acc= 0.75211 time= 0.08500
Epoch: 0004 train_loss= 0.67466 train_acc= 0.82776 val_loss= 0.67245 val_acc= 0.75493 time= 0.07491
Epoch: 0005 train_loss= 0.66020 train_acc= 0.83870 val_loss= 0.66084 val_acc= 0.76056 time= 0.07399
Epoch: 0006 train_loss= 0.64154 train_acc= 0.84292 val_loss= 0.64672 val_acc= 0.75775 time= 0.08181
Epoch: 0007 train_loss= 0.61784 train_acc= 0.85183 val_loss= 0.63040 val_acc= 0.76338 time= 0.07299
Epoch: 0008 train_loss= 0.59169 train_acc= 0.85386 val_loss= 0.61239 val_acc= 0.76479 time= 0.07297
Epoch: 0009 train_loss= 0.56171 train_acc= 0.86308 val_loss= 0.59345 val_acc= 0.77042 time= 0.08010
Epoch: 0010 train_loss= 0.53062 train_acc= 0.86433 val_loss= 0.57437 val_acc= 0.76761 time= 0.07200
Epoch: 0011 train_loss= 0.49556 train_acc= 0.86871 val_loss= 0.55598 val_acc= 0.77042 time= 0.07600
Epoch: 0012 train_loss= 0.46438 train_acc= 0.87152 val_loss= 0.53915 val_acc= 0.77042 time= 0.08201
Epoch: 0013 train_loss= 0.43173 train_acc= 0.87293 val_loss= 0.52449 val_acc= 0.77465 time= 0.07095
Epoch: 0014 train_loss= 0.40085 train_acc= 0.87793 val_loss= 0.51263 val_acc= 0.77606 time= 0.07300
Epoch: 0015 train_loss= 0.37062 train_acc= 0.88168 val_loss= 0.50382 val_acc= 0.77324 time= 0.07705
Epoch: 0016 train_loss= 0.34696 train_acc= 0.88543 val_loss= 0.49820 val_acc= 0.77324 time= 0.07099
Epoch: 0017 train_loss= 0.32278 train_acc= 0.89059 val_loss= 0.49563 val_acc= 0.77324 time= 0.07201
Epoch: 0018 train_loss= 0.30215 train_acc= 0.89481 val_loss= 0.49600 val_acc= 0.77183 time= 0.08099
Epoch: 0019 train_loss= 0.28404 train_acc= 0.89622 val_loss= 0.49918 val_acc= 0.77606 time= 0.07309
Epoch: 0020 train_loss= 0.26737 train_acc= 0.90341 val_loss= 0.50470 val_acc= 0.77606 time= 0.07195
Epoch: 0021 train_loss= 0.25247 train_acc= 0.90528 val_loss= 0.51192 val_acc= 0.77887 time= 0.08109
Epoch: 0022 train_loss= 0.23815 train_acc= 0.90841 val_loss= 0.52122 val_acc= 0.78028 time= 0.07102
Early stopping...
Optimization Finished!
Test set results: cost= 0.52581 accuracy= 0.76140 time= 0.03119
29426
Test Precision, Recall and F1-Score...
              precision    recall  f1-score   support

           0     0.7548    0.7743    0.7644      1777
           1     0.7683    0.7485    0.7583      1777

    accuracy                         0.7614      3554
   macro avg     0.7616    0.7614    0.7614      3554
weighted avg     0.7616    0.7614    0.7614      3554

Macro average Test Precision, Recall and F1-Score...
(0.7615708897130289, 0.7613956105796286, 0.7613556315722794, None)
Micro average Test Precision, Recall and F1-Score...
(0.7613956105796286, 0.7613956105796286, 0.7613956105796287, None)
embeddings:
18764 7108 3554
[[ 0.08651324  0.00732987  0.00256003 ...  0.0949329   0.07173045
  -0.01507498]
 [ 0.03098899  0.06853303  0.14768076 ...  0.01630706  0.00102482
   0.13611178]
 [ 0.17215785 -0.04873653 -0.05931552 ...  0.16842632  0.1324334
  -0.05121726]
 ...
 [ 0.09200184 -0.07506978 -0.01021131 ...  0.14923818  0.15344334
  -0.00143974]
 [ 0.03528238  0.08498586  0.13100307 ...  0.06161175  0.04859123
   0.10007162]
 [ 0.12481216  0.20134963  0.16827847 ...  0.14517517  0.09014575
   0.16542348]]
