(6398, 300) (6398, 2) (3554, 300) (3554, 2) (25872, 300) (25872, 2)
29426
  (0, 10623)	6.18339884402439
  (0, 13919)	0.5465010749888104
  (0, 14559)	1.1115554606675069
  (0, 15700)	3.7569884009179986
  (0, 18226)	1.5195310253612764
  (0, 18467)	4.04333268052812
  (0, 19338)	7.328531148327393
  (0, 22286)	6.789534647594706
  (0, 23328)	1.9258537664551136
  (1, 7795)	5.147306912337615
  (1, 8008)	5.36241829195456
  (1, 9081)	2.030213781779356
  (1, 9548)	1.8885902192574975
  (1, 9842)	5.487127339313642
  (1, 10712)	7.077216720046487
  (1, 11167)	4.763581790865857
  (1, 11240)	1.9780280286087861
  (1, 12074)	8.581294116822761
  (1, 12204)	3.001693660045025
  (1, 13383)	8.175829008714597
  (1, 13384)	1.1367531124051018
  (1, 13919)	2.732505374944052
  (1, 14559)	0.5557777303337534
  (1, 15052)	2.8176716418105427
  (1, 15552)	3.1786167349504817
  :	:
  (29423, 20674)	1.2821726541119611
  (29423, 21548)	2.0777547265483562
  (29423, 21594)	4.71009310591487
  (29423, 22686)	1.3489223175957803
  (29423, 23714)	0.7656835847875705
  (29423, 24605)	6.18339884402439
  (29424, 9508)	7.665003384948606
  (29424, 12204)	1.5008468300225124
  (29424, 12719)	8.175829008714597
  (29424, 13792)	7.19499975570287
  (29424, 14440)	2.1419437457226627
  (29424, 14647)	4.23101618046346
  (29424, 14666)	6.384069539486542
  (29424, 14849)	2.730529451817914
  (29424, 15098)	3.941722504117337
  (29424, 15191)	8.175829008714597
  (29424, 16855)	7.665003384948606
  (29424, 18226)	1.5195310253612764
  (29424, 19164)	4.983981856234315
  (29424, 22983)	4.630050398241334
  (29424, 24152)	4.168495823482126
  (29425, 8194)	6.278709023828715
  (29425, 13921)	5.249089606647557
  (29425, 19699)	0.6764057181223682
  (29425, 22407)	4.855600689586108
(29426, 29426)
(29426, 29426)
29426
Tensor("graphconvolution_2/SparseTensorDenseMatMul/SparseTensorDenseMatMul:0", shape=(None, 2), dtype=float32)
Epoch: 0001 train_loss= 0.69314 train_acc= 0.50156 val_loss= 0.68218 val_acc= 0.48451 time= 0.36877
Epoch: 0002 train_loss= 0.67266 train_acc= 0.50375 val_loss= 0.68054 val_acc= 0.49859 time= 0.07672
Epoch: 0003 train_loss= 0.62868 train_acc= 0.52876 val_loss= 0.61039 val_acc= 0.72113 time= 0.08297
Epoch: 0004 train_loss= 0.54508 train_acc= 0.85339 val_loss= 0.57742 val_acc= 0.68451 time= 0.07404
Epoch: 0005 train_loss= 0.46943 train_acc= 0.80791 val_loss= 0.51273 val_acc= 0.77042 time= 0.08196
Epoch: 0006 train_loss= 0.35323 train_acc= 0.88637 val_loss= 0.52466 val_acc= 0.76056 time= 0.07404
Epoch: 0007 train_loss= 0.30513 train_acc= 0.87574 val_loss= 0.52237 val_acc= 0.76761 time= 0.07299
Epoch: 0008 train_loss= 0.23855 train_acc= 0.89950 val_loss= 0.57454 val_acc= 0.75352 time= 0.07700
Early stopping...
Optimization Finished!
Test set results: cost= 0.57979 accuracy= 0.74761 time= 0.03100
29426
Test Precision, Recall and F1-Score...
              precision    recall  f1-score   support

           0     0.7077    0.8436    0.7697      1777
           1     0.8064    0.6517    0.7208      1777

    accuracy                         0.7476      3554
   macro avg     0.7571    0.7476    0.7453      3554
weighted avg     0.7571    0.7476    0.7453      3554

Macro average Test Precision, Recall and F1-Score...
(0.7570749195777801, 0.7476083286437817, 0.7452632058386042, None)
Micro average Test Precision, Recall and F1-Score...
(0.7476083286437817, 0.7476083286437817, 0.7476083286437816, None)
embeddings:
18764 7108 3554
[[ 0.09523962  0.10843226  0.0436864  ...  0.09251209 -0.04356372
   0.03097927]
 [-0.00539523 -0.02501386 -0.02180537 ...  0.00479639  0.01455345
  -0.02322773]
 [ 0.22973704  0.24693912  0.20851845 ...  0.18326418 -0.04564739
   0.12461472]
 ...
 [ 0.3049742   0.47521272  0.47612303 ...  0.3274052  -0.00051126
   0.28304318]
 [ 0.00746004 -0.00398191 -0.02923407 ... -0.03555528 -0.0186357
  -0.00386863]
 [ 0.03411085  0.03514625 -0.05603885 ...  0.02641288  0.00056577
  -0.01998153]]
