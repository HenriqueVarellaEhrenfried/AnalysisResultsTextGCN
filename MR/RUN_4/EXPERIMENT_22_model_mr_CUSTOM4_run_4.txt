(6398, 300) (6398, 2) (3554, 300) (3554, 2) (25872, 300) (25872, 2)
29426
  (0, 10623)	6.18339884402439
  (0, 13919)	0.5465010749888104
  (0, 14559)	1.1115554606675069
  (0, 15700)	3.7569884009179986
  (0, 18226)	1.5195310253612764
  (0, 18467)	4.04333268052812
  (0, 19338)	7.328531148327393
  (0, 22286)	6.789534647594706
  (0, 23328)	1.9258537664551136
  (1, 7795)	5.147306912337615
  (1, 8008)	5.36241829195456
  (1, 9081)	2.030213781779356
  (1, 9548)	1.8885902192574975
  (1, 9842)	5.487127339313642
  (1, 10712)	7.077216720046487
  (1, 11167)	4.763581790865857
  (1, 11240)	1.9780280286087861
  (1, 12074)	8.581294116822761
  (1, 12204)	3.001693660045025
  (1, 13383)	8.175829008714597
  (1, 13384)	1.1367531124051018
  (1, 13919)	2.732505374944052
  (1, 14559)	0.5557777303337534
  (1, 15052)	2.8176716418105427
  (1, 15552)	3.1786167349504817
  :	:
  (29423, 20674)	1.2821726541119611
  (29423, 21548)	2.0777547265483562
  (29423, 21594)	4.71009310591487
  (29423, 22686)	1.3489223175957803
  (29423, 23714)	0.7656835847875705
  (29423, 24605)	6.18339884402439
  (29424, 9508)	7.665003384948606
  (29424, 12204)	1.5008468300225124
  (29424, 12719)	8.175829008714597
  (29424, 13792)	7.19499975570287
  (29424, 14440)	2.1419437457226627
  (29424, 14647)	4.23101618046346
  (29424, 14666)	6.384069539486542
  (29424, 14849)	2.730529451817914
  (29424, 15098)	3.941722504117337
  (29424, 15191)	8.175829008714597
  (29424, 16855)	7.665003384948606
  (29424, 18226)	1.5195310253612764
  (29424, 19164)	4.983981856234315
  (29424, 22983)	4.630050398241334
  (29424, 24152)	4.168495823482126
  (29425, 8194)	6.278709023828715
  (29425, 13921)	5.249089606647557
  (29425, 19699)	0.6764057181223682
  (29425, 22407)	4.855600689586108
(29426, 29426)
(29426, 29426)
29426
Tensor("graphconvolution_2/SparseTensorDenseMatMul/SparseTensorDenseMatMul:0", shape=(None, 2), dtype=float32)
Epoch: 0001 train_loss= 0.69317 train_acc= 0.49312 val_loss= 0.69176 val_acc= 0.71549 time= 0.36710
Epoch: 0002 train_loss= 0.69072 train_acc= 0.79212 val_loss= 0.68810 val_acc= 0.71831 time= 0.07604
Epoch: 0003 train_loss= 0.68482 train_acc= 0.79666 val_loss= 0.68190 val_acc= 0.72113 time= 0.07408
Epoch: 0004 train_loss= 0.67474 train_acc= 0.80619 val_loss= 0.67319 val_acc= 0.73239 time= 0.08796
Epoch: 0005 train_loss= 0.66028 train_acc= 0.81400 val_loss= 0.66186 val_acc= 0.72958 time= 0.07500
Epoch: 0006 train_loss= 0.64158 train_acc= 0.82448 val_loss= 0.64795 val_acc= 0.73662 time= 0.07311
Epoch: 0007 train_loss= 0.61925 train_acc= 0.84058 val_loss= 0.63180 val_acc= 0.75775 time= 0.07157
Epoch: 0008 train_loss= 0.59177 train_acc= 0.85261 val_loss= 0.61386 val_acc= 0.76056 time= 0.07200
Epoch: 0009 train_loss= 0.56278 train_acc= 0.85292 val_loss= 0.59490 val_acc= 0.77465 time= 0.07403
Epoch: 0010 train_loss= 0.52993 train_acc= 0.86465 val_loss= 0.57572 val_acc= 0.77606 time= 0.08900
Epoch: 0011 train_loss= 0.49978 train_acc= 0.86933 val_loss= 0.55720 val_acc= 0.77465 time= 0.07205
Epoch: 0012 train_loss= 0.46633 train_acc= 0.86824 val_loss= 0.54020 val_acc= 0.77887 time= 0.07199
Epoch: 0013 train_loss= 0.43305 train_acc= 0.87762 val_loss= 0.52535 val_acc= 0.77465 time= 0.07297
Epoch: 0014 train_loss= 0.40166 train_acc= 0.87902 val_loss= 0.51334 val_acc= 0.77746 time= 0.07104
Epoch: 0015 train_loss= 0.37298 train_acc= 0.88074 val_loss= 0.50435 val_acc= 0.77465 time= 0.07302
Epoch: 0016 train_loss= 0.34954 train_acc= 0.88528 val_loss= 0.49843 val_acc= 0.77606 time= 0.08500
Epoch: 0017 train_loss= 0.32486 train_acc= 0.88481 val_loss= 0.49558 val_acc= 0.78028 time= 0.07200
Epoch: 0018 train_loss= 0.30593 train_acc= 0.89309 val_loss= 0.49602 val_acc= 0.77746 time= 0.07305
Epoch: 0019 train_loss= 0.28336 train_acc= 0.89591 val_loss= 0.49935 val_acc= 0.77606 time= 0.07399
Epoch: 0020 train_loss= 0.26569 train_acc= 0.90059 val_loss= 0.50469 val_acc= 0.77746 time= 0.07397
Epoch: 0021 train_loss= 0.24801 train_acc= 0.90435 val_loss= 0.51149 val_acc= 0.78310 time= 0.08809
Epoch: 0022 train_loss= 0.23833 train_acc= 0.91185 val_loss= 0.52032 val_acc= 0.78451 time= 0.07300
Early stopping...
Optimization Finished!
Test set results: cost= 0.52201 accuracy= 0.76083 time= 0.03101
29426
Test Precision, Recall and F1-Score...
              precision    recall  f1-score   support

           0     0.7571    0.7681    0.7626      1777
           1     0.7647    0.7535    0.7591      1777

    accuracy                         0.7608      3554
   macro avg     0.7609    0.7608    0.7608      3554
weighted avg     0.7609    0.7608    0.7608      3554

Macro average Test Precision, Recall and F1-Score...
(0.7608887148869531, 0.7608328643781654, 0.7608200635934076, None)
Micro average Test Precision, Recall and F1-Score...
(0.7608328643781654, 0.7608328643781654, 0.7608328643781654, None)
embeddings:
18764 7108 3554
[[-0.01032474  0.09609408  0.04615739 ...  0.0391256   0.06624287
   0.05421414]
 [ 0.06435904  0.01127914  0.03663151 ...  0.01847248  0.01256317
   0.01979018]
 [-0.0502455   0.12202092  0.16927905 ...  0.16697074  0.16489749
   0.17311803]
 ...
 [-0.00093874  0.1023163   0.14236529 ...  0.05398597  0.11498121
  -0.00304516]
 [ 0.10405415  0.04887404  0.02374803 ...  0.01569806  0.01709517
   0.01460173]
 [ 0.21181859  0.09342548  0.05151094 ...  0.08177142  0.07963966
   0.06767258]]
