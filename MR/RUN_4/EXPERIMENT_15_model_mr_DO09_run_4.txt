(6398, 300) (6398, 2) (3554, 300) (3554, 2) (25872, 300) (25872, 2)
29426
  (0, 10623)	6.18339884402439
  (0, 13919)	0.5465010749888104
  (0, 14559)	1.1115554606675069
  (0, 15700)	3.7569884009179986
  (0, 18226)	1.5195310253612764
  (0, 18467)	4.04333268052812
  (0, 19338)	7.328531148327393
  (0, 22286)	6.789534647594706
  (0, 23328)	1.9258537664551136
  (1, 7795)	5.147306912337615
  (1, 8008)	5.36241829195456
  (1, 9081)	2.030213781779356
  (1, 9548)	1.8885902192574975
  (1, 9842)	5.487127339313642
  (1, 10712)	7.077216720046487
  (1, 11167)	4.763581790865857
  (1, 11240)	1.9780280286087861
  (1, 12074)	8.581294116822761
  (1, 12204)	3.001693660045025
  (1, 13383)	8.175829008714597
  (1, 13384)	1.1367531124051018
  (1, 13919)	2.732505374944052
  (1, 14559)	0.5557777303337534
  (1, 15052)	2.8176716418105427
  (1, 15552)	3.1786167349504817
  :	:
  (29423, 20674)	1.2821726541119611
  (29423, 21548)	2.0777547265483562
  (29423, 21594)	4.71009310591487
  (29423, 22686)	1.3489223175957803
  (29423, 23714)	0.7656835847875705
  (29423, 24605)	6.18339884402439
  (29424, 9508)	7.665003384948606
  (29424, 12204)	1.5008468300225124
  (29424, 12719)	8.175829008714597
  (29424, 13792)	7.19499975570287
  (29424, 14440)	2.1419437457226627
  (29424, 14647)	4.23101618046346
  (29424, 14666)	6.384069539486542
  (29424, 14849)	2.730529451817914
  (29424, 15098)	3.941722504117337
  (29424, 15191)	8.175829008714597
  (29424, 16855)	7.665003384948606
  (29424, 18226)	1.5195310253612764
  (29424, 19164)	4.983981856234315
  (29424, 22983)	4.630050398241334
  (29424, 24152)	4.168495823482126
  (29425, 8194)	6.278709023828715
  (29425, 13921)	5.249089606647557
  (29425, 19699)	0.6764057181223682
  (29425, 22407)	4.855600689586108
(29426, 29426)
(29426, 29426)
29426
Tensor("graphconvolution_2/SparseTensorDenseMatMul/SparseTensorDenseMatMul:0", shape=(None, 2), dtype=float32)
Epoch: 0001 train_loss= 0.69313 train_acc= 0.49828 val_loss= 0.69165 val_acc= 0.68592 time= 0.37803
Epoch: 0002 train_loss= 0.69051 train_acc= 0.76774 val_loss= 0.68783 val_acc= 0.68169 time= 0.07600
Epoch: 0003 train_loss= 0.68417 train_acc= 0.76586 val_loss= 0.68153 val_acc= 0.67746 time= 0.07501
Epoch: 0004 train_loss= 0.67365 train_acc= 0.77931 val_loss= 0.67279 val_acc= 0.69577 time= 0.07500
Epoch: 0005 train_loss= 0.65940 train_acc= 0.78603 val_loss= 0.66159 val_acc= 0.70845 time= 0.07201
Epoch: 0006 train_loss= 0.64084 train_acc= 0.80510 val_loss= 0.64797 val_acc= 0.73239 time= 0.09100
Epoch: 0007 train_loss= 0.61829 train_acc= 0.82369 val_loss= 0.63214 val_acc= 0.74225 time= 0.07199
Epoch: 0008 train_loss= 0.59141 train_acc= 0.83620 val_loss= 0.61448 val_acc= 0.75352 time= 0.07297
Epoch: 0009 train_loss= 0.56234 train_acc= 0.85324 val_loss= 0.59570 val_acc= 0.75634 time= 0.07503
Epoch: 0010 train_loss= 0.53071 train_acc= 0.85871 val_loss= 0.57665 val_acc= 0.77042 time= 0.07100
Epoch: 0011 train_loss= 0.49802 train_acc= 0.87293 val_loss= 0.55830 val_acc= 0.78028 time= 0.07300
Epoch: 0012 train_loss= 0.46582 train_acc= 0.87449 val_loss= 0.54147 val_acc= 0.77746 time= 0.08700
Epoch: 0013 train_loss= 0.43534 train_acc= 0.87449 val_loss= 0.52681 val_acc= 0.78028 time= 0.07647
Epoch: 0014 train_loss= 0.40164 train_acc= 0.87996 val_loss= 0.51474 val_acc= 0.78169 time= 0.07200
Epoch: 0015 train_loss= 0.37635 train_acc= 0.88184 val_loss= 0.50574 val_acc= 0.77887 time= 0.07199
Epoch: 0016 train_loss= 0.34621 train_acc= 0.88731 val_loss= 0.49993 val_acc= 0.77887 time= 0.07200
Epoch: 0017 train_loss= 0.32232 train_acc= 0.89106 val_loss= 0.49735 val_acc= 0.77887 time= 0.07252
Epoch: 0018 train_loss= 0.30534 train_acc= 0.89340 val_loss= 0.49784 val_acc= 0.78169 time= 0.07296
Epoch: 0019 train_loss= 0.28412 train_acc= 0.89887 val_loss= 0.50094 val_acc= 0.77746 time= 0.08704
Epoch: 0020 train_loss= 0.26601 train_acc= 0.90388 val_loss= 0.50640 val_acc= 0.77465 time= 0.07201
Epoch: 0021 train_loss= 0.25149 train_acc= 0.90857 val_loss= 0.51430 val_acc= 0.77606 time= 0.07100
Epoch: 0022 train_loss= 0.23785 train_acc= 0.91028 val_loss= 0.52351 val_acc= 0.77324 time= 0.07309
Early stopping...
Optimization Finished!
Test set results: cost= 0.52222 accuracy= 0.76111 time= 0.03196
29426
Test Precision, Recall and F1-Score...
              precision    recall  f1-score   support

           0     0.7495    0.7845    0.7666      1777
           1     0.7739    0.7378    0.7554      1777

    accuracy                         0.7611      3554
   macro avg     0.7617    0.7611    0.7610      3554
weighted avg     0.7617    0.7611    0.7610      3554

Macro average Test Precision, Recall and F1-Score...
(0.7616851379314722, 0.7611142374788971, 0.7609838762226981, None)
Micro average Test Precision, Recall and F1-Score...
(0.7611142374788971, 0.7611142374788971, 0.7611142374788971, None)
embeddings:
18764 7108 3554
[[ 0.07929665 -0.00770499  0.12210348 ...  0.017484    0.10033827
   0.00767386]
 [ 0.06772369  0.15198462 -0.00185851 ...  0.15171306 -0.01494662
   0.01380901]
 [ 0.16458508 -0.06236511  0.16844344 ... -0.0339777   0.16297705
   0.15941346]
 ...
 [ 0.13279271 -0.10215452  0.01045287 ... -0.09587353 -0.0006616
   0.14373885]
 [ 0.03784621  0.12076458  0.02833545 ...  0.12686788  0.02744026
   0.00539197]
 [ 0.1006076   0.23276442  0.07761118 ...  0.2417661   0.04835783
   0.08655218]]
