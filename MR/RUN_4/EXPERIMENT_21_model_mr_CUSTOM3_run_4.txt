(6398, 300) (6398, 2) (3554, 300) (3554, 2) (25872, 300) (25872, 2)
29426
  (0, 10623)	6.18339884402439
  (0, 13919)	0.5465010749888104
  (0, 14559)	1.1115554606675069
  (0, 15700)	3.7569884009179986
  (0, 18226)	1.5195310253612764
  (0, 18467)	4.04333268052812
  (0, 19338)	7.328531148327393
  (0, 22286)	6.789534647594706
  (0, 23328)	1.9258537664551136
  (1, 7795)	5.147306912337615
  (1, 8008)	5.36241829195456
  (1, 9081)	2.030213781779356
  (1, 9548)	1.8885902192574975
  (1, 9842)	5.487127339313642
  (1, 10712)	7.077216720046487
  (1, 11167)	4.763581790865857
  (1, 11240)	1.9780280286087861
  (1, 12074)	8.581294116822761
  (1, 12204)	3.001693660045025
  (1, 13383)	8.175829008714597
  (1, 13384)	1.1367531124051018
  (1, 13919)	2.732505374944052
  (1, 14559)	0.5557777303337534
  (1, 15052)	2.8176716418105427
  (1, 15552)	3.1786167349504817
  :	:
  (29423, 20674)	1.2821726541119611
  (29423, 21548)	2.0777547265483562
  (29423, 21594)	4.71009310591487
  (29423, 22686)	1.3489223175957803
  (29423, 23714)	0.7656835847875705
  (29423, 24605)	6.18339884402439
  (29424, 9508)	7.665003384948606
  (29424, 12204)	1.5008468300225124
  (29424, 12719)	8.175829008714597
  (29424, 13792)	7.19499975570287
  (29424, 14440)	2.1419437457226627
  (29424, 14647)	4.23101618046346
  (29424, 14666)	6.384069539486542
  (29424, 14849)	2.730529451817914
  (29424, 15098)	3.941722504117337
  (29424, 15191)	8.175829008714597
  (29424, 16855)	7.665003384948606
  (29424, 18226)	1.5195310253612764
  (29424, 19164)	4.983981856234315
  (29424, 22983)	4.630050398241334
  (29424, 24152)	4.168495823482126
  (29425, 8194)	6.278709023828715
  (29425, 13921)	5.249089606647557
  (29425, 19699)	0.6764057181223682
  (29425, 22407)	4.855600689586108
(29426, 29426)
(29426, 29426)
29426
Tensor("graphconvolution_2/SparseTensorDenseMatMul/SparseTensorDenseMatMul:0", shape=(None, 2), dtype=float32)
Epoch: 0001 train_loss= 0.69314 train_acc= 0.49328 val_loss= 0.69157 val_acc= 0.65915 time= 0.37362
Epoch: 0002 train_loss= 0.69045 train_acc= 0.74586 val_loss= 0.68771 val_acc= 0.65775 time= 0.07617
Epoch: 0003 train_loss= 0.68405 train_acc= 0.74820 val_loss= 0.68138 val_acc= 0.67746 time= 0.07399
Epoch: 0004 train_loss= 0.67365 train_acc= 0.75258 val_loss= 0.67261 val_acc= 0.68732 time= 0.07317
Epoch: 0005 train_loss= 0.65923 train_acc= 0.77618 val_loss= 0.66140 val_acc= 0.70282 time= 0.08811
Epoch: 0006 train_loss= 0.64065 train_acc= 0.79118 val_loss= 0.64771 val_acc= 0.72817 time= 0.07301
Epoch: 0007 train_loss= 0.61772 train_acc= 0.81338 val_loss= 0.63179 val_acc= 0.73380 time= 0.07103
Epoch: 0008 train_loss= 0.59110 train_acc= 0.83292 val_loss= 0.61406 val_acc= 0.74930 time= 0.07799
Epoch: 0009 train_loss= 0.56202 train_acc= 0.85152 val_loss= 0.59525 val_acc= 0.75775 time= 0.07297
Epoch: 0010 train_loss= 0.53079 train_acc= 0.85683 val_loss= 0.57613 val_acc= 0.76620 time= 0.07181
Epoch: 0011 train_loss= 0.49758 train_acc= 0.86574 val_loss= 0.55764 val_acc= 0.77746 time= 0.07217
Epoch: 0012 train_loss= 0.46584 train_acc= 0.87324 val_loss= 0.54070 val_acc= 0.77606 time= 0.07201
Epoch: 0013 train_loss= 0.43289 train_acc= 0.87902 val_loss= 0.52596 val_acc= 0.77183 time= 0.07204
Epoch: 0014 train_loss= 0.40272 train_acc= 0.87934 val_loss= 0.51387 val_acc= 0.77606 time= 0.08585
Epoch: 0015 train_loss= 0.37397 train_acc= 0.88340 val_loss= 0.50478 val_acc= 0.77465 time= 0.07314
Epoch: 0016 train_loss= 0.34886 train_acc= 0.88543 val_loss= 0.49870 val_acc= 0.77746 time= 0.07200
Epoch: 0017 train_loss= 0.32282 train_acc= 0.89465 val_loss= 0.49583 val_acc= 0.77606 time= 0.07300
Epoch: 0018 train_loss= 0.30471 train_acc= 0.89387 val_loss= 0.49590 val_acc= 0.77324 time= 0.07225
Epoch: 0019 train_loss= 0.28301 train_acc= 0.89934 val_loss= 0.49878 val_acc= 0.77183 time= 0.08598
Epoch: 0020 train_loss= 0.26669 train_acc= 0.90231 val_loss= 0.50398 val_acc= 0.77183 time= 0.07116
Epoch: 0021 train_loss= 0.25188 train_acc= 0.90794 val_loss= 0.51128 val_acc= 0.78028 time= 0.07207
Epoch: 0022 train_loss= 0.23793 train_acc= 0.91169 val_loss= 0.52051 val_acc= 0.77606 time= 0.08095
Early stopping...
Optimization Finished!
Test set results: cost= 0.52084 accuracy= 0.76168 time= 0.03300
29426
Test Precision, Recall and F1-Score...
              precision    recall  f1-score   support

           0     0.7511    0.7828    0.7666      1777
           1     0.7732    0.7406    0.7565      1777

    accuracy                         0.7617      3554
   macro avg     0.7621    0.7617    0.7616      3554
weighted avg     0.7621    0.7617    0.7616      3554

Macro average Test Precision, Recall and F1-Score...
(0.7621439521031032, 0.7616769836803602, 0.7615708026056587, None)
Micro average Test Precision, Recall and F1-Score...
(0.7616769836803602, 0.7616769836803602, 0.7616769836803602, None)
embeddings:
18764 7108 3554
[[ 0.07726506  0.00204834  0.00108121 ... -0.01612713  0.06526048
   0.09843247]
 [ 0.04938388  0.14058495  0.13818975 ...  0.06110087  0.00101096
  -0.01331854]
 [ 0.16167177 -0.04776332 -0.05517789 ... -0.03030181  0.15739076
   0.14218612]
 ...
 [ 0.14449584 -0.01229479 -0.01258015 ... -0.00907354  0.09268488
  -0.00610659]
 [ 0.0245811   0.0867634   0.11061104 ...  0.10936435  0.01168481
   0.01824559]
 [ 0.05287597  0.23550744  0.1869568  ...  0.1568393   0.06408636
   0.06823128]]
