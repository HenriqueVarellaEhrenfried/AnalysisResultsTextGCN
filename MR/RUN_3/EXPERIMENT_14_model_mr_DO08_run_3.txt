(6398, 300) (6398, 2) (3554, 300) (3554, 2) (25872, 300) (25872, 2)
29426
  (0, 10623)	6.18339884402439
  (0, 13919)	0.5465010749888104
  (0, 14559)	1.1115554606675069
  (0, 15700)	3.7569884009179986
  (0, 18226)	1.5195310253612764
  (0, 18467)	4.04333268052812
  (0, 19338)	7.328531148327393
  (0, 22286)	6.789534647594706
  (0, 23328)	1.9258537664551136
  (1, 7795)	5.147306912337615
  (1, 8008)	5.36241829195456
  (1, 9081)	2.030213781779356
  (1, 9548)	1.8885902192574975
  (1, 9842)	5.487127339313642
  (1, 10712)	7.077216720046487
  (1, 11167)	4.763581790865857
  (1, 11240)	1.9780280286087861
  (1, 12074)	8.581294116822761
  (1, 12204)	3.001693660045025
  (1, 13383)	8.175829008714597
  (1, 13384)	1.1367531124051018
  (1, 13919)	2.732505374944052
  (1, 14559)	0.5557777303337534
  (1, 15052)	2.8176716418105427
  (1, 15552)	3.1786167349504817
  :	:
  (29423, 20674)	1.2821726541119611
  (29423, 21548)	2.0777547265483562
  (29423, 21594)	4.71009310591487
  (29423, 22686)	1.3489223175957803
  (29423, 23714)	0.7656835847875705
  (29423, 24605)	6.18339884402439
  (29424, 9508)	7.665003384948606
  (29424, 12204)	1.5008468300225124
  (29424, 12719)	8.175829008714597
  (29424, 13792)	7.19499975570287
  (29424, 14440)	2.1419437457226627
  (29424, 14647)	4.23101618046346
  (29424, 14666)	6.384069539486542
  (29424, 14849)	2.730529451817914
  (29424, 15098)	3.941722504117337
  (29424, 15191)	8.175829008714597
  (29424, 16855)	7.665003384948606
  (29424, 18226)	1.5195310253612764
  (29424, 19164)	4.983981856234315
  (29424, 22983)	4.630050398241334
  (29424, 24152)	4.168495823482126
  (29425, 8194)	6.278709023828715
  (29425, 13921)	5.249089606647557
  (29425, 19699)	0.6764057181223682
  (29425, 22407)	4.855600689586108
(29426, 29426)
(29426, 29426)
29426
Tensor("graphconvolution_2/SparseTensorDenseMatMul/SparseTensorDenseMatMul:0", shape=(None, 2), dtype=float32)
Epoch: 0001 train_loss= 0.69315 train_acc= 0.48187 val_loss= 0.69132 val_acc= 0.73944 time= 0.37275
Epoch: 0002 train_loss= 0.68985 train_acc= 0.82557 val_loss= 0.68629 val_acc= 0.70986 time= 0.07601
Epoch: 0003 train_loss= 0.68150 train_acc= 0.80009 val_loss= 0.67847 val_acc= 0.70986 time= 0.07499
Epoch: 0004 train_loss= 0.66832 train_acc= 0.80635 val_loss= 0.66776 val_acc= 0.72676 time= 0.07296
Epoch: 0005 train_loss= 0.65074 train_acc= 0.82651 val_loss= 0.65414 val_acc= 0.73803 time= 0.08300
Epoch: 0006 train_loss= 0.62757 train_acc= 0.83479 val_loss= 0.63784 val_acc= 0.74225 time= 0.07362
Epoch: 0007 train_loss= 0.60057 train_acc= 0.84855 val_loss= 0.61926 val_acc= 0.75634 time= 0.07300
Epoch: 0008 train_loss= 0.56870 train_acc= 0.86636 val_loss= 0.59920 val_acc= 0.75775 time= 0.07196
Epoch: 0009 train_loss= 0.53416 train_acc= 0.87309 val_loss= 0.57865 val_acc= 0.77183 time= 0.07109
Epoch: 0010 train_loss= 0.49889 train_acc= 0.87777 val_loss= 0.55868 val_acc= 0.77324 time= 0.08904
Epoch: 0011 train_loss= 0.46212 train_acc= 0.87965 val_loss= 0.54032 val_acc= 0.77324 time= 0.07206
Epoch: 0012 train_loss= 0.42654 train_acc= 0.88543 val_loss= 0.52467 val_acc= 0.77324 time= 0.07200
Epoch: 0013 train_loss= 0.39203 train_acc= 0.89028 val_loss= 0.51229 val_acc= 0.77324 time= 0.07296
Epoch: 0014 train_loss= 0.35955 train_acc= 0.89012 val_loss= 0.50366 val_acc= 0.77465 time= 0.07212
Epoch: 0015 train_loss= 0.33038 train_acc= 0.89856 val_loss= 0.49889 val_acc= 0.77887 time= 0.07296
Epoch: 0016 train_loss= 0.30472 train_acc= 0.90013 val_loss= 0.49805 val_acc= 0.77606 time= 0.08804
Epoch: 0017 train_loss= 0.28114 train_acc= 0.90653 val_loss= 0.50125 val_acc= 0.77465 time= 0.07200
Epoch: 0018 train_loss= 0.25855 train_acc= 0.91013 val_loss= 0.50743 val_acc= 0.77465 time= 0.07108
Epoch: 0019 train_loss= 0.23960 train_acc= 0.91404 val_loss= 0.51633 val_acc= 0.77887 time= 0.07396
Epoch: 0020 train_loss= 0.22635 train_acc= 0.91669 val_loss= 0.52756 val_acc= 0.77887 time= 0.07603
Early stopping...
Optimization Finished!
Test set results: cost= 0.52724 accuracy= 0.76168 time= 0.03300
29426
Test Precision, Recall and F1-Score...
              precision    recall  f1-score   support

           0     0.7514    0.7822    0.7665      1777
           1     0.7729    0.7411    0.7567      1777

    accuracy                         0.7617      3554
   macro avg     0.7621    0.7617    0.7616      3554
weighted avg     0.7621    0.7617    0.7616      3554

Macro average Test Precision, Recall and F1-Score...
(0.7621193376475066, 0.7616769836803602, 0.7615763924481294, None)
Micro average Test Precision, Recall and F1-Score...
(0.7616769836803602, 0.7616769836803602, 0.7616769836803602, None)
embeddings:
18764 7108 3554
[[ 0.02834416 -0.00916672  0.05603312 ...  0.01790342  0.059675
   0.10813738]
 [ 0.1499598   0.14421043 -0.00534705 ...  0.10147788  0.01234023
   0.0006228 ]
 [-0.03936585 -0.04967323  0.11658643 ... -0.03658566  0.11407231
   0.1741526 ]
 ...
 [-0.09760547 -0.07422215  0.13227928 ... -0.08052219 -0.0100833
  -0.00446417]
 [ 0.13576129  0.12151473  0.01793007 ...  0.14048815  0.02066283
   0.01831446]
 [ 0.24389984  0.22853076  0.08978339 ...  0.2133017   0.08413221
   0.12035778]]
