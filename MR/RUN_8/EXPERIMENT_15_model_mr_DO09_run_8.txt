(6398, 300) (6398, 2) (3554, 300) (3554, 2) (25872, 300) (25872, 2)
29426
  (0, 10623)	6.18339884402439
  (0, 13919)	0.5465010749888104
  (0, 14559)	1.1115554606675069
  (0, 15700)	3.7569884009179986
  (0, 18226)	1.5195310253612764
  (0, 18467)	4.04333268052812
  (0, 19338)	7.328531148327393
  (0, 22286)	6.789534647594706
  (0, 23328)	1.9258537664551136
  (1, 7795)	5.147306912337615
  (1, 8008)	5.36241829195456
  (1, 9081)	2.030213781779356
  (1, 9548)	1.8885902192574975
  (1, 9842)	5.487127339313642
  (1, 10712)	7.077216720046487
  (1, 11167)	4.763581790865857
  (1, 11240)	1.9780280286087861
  (1, 12074)	8.581294116822761
  (1, 12204)	3.001693660045025
  (1, 13383)	8.175829008714597
  (1, 13384)	1.1367531124051018
  (1, 13919)	2.732505374944052
  (1, 14559)	0.5557777303337534
  (1, 15052)	2.8176716418105427
  (1, 15552)	3.1786167349504817
  :	:
  (29423, 20674)	1.2821726541119611
  (29423, 21548)	2.0777547265483562
  (29423, 21594)	4.71009310591487
  (29423, 22686)	1.3489223175957803
  (29423, 23714)	0.7656835847875705
  (29423, 24605)	6.18339884402439
  (29424, 9508)	7.665003384948606
  (29424, 12204)	1.5008468300225124
  (29424, 12719)	8.175829008714597
  (29424, 13792)	7.19499975570287
  (29424, 14440)	2.1419437457226627
  (29424, 14647)	4.23101618046346
  (29424, 14666)	6.384069539486542
  (29424, 14849)	2.730529451817914
  (29424, 15098)	3.941722504117337
  (29424, 15191)	8.175829008714597
  (29424, 16855)	7.665003384948606
  (29424, 18226)	1.5195310253612764
  (29424, 19164)	4.983981856234315
  (29424, 22983)	4.630050398241334
  (29424, 24152)	4.168495823482126
  (29425, 8194)	6.278709023828715
  (29425, 13921)	5.249089606647557
  (29425, 19699)	0.6764057181223682
  (29425, 22407)	4.855600689586108
(29426, 29426)
(29426, 29426)
29426
Tensor("graphconvolution_2/SparseTensorDenseMatMul/SparseTensorDenseMatMul:0", shape=(None, 2), dtype=float32)
Epoch: 0001 train_loss= 0.69314 train_acc= 0.50469 val_loss= 0.69167 val_acc= 0.72535 time= 0.37990
Epoch: 0002 train_loss= 0.69058 train_acc= 0.79744 val_loss= 0.68795 val_acc= 0.72958 time= 0.08903
Epoch: 0003 train_loss= 0.68450 train_acc= 0.79634 val_loss= 0.68171 val_acc= 0.72817 time= 0.07500
Epoch: 0004 train_loss= 0.67453 train_acc= 0.81103 val_loss= 0.67299 val_acc= 0.73803 time= 0.08000
Epoch: 0005 train_loss= 0.66023 train_acc= 0.81697 val_loss= 0.66168 val_acc= 0.74225 time= 0.07235
Epoch: 0006 train_loss= 0.64190 train_acc= 0.83135 val_loss= 0.64788 val_acc= 0.74085 time= 0.07308
Epoch: 0007 train_loss= 0.61999 train_acc= 0.83542 val_loss= 0.63190 val_acc= 0.75211 time= 0.07383
Epoch: 0008 train_loss= 0.59366 train_acc= 0.84698 val_loss= 0.61424 val_acc= 0.75493 time= 0.08303
Epoch: 0009 train_loss= 0.56386 train_acc= 0.85730 val_loss= 0.59545 val_acc= 0.76761 time= 0.07200
Epoch: 0010 train_loss= 0.53230 train_acc= 0.86183 val_loss= 0.57640 val_acc= 0.77042 time= 0.07096
Epoch: 0011 train_loss= 0.49979 train_acc= 0.86699 val_loss= 0.55791 val_acc= 0.77042 time= 0.07410
Epoch: 0012 train_loss= 0.46615 train_acc= 0.87168 val_loss= 0.54086 val_acc= 0.77183 time= 0.08397
Epoch: 0013 train_loss= 0.43476 train_acc= 0.87262 val_loss= 0.52598 val_acc= 0.77324 time= 0.07504
Epoch: 0014 train_loss= 0.40430 train_acc= 0.88043 val_loss= 0.51382 val_acc= 0.77042 time= 0.07503
Epoch: 0015 train_loss= 0.37639 train_acc= 0.88153 val_loss= 0.50485 val_acc= 0.77042 time= 0.07300
Epoch: 0016 train_loss= 0.34943 train_acc= 0.88403 val_loss= 0.49892 val_acc= 0.77465 time= 0.08270
Epoch: 0017 train_loss= 0.32642 train_acc= 0.88793 val_loss= 0.49606 val_acc= 0.77887 time= 0.07208
Epoch: 0018 train_loss= 0.30442 train_acc= 0.89247 val_loss= 0.49610 val_acc= 0.78028 time= 0.07107
Epoch: 0019 train_loss= 0.28553 train_acc= 0.89622 val_loss= 0.49899 val_acc= 0.78028 time= 0.07299
Epoch: 0020 train_loss= 0.26747 train_acc= 0.89606 val_loss= 0.50476 val_acc= 0.77746 time= 0.07307
Epoch: 0021 train_loss= 0.25110 train_acc= 0.90544 val_loss= 0.51285 val_acc= 0.77746 time= 0.08408
Epoch: 0022 train_loss= 0.23943 train_acc= 0.91091 val_loss= 0.52215 val_acc= 0.78028 time= 0.07201
Early stopping...
Optimization Finished!
Test set results: cost= 0.52451 accuracy= 0.76196 time= 0.03198
29426
Test Precision, Recall and F1-Score...
              precision    recall  f1-score   support

           0     0.7472    0.7918    0.7689      1777
           1     0.7786    0.7321    0.7546      1777

    accuracy                         0.7620      3554
   macro avg     0.7629    0.7620    0.7617      3554
weighted avg     0.7629    0.7620    0.7617      3554

Macro average Test Precision, Recall and F1-Score...
(0.762893799541267, 0.7619583567810917, 0.761746415123046, None)
Micro average Test Precision, Recall and F1-Score...
(0.7619583567810917, 0.7619583567810917, 0.7619583567810917, None)
embeddings:
18764 7108 3554
[[ 0.09756658  0.01674194  0.0786605  ...  0.0351061   0.0349608
  -0.0127478 ]
 [ 0.05957504  0.15561694  0.00868898 ...  0.0899252   0.10883678
   0.16189566]
 [ 0.14350662 -0.02453234  0.13488397 ... -0.05129858 -0.03769445
  -0.0270967 ]
 ...
 [-0.00148836 -0.0701839  -0.01072991 ... -0.09012345  0.00798773
  -0.07120573]
 [ 0.0296274   0.08739964  0.00434331 ...  0.1311959   0.09176619
   0.12273322]
 [ 0.09280108  0.17984131  0.07127951 ...  0.20690133  0.17148504
   0.25026774]]
