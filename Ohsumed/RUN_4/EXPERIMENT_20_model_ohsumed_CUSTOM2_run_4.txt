(3022, 300) (3022, 23) (4043, 300) (4043, 23) (17514, 300) (17514, 23)
21557
  (0, 3359)	5.577030769017057
  (0, 3385)	26.455355949884314
  (0, 3421)	13.939666206452838
  (0, 3587)	5.220355825078324
  (0, 3645)	0.9703478889312359
  (0, 3738)	5.8647128414688385
  (0, 3917)	19.628143287419626
  (0, 4195)	5.651138741170779
  (0, 4329)	31.721429608653622
  (0, 4385)	4.52720864451838
  (0, 4428)	19.128403576588678
  (0, 4548)	3.6781266623376743
  (0, 4600)	2.5007064881327628
  (0, 4711)	10.730794439619183
  (0, 4779)	3.68348860547906
  (0, 4822)	6.076021935136045
  (0, 4886)	1.3033452781391397
  (0, 5046)	3.7387512841541093
  (0, 5108)	13.65958747502485
  (0, 5197)	4.565429857338577
  (0, 5737)	5.731181448844316
  (0, 5896)	3.147183896412084
  (0, 5900)	1.6815727804636063
  (0, 6074)	3.7107382479264355
  (0, 6125)	4.502516031928008
  :	:
  (21556, 12648)	4.03403795599111
  (21556, 12692)	22.56882275421711
  (21556, 12705)	2.9278210679377805
  (21556, 12894)	4.53978742672524
  (21556, 12960)	2.644863488059361
  (21556, 13102)	6.963325130136948
  (21556, 13281)	3.0484490557263952
  (21556, 14226)	5.651138741170779
  (21556, 14662)	14.483872993990904
  (21556, 14684)	9.23755167608774
  (21556, 14980)	3.56690102722745
  (21556, 15283)	3.071504832026321
  (21556, 15587)	1.6650077635889111
  (21556, 15636)	4.245796185080194
  (21556, 15690)	11.729425682937677
  (21556, 15849)	3.859379271942724
  (21556, 16287)	6.076021935136045
  (21556, 16491)	3.2567460989236108
  (21556, 16547)	2.7292186255396884
  (21556, 16819)	1.8953198043817334
  (21556, 17017)	5.337918868042983
  (21556, 17066)	6.018675851219539
  (21556, 17095)	6.1366465569524795
  (21556, 17311)	6.344285921730725
  (21556, 17421)	3.744449305268747
(21557, 21557)
(21557, 21557)
21557
Tensor("graphconvolution_2/SparseTensorDenseMatMul/SparseTensorDenseMatMul:0", shape=(None, 23), dtype=float32)
Epoch: 0001 train_loss= 3.13545 train_acc= 0.05725 val_loss= 2.92439 val_acc= 0.21493 time= 0.58079
Epoch: 0002 train_loss= 2.92707 train_acc= 0.18597 val_loss= 2.73215 val_acc= 0.25075 time= 0.28901
Epoch: 0003 train_loss= 2.75175 train_acc= 0.21906 val_loss= 2.65716 val_acc= 0.20597 time= 0.29889
Epoch: 0004 train_loss= 2.67070 train_acc= 0.17803 val_loss= 2.51808 val_acc= 0.29254 time= 0.28798
Epoch: 0005 train_loss= 2.49097 train_acc= 0.27498 val_loss= 2.44027 val_acc= 0.36418 time= 0.28703
Epoch: 0006 train_loss= 2.38645 train_acc= 0.35539 val_loss= 2.30590 val_acc= 0.41194 time= 0.28639
Epoch: 0007 train_loss= 2.23179 train_acc= 0.42852 val_loss= 2.12858 val_acc= 0.44179 time= 0.29404
Epoch: 0008 train_loss= 2.04076 train_acc= 0.47353 val_loss= 1.99081 val_acc= 0.43582 time= 0.28900
Epoch: 0009 train_loss= 1.87968 train_acc= 0.48213 val_loss= 1.88084 val_acc= 0.47463 time= 0.28704
Epoch: 0010 train_loss= 1.73514 train_acc= 0.53872 val_loss= 1.77574 val_acc= 0.52537 time= 0.29300
Epoch: 0011 train_loss= 1.57921 train_acc= 0.58835 val_loss= 1.67905 val_acc= 0.51940 time= 0.29600
Epoch: 0012 train_loss= 1.42780 train_acc= 0.61681 val_loss= 1.59970 val_acc= 0.54328 time= 0.29153
Epoch: 0013 train_loss= 1.30392 train_acc= 0.67538 val_loss= 1.54199 val_acc= 0.56119 time= 0.28803
Epoch: 0014 train_loss= 1.18979 train_acc= 0.70053 val_loss= 1.47237 val_acc= 0.57015 time= 0.29300
Epoch: 0015 train_loss= 1.07516 train_acc= 0.72535 val_loss= 1.41537 val_acc= 0.59701 time= 0.28901
Epoch: 0016 train_loss= 0.96585 train_acc= 0.73858 val_loss= 1.38559 val_acc= 0.59701 time= 0.28700
Epoch: 0017 train_loss= 0.87789 train_acc= 0.76406 val_loss= 1.35443 val_acc= 0.62687 time= 0.28501
Epoch: 0018 train_loss= 0.77553 train_acc= 0.79318 val_loss= 1.33575 val_acc= 0.62388 time= 0.29400
Epoch: 0019 train_loss= 0.68445 train_acc= 0.83058 val_loss= 1.31207 val_acc= 0.63582 time= 0.28900
Epoch: 0020 train_loss= 0.60378 train_acc= 0.85208 val_loss= 1.28990 val_acc= 0.64179 time= 0.29000
Epoch: 0021 train_loss= 0.53496 train_acc= 0.86102 val_loss= 1.27608 val_acc= 0.64179 time= 0.29300
Epoch: 0022 train_loss= 0.47056 train_acc= 0.87326 val_loss= 1.27429 val_acc= 0.63582 time= 0.29100
Epoch: 0023 train_loss= 0.41003 train_acc= 0.89047 val_loss= 1.27992 val_acc= 0.67164 time= 0.28700
Epoch: 0024 train_loss= 0.35608 train_acc= 0.91727 val_loss= 1.28424 val_acc= 0.67463 time= 0.28800
Epoch: 0025 train_loss= 0.31836 train_acc= 0.92819 val_loss= 1.28709 val_acc= 0.66866 time= 0.29303
Early stopping...
Optimization Finished!
Test set results: cost= 1.31583 accuracy= 0.67104 time= 0.13100
21557
Test Precision, Recall and F1-Score...
              precision    recall  f1-score   support

           0     0.6945    0.7047    0.6996       342
           1     0.6847    0.7379    0.7103       103
           2     0.6600    0.4714    0.5500       140
           3     0.6122    0.3797    0.4688        79
           4     0.6447    0.7424    0.6901       132
           5     0.7143    0.7668    0.7396       313
           6     0.6429    0.7059    0.6729       102
           7     0.5667    0.2429    0.3400        70
           8     0.5200    0.2600    0.3467        50
           9     0.5850    0.7548    0.6592       155
          10     0.8311    0.6578    0.7343       187
          11     0.6505    0.5801    0.6133       231
          12     0.7679    0.7247    0.7457       178
          13     0.7701    0.7983    0.7840       600
          14     0.7974    0.8203    0.8087       590
          15     0.7879    0.6842    0.7324        76
          16     0.7143    0.2941    0.4167        34
          17     0.0000    0.0000    0.0000        10
          18     0.3779    0.5131    0.4352       419
          19     0.5656    0.5349    0.5498       129
          20     0.7500    0.5357    0.6250        28
          21     1.0000    0.6897    0.8163        29
          22     0.6842    0.2826    0.4000        46

    accuracy                         0.6710      4043
   macro avg     0.6531    0.5601    0.5886      4043
weighted avg     0.6805    0.6710    0.6685      4043

Macro average Test Precision, Recall and F1-Score...
(0.6531169278370045, 0.5600887828684918, 0.5886251969938566, None)
Micro average Test Precision, Recall and F1-Score...
(0.6710363591392531, 0.6710363591392531, 0.6710363591392531, None)
embeddings:
14157 3357 4043
[[ 0.14996935  0.3537195   0.29689792 ... -0.6258332   0.11581403
   0.4832962 ]
 [ 0.05472642 -0.08308703  0.25402635 ... -0.15671232 -0.01328384
   0.38452584]
 [ 0.11272986 -0.02108479  0.10570998 ... -0.39231074  0.14430426
   0.38475418]
 ...
 [ 0.113304    0.24850549  0.1580524  ... -0.18879269  0.08514424
   0.29117885]
 [-0.13953401 -0.09939329  0.10398809 ... -0.21140206 -0.08278267
  -0.06725829]
 [ 0.09628069  0.26805666  0.31635055 ... -0.18319839  0.24311624
   0.4475286 ]]
