(3022, 300) (3022, 23) (4043, 300) (4043, 23) (17514, 300) (17514, 23)
21557
  (0, 3359)	5.577030769017057
  (0, 3385)	26.455355949884314
  (0, 3421)	13.939666206452838
  (0, 3587)	5.220355825078324
  (0, 3645)	0.9703478889312359
  (0, 3738)	5.8647128414688385
  (0, 3917)	19.628143287419626
  (0, 4195)	5.651138741170779
  (0, 4329)	31.721429608653622
  (0, 4385)	4.52720864451838
  (0, 4428)	19.128403576588678
  (0, 4548)	3.6781266623376743
  (0, 4600)	2.5007064881327628
  (0, 4711)	10.730794439619183
  (0, 4779)	3.68348860547906
  (0, 4822)	6.076021935136045
  (0, 4886)	1.3033452781391397
  (0, 5046)	3.7387512841541093
  (0, 5108)	13.65958747502485
  (0, 5197)	4.565429857338577
  (0, 5737)	5.731181448844316
  (0, 5896)	3.147183896412084
  (0, 5900)	1.6815727804636063
  (0, 6074)	3.7107382479264355
  (0, 6125)	4.502516031928008
  :	:
  (21556, 12648)	4.03403795599111
  (21556, 12692)	22.56882275421711
  (21556, 12705)	2.9278210679377805
  (21556, 12894)	4.53978742672524
  (21556, 12960)	2.644863488059361
  (21556, 13102)	6.963325130136948
  (21556, 13281)	3.0484490557263952
  (21556, 14226)	5.651138741170779
  (21556, 14662)	14.483872993990904
  (21556, 14684)	9.23755167608774
  (21556, 14980)	3.56690102722745
  (21556, 15283)	3.071504832026321
  (21556, 15587)	1.6650077635889111
  (21556, 15636)	4.245796185080194
  (21556, 15690)	11.729425682937677
  (21556, 15849)	3.859379271942724
  (21556, 16287)	6.076021935136045
  (21556, 16491)	3.2567460989236108
  (21556, 16547)	2.7292186255396884
  (21556, 16819)	1.8953198043817334
  (21556, 17017)	5.337918868042983
  (21556, 17066)	6.018675851219539
  (21556, 17095)	6.1366465569524795
  (21556, 17311)	6.344285921730725
  (21556, 17421)	3.744449305268747
(21557, 21557)
(21557, 21557)
21557
Tensor("graphconvolution_2/SparseTensorDenseMatMul/SparseTensorDenseMatMul:0", shape=(None, 23), dtype=float32)
Epoch: 0001 train_loss= 3.13550 train_acc= 0.06089 val_loss= 2.92648 val_acc= 0.20896 time= 0.58362
Epoch: 0002 train_loss= 2.92680 train_acc= 0.18200 val_loss= 2.73323 val_acc= 0.20597 time= 0.28708
Epoch: 0003 train_loss= 2.75190 train_acc= 0.17439 val_loss= 2.67989 val_acc= 0.20299 time= 0.29100
Epoch: 0004 train_loss= 2.69123 train_acc= 0.17240 val_loss= 2.55065 val_acc= 0.27463 time= 0.29000
Epoch: 0005 train_loss= 2.51973 train_acc= 0.26075 val_loss= 2.48188 val_acc= 0.34627 time= 0.29203
Epoch: 0006 train_loss= 2.42772 train_acc= 0.35308 val_loss= 2.35758 val_acc= 0.39701 time= 0.28697
Epoch: 0007 train_loss= 2.28874 train_acc= 0.40470 val_loss= 2.18049 val_acc= 0.41493 time= 0.29968
Epoch: 0008 train_loss= 2.10117 train_acc= 0.44275 val_loss= 2.03415 val_acc= 0.42090 time= 0.28997
Epoch: 0009 train_loss= 1.93751 train_acc= 0.47121 val_loss= 1.92429 val_acc= 0.47463 time= 0.29003
Epoch: 0010 train_loss= 1.78017 train_acc= 0.53342 val_loss= 1.82291 val_acc= 0.51642 time= 0.29300
Epoch: 0011 train_loss= 1.63077 train_acc= 0.59034 val_loss= 1.72067 val_acc= 0.51940 time= 0.29500
Epoch: 0012 train_loss= 1.47793 train_acc= 0.61251 val_loss= 1.63103 val_acc= 0.56418 time= 0.29299
Epoch: 0013 train_loss= 1.33580 train_acc= 0.66016 val_loss= 1.56939 val_acc= 0.57015 time= 0.29497
Epoch: 0014 train_loss= 1.22468 train_acc= 0.70119 val_loss= 1.49914 val_acc= 0.57612 time= 0.29400
Epoch: 0015 train_loss= 1.10639 train_acc= 0.72270 val_loss= 1.43539 val_acc= 0.60000 time= 0.29203
Epoch: 0016 train_loss= 0.99095 train_acc= 0.73594 val_loss= 1.39876 val_acc= 0.60000 time= 0.28659
Epoch: 0017 train_loss= 0.89567 train_acc= 0.75546 val_loss= 1.37444 val_acc= 0.60299 time= 0.28800
Epoch: 0018 train_loss= 0.80562 train_acc= 0.77895 val_loss= 1.35288 val_acc= 0.60896 time= 0.29601
Epoch: 0019 train_loss= 0.70169 train_acc= 0.82032 val_loss= 1.33973 val_acc= 0.62985 time= 0.29018
Epoch: 0020 train_loss= 0.63559 train_acc= 0.84116 val_loss= 1.31749 val_acc= 0.61791 time= 0.28804
Epoch: 0021 train_loss= 0.55208 train_acc= 0.85407 val_loss= 1.29135 val_acc= 0.62985 time= 0.29304
Epoch: 0022 train_loss= 0.47946 train_acc= 0.86995 val_loss= 1.28383 val_acc= 0.64179 time= 0.29300
Epoch: 0023 train_loss= 0.43307 train_acc= 0.88120 val_loss= 1.29726 val_acc= 0.63881 time= 0.28900
Epoch: 0024 train_loss= 0.37704 train_acc= 0.90404 val_loss= 1.31367 val_acc= 0.64478 time= 0.28800
Early stopping...
Optimization Finished!
Test set results: cost= 1.29777 accuracy= 0.67029 time= 0.12804
21557
Test Precision, Recall and F1-Score...
              precision    recall  f1-score   support

           0     0.6772    0.6871    0.6821       342
           1     0.7188    0.6699    0.6935       103
           2     0.6893    0.5071    0.5844       140
           3     0.4125    0.4177    0.4151        79
           4     0.5854    0.7273    0.6486       132
           5     0.6969    0.7859    0.7387       313
           6     0.6339    0.6961    0.6636       102
           7     0.5111    0.3286    0.4000        70
           8     0.5600    0.2800    0.3733        50
           9     0.6461    0.7419    0.6907       155
          10     0.6837    0.7166    0.6997       187
          11     0.6234    0.6234    0.6234       231
          12     0.7674    0.7416    0.7543       178
          13     0.7802    0.7750    0.7776       600
          14     0.7569    0.8390    0.7958       590
          15     0.7941    0.7105    0.7500        76
          16     0.6111    0.3235    0.4231        34
          17     0.0000    0.0000    0.0000        10
          18     0.4354    0.4582    0.4465       419
          19     0.6061    0.4651    0.5263       129
          20     0.6800    0.6071    0.6415        28
          21     1.0000    0.6552    0.7917        29
          22     0.7000    0.3043    0.4242        46

    accuracy                         0.6703      4043
   macro avg     0.6335    0.5679    0.5889      4043
weighted avg     0.6688    0.6703    0.6652      4043

Macro average Test Precision, Recall and F1-Score...
(0.6334520941613405, 0.5678818085511543, 0.5888769863245187, None)
Micro average Test Precision, Recall and F1-Score...
(0.6702943358891912, 0.6702943358891912, 0.6702943358891912, None)
embeddings:
14157 3357 4043
[[ 0.18715115  0.2783893   0.56831324 ...  0.17807662  0.02380351
   0.08246416]
 [-0.09575428  0.35562748  0.17150196 ...  0.12688717  0.16089094
  -0.01350938]
 [-0.05384827  0.24325286  0.46840617 ...  0.15450975  0.1322292
   0.12377499]
 ...
 [ 0.05553786  0.10788351  0.30780703 ...  0.09157495  0.09499525
   0.09329487]
 [-0.02583836  0.10522278 -0.06907504 ... -0.14430301  0.01741887
  -0.1369921 ]
 [ 0.14007437  0.29906982  0.196798   ...  0.20977779  0.07722747
   0.06663504]]
