(3022, 300) (3022, 23) (4043, 300) (4043, 23) (17514, 300) (17514, 23)
21557
  (0, 3359)	5.577030769017057
  (0, 3385)	26.455355949884314
  (0, 3421)	13.939666206452838
  (0, 3587)	5.220355825078324
  (0, 3645)	0.9703478889312359
  (0, 3738)	5.8647128414688385
  (0, 3917)	19.628143287419626
  (0, 4195)	5.651138741170779
  (0, 4329)	31.721429608653622
  (0, 4385)	4.52720864451838
  (0, 4428)	19.128403576588678
  (0, 4548)	3.6781266623376743
  (0, 4600)	2.5007064881327628
  (0, 4711)	10.730794439619183
  (0, 4779)	3.68348860547906
  (0, 4822)	6.076021935136045
  (0, 4886)	1.3033452781391397
  (0, 5046)	3.7387512841541093
  (0, 5108)	13.65958747502485
  (0, 5197)	4.565429857338577
  (0, 5737)	5.731181448844316
  (0, 5896)	3.147183896412084
  (0, 5900)	1.6815727804636063
  (0, 6074)	3.7107382479264355
  (0, 6125)	4.502516031928008
  :	:
  (21556, 12648)	4.03403795599111
  (21556, 12692)	22.56882275421711
  (21556, 12705)	2.9278210679377805
  (21556, 12894)	4.53978742672524
  (21556, 12960)	2.644863488059361
  (21556, 13102)	6.963325130136948
  (21556, 13281)	3.0484490557263952
  (21556, 14226)	5.651138741170779
  (21556, 14662)	14.483872993990904
  (21556, 14684)	9.23755167608774
  (21556, 14980)	3.56690102722745
  (21556, 15283)	3.071504832026321
  (21556, 15587)	1.6650077635889111
  (21556, 15636)	4.245796185080194
  (21556, 15690)	11.729425682937677
  (21556, 15849)	3.859379271942724
  (21556, 16287)	6.076021935136045
  (21556, 16491)	3.2567460989236108
  (21556, 16547)	2.7292186255396884
  (21556, 16819)	1.8953198043817334
  (21556, 17017)	5.337918868042983
  (21556, 17066)	6.018675851219539
  (21556, 17095)	6.1366465569524795
  (21556, 17311)	6.344285921730725
  (21556, 17421)	3.744449305268747
(21557, 21557)
(21557, 21557)
21557
Tensor("graphconvolution_2/SparseTensorDenseMatMul/SparseTensorDenseMatMul:0", shape=(None, 23), dtype=float32)
Epoch: 0001 train_loss= 3.13550 train_acc= 0.04103 val_loss= 2.92741 val_acc= 0.26866 time= 0.57907
Epoch: 0002 train_loss= 2.92640 train_acc= 0.24520 val_loss= 2.73997 val_acc= 0.24478 time= 0.29397
Epoch: 0003 train_loss= 2.75625 train_acc= 0.21343 val_loss= 2.68156 val_acc= 0.20000 time= 0.28903
Epoch: 0004 train_loss= 2.69965 train_acc= 0.17141 val_loss= 2.55358 val_acc= 0.27463 time= 0.28697
Epoch: 0005 train_loss= 2.53506 train_acc= 0.24686 val_loss= 2.49307 val_acc= 0.32537 time= 0.29203
Epoch: 0006 train_loss= 2.44719 train_acc= 0.32363 val_loss= 2.37111 val_acc= 0.38806 time= 0.29000
Epoch: 0007 train_loss= 2.30979 train_acc= 0.38319 val_loss= 2.20305 val_acc= 0.40597 time= 0.28900
Epoch: 0008 train_loss= 2.13143 train_acc= 0.40966 val_loss= 2.06222 val_acc= 0.39403 time= 0.28800
Epoch: 0009 train_loss= 1.97743 train_acc= 0.42852 val_loss= 1.95930 val_acc= 0.44179 time= 0.29906
Epoch: 0010 train_loss= 1.84643 train_acc= 0.48445 val_loss= 1.85534 val_acc= 0.50746 time= 0.28843
Epoch: 0011 train_loss= 1.69706 train_acc= 0.56982 val_loss= 1.75198 val_acc= 0.53433 time= 0.29000
Epoch: 0012 train_loss= 1.55103 train_acc= 0.60390 val_loss= 1.66617 val_acc= 0.54030 time= 0.29340
Epoch: 0013 train_loss= 1.41496 train_acc= 0.63832 val_loss= 1.60283 val_acc= 0.56119 time= 0.29200
Epoch: 0014 train_loss= 1.30652 train_acc= 0.68233 val_loss= 1.53499 val_acc= 0.56418 time= 0.28755
Epoch: 0015 train_loss= 1.18842 train_acc= 0.69887 val_loss= 1.46485 val_acc= 0.58507 time= 0.28901
Epoch: 0016 train_loss= 1.06381 train_acc= 0.71476 val_loss= 1.42481 val_acc= 0.58806 time= 0.29399
Epoch: 0017 train_loss= 0.96695 train_acc= 0.72833 val_loss= 1.39254 val_acc= 0.60000 time= 0.28800
Epoch: 0018 train_loss= 0.87404 train_acc= 0.74851 val_loss= 1.35271 val_acc= 0.63284 time= 0.29297
Epoch: 0019 train_loss= 0.77866 train_acc= 0.79484 val_loss= 1.33575 val_acc= 0.61791 time= 0.28900
Epoch: 0020 train_loss= 0.68908 train_acc= 0.81800 val_loss= 1.31533 val_acc= 0.61194 time= 0.29900
Epoch: 0021 train_loss= 0.61586 train_acc= 0.84216 val_loss= 1.29333 val_acc= 0.62090 time= 0.29303
Epoch: 0022 train_loss= 0.53236 train_acc= 0.85539 val_loss= 1.28600 val_acc= 0.61493 time= 0.28803
Epoch: 0023 train_loss= 0.47553 train_acc= 0.86532 val_loss= 1.29259 val_acc= 0.64776 time= 0.29700
Epoch: 0024 train_loss= 0.41576 train_acc= 0.88848 val_loss= 1.29735 val_acc= 0.64478 time= 0.29100
Epoch: 0025 train_loss= 0.36070 train_acc= 0.91132 val_loss= 1.30776 val_acc= 0.64179 time= 0.28900
Early stopping...
Optimization Finished!
Test set results: cost= 1.30113 accuracy= 0.66362 time= 0.13000
21557
Test Precision, Recall and F1-Score...
              precision    recall  f1-score   support

           0     0.6905    0.6784    0.6844       342
           1     0.7087    0.7087    0.7087       103
           2     0.6047    0.5571    0.5799       140
           3     0.4688    0.3797    0.4196        79
           4     0.6226    0.7500    0.6804       132
           5     0.7169    0.7444    0.7304       313
           6     0.6404    0.7157    0.6759       102
           7     0.4839    0.2143    0.2970        70
           8     0.5455    0.2400    0.3333        50
           9     0.6170    0.7484    0.6764       155
          10     0.8052    0.6631    0.7273       187
          11     0.6301    0.5974    0.6133       231
          12     0.7473    0.7640    0.7556       178
          13     0.7789    0.7867    0.7828       600
          14     0.7769    0.8085    0.7924       590
          15     0.7969    0.6711    0.7286        76
          16     0.6923    0.2647    0.3830        34
          17     0.0000    0.0000    0.0000        10
          18     0.3728    0.5036    0.4284       419
          19     0.5943    0.4884    0.5362       129
          20     0.7333    0.3929    0.5116        28
          21     1.0000    0.5862    0.7391        29
          22     0.8125    0.2826    0.4194        46

    accuracy                         0.6636      4043
   macro avg     0.6452    0.5455    0.5741      4043
weighted avg     0.6723    0.6636    0.6610      4043

Macro average Test Precision, Recall and F1-Score...
(0.6451895664830891, 0.5454709497279058, 0.5740711598219691, None)
Micro average Test Precision, Recall and F1-Score...
(0.6636161266386347, 0.6636161266386347, 0.6636161266386347, None)
embeddings:
14157 3357 4043
[[ 0.480333    0.4828774   0.35560986 ...  0.30135873  0.16118781
   0.5074204 ]
 [-0.05683313  0.3264965   0.18026537 ...  0.03921628 -0.07215007
   0.15980218]
 [ 0.0523956   0.28265464  0.11188584 ...  0.03345922 -0.09628522
   0.21269181]
 ...
 [ 0.29394984  0.11174574  0.08675665 ...  0.13138306  0.03229872
   0.278259  ]
 [ 0.5648575   0.45788556  0.2286117  ...  0.5476324   0.42705032
   0.3723874 ]
 [ 0.15960605  0.29121968  0.24235453 ...  0.24867254  0.08685842
   0.24198073]]
