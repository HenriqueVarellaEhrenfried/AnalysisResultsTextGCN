(3022, 300) (3022, 23) (4043, 300) (4043, 23) (17514, 300) (17514, 23)
21557
  (0, 3359)	5.577030769017057
  (0, 3385)	26.455355949884314
  (0, 3421)	13.939666206452838
  (0, 3587)	5.220355825078324
  (0, 3645)	0.9703478889312359
  (0, 3738)	5.8647128414688385
  (0, 3917)	19.628143287419626
  (0, 4195)	5.651138741170779
  (0, 4329)	31.721429608653622
  (0, 4385)	4.52720864451838
  (0, 4428)	19.128403576588678
  (0, 4548)	3.6781266623376743
  (0, 4600)	2.5007064881327628
  (0, 4711)	10.730794439619183
  (0, 4779)	3.68348860547906
  (0, 4822)	6.076021935136045
  (0, 4886)	1.3033452781391397
  (0, 5046)	3.7387512841541093
  (0, 5108)	13.65958747502485
  (0, 5197)	4.565429857338577
  (0, 5737)	5.731181448844316
  (0, 5896)	3.147183896412084
  (0, 5900)	1.6815727804636063
  (0, 6074)	3.7107382479264355
  (0, 6125)	4.502516031928008
  :	:
  (21556, 12648)	4.03403795599111
  (21556, 12692)	22.56882275421711
  (21556, 12705)	2.9278210679377805
  (21556, 12894)	4.53978742672524
  (21556, 12960)	2.644863488059361
  (21556, 13102)	6.963325130136948
  (21556, 13281)	3.0484490557263952
  (21556, 14226)	5.651138741170779
  (21556, 14662)	14.483872993990904
  (21556, 14684)	9.23755167608774
  (21556, 14980)	3.56690102722745
  (21556, 15283)	3.071504832026321
  (21556, 15587)	1.6650077635889111
  (21556, 15636)	4.245796185080194
  (21556, 15690)	11.729425682937677
  (21556, 15849)	3.859379271942724
  (21556, 16287)	6.076021935136045
  (21556, 16491)	3.2567460989236108
  (21556, 16547)	2.7292186255396884
  (21556, 16819)	1.8953198043817334
  (21556, 17017)	5.337918868042983
  (21556, 17066)	6.018675851219539
  (21556, 17095)	6.1366465569524795
  (21556, 17311)	6.344285921730725
  (21556, 17421)	3.744449305268747
(21557, 21557)
(21557, 21557)
21557
Tensor("graphconvolution_2/SparseTensorDenseMatMul/SparseTensorDenseMatMul:0", shape=(None, 23), dtype=float32)
Epoch: 0001 train_loss= 3.13560 train_acc= 0.02912 val_loss= 2.95505 val_acc= 0.23881 time= 0.59096
Epoch: 0002 train_loss= 2.95498 train_acc= 0.21013 val_loss= 2.72987 val_acc= 0.23881 time= 0.29408
Epoch: 0003 train_loss= 2.73984 train_acc= 0.21112 val_loss= 2.74006 val_acc= 0.20000 time= 0.29202
Epoch: 0004 train_loss= 2.75266 train_acc= 0.17141 val_loss= 2.57447 val_acc= 0.24478 time= 0.28803
Epoch: 0005 train_loss= 2.55195 train_acc= 0.20913 val_loss= 2.50029 val_acc= 0.32239 time= 0.28727
Epoch: 0006 train_loss= 2.45801 train_acc= 0.33554 val_loss= 2.40213 val_acc= 0.42090 time= 0.29182
Epoch: 0007 train_loss= 2.34117 train_acc= 0.44375 val_loss= 2.24084 val_acc= 0.42687 time= 0.29100
Epoch: 0008 train_loss= 2.16262 train_acc= 0.46128 val_loss= 2.08764 val_acc= 0.41493 time= 0.28798
Epoch: 0009 train_loss= 1.99415 train_acc= 0.46228 val_loss= 1.97700 val_acc= 0.44776 time= 0.28803
Epoch: 0010 train_loss= 1.84998 train_acc= 0.49040 val_loss= 1.85775 val_acc= 0.51343 time= 0.29177
Epoch: 0011 train_loss= 1.68061 train_acc= 0.57346 val_loss= 1.74827 val_acc= 0.52537 time= 0.29120
Epoch: 0012 train_loss= 1.52424 train_acc= 0.61648 val_loss= 1.64874 val_acc= 0.54627 time= 0.28900
Epoch: 0013 train_loss= 1.38417 train_acc= 0.64858 val_loss= 1.57161 val_acc= 0.57313 time= 0.28500
Epoch: 0014 train_loss= 1.26504 train_acc= 0.69755 val_loss= 1.50055 val_acc= 0.56716 time= 0.29601
Epoch: 0015 train_loss= 1.14758 train_acc= 0.70417 val_loss= 1.43615 val_acc= 0.58806 time= 0.28900
Epoch: 0016 train_loss= 1.03118 train_acc= 0.72336 val_loss= 1.39450 val_acc= 0.60299 time= 0.28900
Epoch: 0017 train_loss= 0.93175 train_acc= 0.73627 val_loss= 1.35818 val_acc= 0.60000 time= 0.28600
Epoch: 0018 train_loss= 0.83500 train_acc= 0.76406 val_loss= 1.33038 val_acc= 0.62388 time= 0.30200
Epoch: 0019 train_loss= 0.74445 train_acc= 0.81039 val_loss= 1.31766 val_acc= 0.62090 time= 0.29011
Epoch: 0020 train_loss= 0.66522 train_acc= 0.83091 val_loss= 1.29291 val_acc= 0.62985 time= 0.28700
Epoch: 0021 train_loss= 0.59174 train_acc= 0.84944 val_loss= 1.27241 val_acc= 0.64179 time= 0.29400
Epoch: 0022 train_loss= 0.52081 train_acc= 0.85771 val_loss= 1.27080 val_acc= 0.64179 time= 0.29397
Epoch: 0023 train_loss= 0.46528 train_acc= 0.86731 val_loss= 1.27725 val_acc= 0.65373 time= 0.28803
Epoch: 0024 train_loss= 0.40359 train_acc= 0.89676 val_loss= 1.29139 val_acc= 0.65373 time= 0.29200
Early stopping...
Optimization Finished!
Test set results: cost= 1.30336 accuracy= 0.67029 time= 0.13100
21557
Test Precision, Recall and F1-Score...
              precision    recall  f1-score   support

           0     0.7194    0.6520    0.6840       342
           1     0.6792    0.6990    0.6890       103
           2     0.6639    0.5786    0.6183       140
           3     0.5075    0.4304    0.4658        79
           4     0.5650    0.7576    0.6472       132
           5     0.6712    0.7955    0.7281       313
           6     0.6306    0.6863    0.6573       102
           7     0.5946    0.3143    0.4112        70
           8     0.5385    0.2800    0.3684        50
           9     0.6587    0.7097    0.6832       155
          10     0.7831    0.6952    0.7365       187
          11     0.6559    0.5281    0.5851       231
          12     0.7669    0.7022    0.7331       178
          13     0.7595    0.8000    0.7792       600
          14     0.7553    0.8525    0.8010       590
          15     0.7969    0.6711    0.7286        76
          16     0.7333    0.3235    0.4490        34
          17     0.0000    0.0000    0.0000        10
          18     0.4403    0.4749    0.4569       419
          19     0.4889    0.5116    0.5000       129
          20     0.6957    0.5714    0.6275        28
          21     1.0000    0.6207    0.7660        29
          22     0.5000    0.3043    0.3784        46

    accuracy                         0.6703      4043
   macro avg     0.6350    0.5634    0.5867      4043
weighted avg     0.6700    0.6703    0.6651      4043

Macro average Test Precision, Recall and F1-Score...
(0.6349642998811341, 0.5634390972938995, 0.586689313202645, None)
Micro average Test Precision, Recall and F1-Score...
(0.6702943358891912, 0.6702943358891912, 0.6702943358891912, None)
embeddings:
14157 3357 4043
[[ 0.6228081   0.29187828  0.34786546 ...  0.42262685  0.11901676
   0.31476995]
 [ 0.36577848 -0.02779898  0.15605702 ... -0.04808381 -0.03964265
   0.08352984]
 [ 0.39437777  0.30416018  0.14369425 ...  0.08677953  0.14104487
   0.33629605]
 ...
 [ 0.18033142  0.14575824  0.1389286  ...  0.24543975  0.07093728
   0.14918928]
 [ 0.49739784 -0.00092717  0.2453987  ...  0.08092067 -0.18628782
   0.35174623]
 [ 0.25418964  0.12185423  0.30555114 ...  0.32953027  0.11252875
   0.09419636]]
