(3022, 300) (3022, 23) (4043, 300) (4043, 23) (17514, 300) (17514, 23)
21557
  (0, 3359)	5.577030769017057
  (0, 3385)	26.455355949884314
  (0, 3421)	13.939666206452838
  (0, 3587)	5.220355825078324
  (0, 3645)	0.9703478889312359
  (0, 3738)	5.8647128414688385
  (0, 3917)	19.628143287419626
  (0, 4195)	5.651138741170779
  (0, 4329)	31.721429608653622
  (0, 4385)	4.52720864451838
  (0, 4428)	19.128403576588678
  (0, 4548)	3.6781266623376743
  (0, 4600)	2.5007064881327628
  (0, 4711)	10.730794439619183
  (0, 4779)	3.68348860547906
  (0, 4822)	6.076021935136045
  (0, 4886)	1.3033452781391397
  (0, 5046)	3.7387512841541093
  (0, 5108)	13.65958747502485
  (0, 5197)	4.565429857338577
  (0, 5737)	5.731181448844316
  (0, 5896)	3.147183896412084
  (0, 5900)	1.6815727804636063
  (0, 6074)	3.7107382479264355
  (0, 6125)	4.502516031928008
  :	:
  (21556, 12648)	4.03403795599111
  (21556, 12692)	22.56882275421711
  (21556, 12705)	2.9278210679377805
  (21556, 12894)	4.53978742672524
  (21556, 12960)	2.644863488059361
  (21556, 13102)	6.963325130136948
  (21556, 13281)	3.0484490557263952
  (21556, 14226)	5.651138741170779
  (21556, 14662)	14.483872993990904
  (21556, 14684)	9.23755167608774
  (21556, 14980)	3.56690102722745
  (21556, 15283)	3.071504832026321
  (21556, 15587)	1.6650077635889111
  (21556, 15636)	4.245796185080194
  (21556, 15690)	11.729425682937677
  (21556, 15849)	3.859379271942724
  (21556, 16287)	6.076021935136045
  (21556, 16491)	3.2567460989236108
  (21556, 16547)	2.7292186255396884
  (21556, 16819)	1.8953198043817334
  (21556, 17017)	5.337918868042983
  (21556, 17066)	6.018675851219539
  (21556, 17095)	6.1366465569524795
  (21556, 17311)	6.344285921730725
  (21556, 17421)	3.744449305268747
(21557, 21557)
(21557, 21557)
21557
Tensor("graphconvolution_2/SparseTensorDenseMatMul/SparseTensorDenseMatMul:0", shape=(None, 23), dtype=float32)
Epoch: 0001 train_loss= 3.13544 train_acc= 0.08074 val_loss= 2.90190 val_acc= 0.20299 time= 0.58211
Epoch: 0002 train_loss= 2.90431 train_acc= 0.17340 val_loss= 2.75727 val_acc= 0.20299 time= 0.30003
Epoch: 0003 train_loss= 2.77576 train_acc= 0.17340 val_loss= 2.64608 val_acc= 0.20597 time= 0.28997
Epoch: 0004 train_loss= 2.65104 train_acc= 0.17968 val_loss= 2.54629 val_acc= 0.27761 time= 0.29100
Epoch: 0005 train_loss= 2.52808 train_acc= 0.25778 val_loss= 2.45263 val_acc= 0.30448 time= 0.29248
Epoch: 0006 train_loss= 2.42085 train_acc= 0.30146 val_loss= 2.31616 val_acc= 0.32836 time= 0.29603
Epoch: 0007 train_loss= 2.27312 train_acc= 0.34083 val_loss= 2.17160 val_acc= 0.36716 time= 0.29603
Epoch: 0008 train_loss= 2.11121 train_acc= 0.39246 val_loss= 2.04360 val_acc= 0.42985 time= 0.29100
Epoch: 0009 train_loss= 1.95283 train_acc= 0.47717 val_loss= 1.93049 val_acc= 0.49254 time= 0.29716
Epoch: 0010 train_loss= 1.80324 train_acc= 0.55592 val_loss= 1.81822 val_acc= 0.54627 time= 0.29002
Epoch: 0011 train_loss= 1.63893 train_acc= 0.59795 val_loss= 1.70477 val_acc= 0.54627 time= 0.29307
Epoch: 0012 train_loss= 1.48595 train_acc= 0.62475 val_loss= 1.61203 val_acc= 0.55821 time= 0.29100
Epoch: 0013 train_loss= 1.34870 train_acc= 0.65983 val_loss= 1.54357 val_acc= 0.57612 time= 0.29500
Epoch: 0014 train_loss= 1.22740 train_acc= 0.69126 val_loss= 1.47748 val_acc= 0.58806 time= 0.29003
Epoch: 0015 train_loss= 1.10188 train_acc= 0.70946 val_loss= 1.42102 val_acc= 0.59104 time= 0.28800
Epoch: 0016 train_loss= 0.98924 train_acc= 0.72965 val_loss= 1.37376 val_acc= 0.60000 time= 0.28900
Epoch: 0017 train_loss= 0.88407 train_acc= 0.76439 val_loss= 1.34302 val_acc= 0.62090 time= 0.29535
Epoch: 0018 train_loss= 0.79958 train_acc= 0.79021 val_loss= 1.32236 val_acc= 0.62388 time= 0.28600
Epoch: 0019 train_loss= 0.70461 train_acc= 0.82826 val_loss= 1.30466 val_acc= 0.62985 time= 0.29200
Epoch: 0020 train_loss= 0.61341 train_acc= 0.84183 val_loss= 1.29949 val_acc= 0.63881 time= 0.29061
Epoch: 0021 train_loss= 0.54169 train_acc= 0.85374 val_loss= 1.28649 val_acc= 0.63284 time= 0.29800
Epoch: 0022 train_loss= 0.47240 train_acc= 0.86863 val_loss= 1.27474 val_acc= 0.66866 time= 0.29109
Epoch: 0023 train_loss= 0.41336 train_acc= 0.89444 val_loss= 1.28139 val_acc= 0.66269 time= 0.29198
Epoch: 0024 train_loss= 0.35720 train_acc= 0.91628 val_loss= 1.29120 val_acc= 0.65373 time= 0.29362
Early stopping...
Optimization Finished!
Test set results: cost= 1.31692 accuracy= 0.66733 time= 0.13303
21557
Test Precision, Recall and F1-Score...
              precision    recall  f1-score   support

           0     0.7087    0.6901    0.6993       342
           1     0.7216    0.6796    0.7000       103
           2     0.6422    0.5000    0.5622       140
           3     0.4394    0.3671    0.4000        79
           4     0.6620    0.7121    0.6861       132
           5     0.7164    0.7827    0.7481       313
           6     0.6491    0.7255    0.6852       102
           7     0.4857    0.2429    0.3238        70
           8     0.6471    0.2200    0.3284        50
           9     0.5879    0.7548    0.6610       155
          10     0.7725    0.6898    0.7288       187
          11     0.6239    0.6320    0.6280       231
          12     0.7249    0.7697    0.7466       178
          13     0.7785    0.7733    0.7759       600
          14     0.8051    0.8051    0.8051       590
          15     0.7812    0.6579    0.7143        76
          16     0.5294    0.2647    0.3529        34
          17     0.0000    0.0000    0.0000        10
          18     0.3850    0.5155    0.4408       419
          19     0.6300    0.4884    0.5502       129
          20     0.8235    0.5000    0.6222        28
          21     1.0000    0.6552    0.7917        29
          22     0.4062    0.2826    0.3333        46

    accuracy                         0.6673      4043
   macro avg     0.6313    0.5526    0.5776      4043
weighted avg     0.6745    0.6673    0.6654      4043

Macro average Test Precision, Recall and F1-Score...
(0.631324620478278, 0.5525667719568409, 0.5775632141132188, None)
Micro average Test Precision, Recall and F1-Score...
(0.6673262428889438, 0.6673262428889438, 0.6673262428889438, None)
embeddings:
14157 3357 4043
[[-0.01394754  0.15127395  0.08004571 ...  0.5035579   0.31925005
   0.13310812]
 [ 0.03000801 -0.02667728  0.00228043 ...  0.01859544  0.22902222
   0.13433266]
 [-0.04418131 -0.12461057  0.04739928 ... -0.02729756  0.26138556
   0.09991812]
 ...
 [ 0.03145764  0.1155051   0.03792203 ...  0.16551621  0.03872702
   0.11578961]
 [-0.02442663 -0.12470458  0.10902766 ...  0.06294158  0.1945401
   0.37801325]
 [ 0.14842351  0.25896955  0.09986136 ...  0.23459107  0.24781717
   0.04630766]]
