(3022, 300) (3022, 23) (4043, 300) (4043, 23) (17514, 300) (17514, 23)
21557
  (0, 3359)	5.577030769017057
  (0, 3385)	26.455355949884314
  (0, 3421)	13.939666206452838
  (0, 3587)	5.220355825078324
  (0, 3645)	0.9703478889312359
  (0, 3738)	5.8647128414688385
  (0, 3917)	19.628143287419626
  (0, 4195)	5.651138741170779
  (0, 4329)	31.721429608653622
  (0, 4385)	4.52720864451838
  (0, 4428)	19.128403576588678
  (0, 4548)	3.6781266623376743
  (0, 4600)	2.5007064881327628
  (0, 4711)	10.730794439619183
  (0, 4779)	3.68348860547906
  (0, 4822)	6.076021935136045
  (0, 4886)	1.3033452781391397
  (0, 5046)	3.7387512841541093
  (0, 5108)	13.65958747502485
  (0, 5197)	4.565429857338577
  (0, 5737)	5.731181448844316
  (0, 5896)	3.147183896412084
  (0, 5900)	1.6815727804636063
  (0, 6074)	3.7107382479264355
  (0, 6125)	4.502516031928008
  :	:
  (21556, 12648)	4.03403795599111
  (21556, 12692)	22.56882275421711
  (21556, 12705)	2.9278210679377805
  (21556, 12894)	4.53978742672524
  (21556, 12960)	2.644863488059361
  (21556, 13102)	6.963325130136948
  (21556, 13281)	3.0484490557263952
  (21556, 14226)	5.651138741170779
  (21556, 14662)	14.483872993990904
  (21556, 14684)	9.23755167608774
  (21556, 14980)	3.56690102722745
  (21556, 15283)	3.071504832026321
  (21556, 15587)	1.6650077635889111
  (21556, 15636)	4.245796185080194
  (21556, 15690)	11.729425682937677
  (21556, 15849)	3.859379271942724
  (21556, 16287)	6.076021935136045
  (21556, 16491)	3.2567460989236108
  (21556, 16547)	2.7292186255396884
  (21556, 16819)	1.8953198043817334
  (21556, 17017)	5.337918868042983
  (21556, 17066)	6.018675851219539
  (21556, 17095)	6.1366465569524795
  (21556, 17311)	6.344285921730725
  (21556, 17421)	3.744449305268747
(21557, 21557)
(21557, 21557)
21557
Tensor("graphconvolution_2/SparseTensorDenseMatMul/SparseTensorDenseMatMul:0", shape=(None, 23), dtype=float32)
Epoch: 0001 train_loss= 3.13549 train_acc= 0.01655 val_loss= 2.89935 val_acc= 0.20000 time= 0.58416
Epoch: 0002 train_loss= 2.90384 train_acc= 0.17174 val_loss= 2.76329 val_acc= 0.20597 time= 0.29200
Epoch: 0003 train_loss= 2.78432 train_acc= 0.17406 val_loss= 2.65114 val_acc= 0.20597 time= 0.28912
Epoch: 0004 train_loss= 2.66469 train_acc= 0.17604 val_loss= 2.55916 val_acc= 0.28060 time= 0.28897
Epoch: 0005 train_loss= 2.54301 train_acc= 0.25480 val_loss= 2.48449 val_acc= 0.31045 time= 0.28910
Epoch: 0006 train_loss= 2.45249 train_acc= 0.29815 val_loss= 2.35039 val_acc= 0.32537 time= 0.28901
Epoch: 0007 train_loss= 2.30605 train_acc= 0.33521 val_loss= 2.20973 val_acc= 0.35821 time= 0.28577
Epoch: 0008 train_loss= 2.15743 train_acc= 0.36466 val_loss= 2.09330 val_acc= 0.39104 time= 0.29003
Epoch: 0009 train_loss= 2.01493 train_acc= 0.42323 val_loss= 1.98407 val_acc= 0.45970 time= 0.28681
Epoch: 0010 train_loss= 1.87147 train_acc= 0.51985 val_loss= 1.88345 val_acc= 0.52537 time= 0.29000
Epoch: 0011 train_loss= 1.72712 train_acc= 0.57975 val_loss= 1.78361 val_acc= 0.52537 time= 0.29100
Epoch: 0012 train_loss= 1.57924 train_acc= 0.61383 val_loss= 1.69493 val_acc= 0.55224 time= 0.29200
Epoch: 0013 train_loss= 1.45177 train_acc= 0.63369 val_loss= 1.61831 val_acc= 0.57313 time= 0.28900
Epoch: 0014 train_loss= 1.33004 train_acc= 0.67604 val_loss= 1.54845 val_acc= 0.58209 time= 0.28713
Epoch: 0015 train_loss= 1.20487 train_acc= 0.69656 val_loss= 1.48624 val_acc= 0.58806 time= 0.28800
Epoch: 0016 train_loss= 1.09408 train_acc= 0.71244 val_loss= 1.43777 val_acc= 0.58507 time= 0.28600
Epoch: 0017 train_loss= 0.99032 train_acc= 0.73561 val_loss= 1.40025 val_acc= 0.60597 time= 0.28900
Epoch: 0018 train_loss= 0.89480 train_acc= 0.76406 val_loss= 1.37492 val_acc= 0.60299 time= 0.28800
Epoch: 0019 train_loss= 0.80672 train_acc= 0.79649 val_loss= 1.35399 val_acc= 0.60299 time= 0.29201
Epoch: 0020 train_loss= 0.71772 train_acc= 0.81271 val_loss= 1.32858 val_acc= 0.60597 time= 0.28900
Epoch: 0021 train_loss= 0.64087 train_acc= 0.82760 val_loss= 1.30489 val_acc= 0.60896 time= 0.28800
Epoch: 0022 train_loss= 0.57249 train_acc= 0.84811 val_loss= 1.29249 val_acc= 0.62687 time= 0.29100
Epoch: 0023 train_loss= 0.50820 train_acc= 0.86234 val_loss= 1.29508 val_acc= 0.63284 time= 0.28700
Epoch: 0024 train_loss= 0.43660 train_acc= 0.88584 val_loss= 1.30047 val_acc= 0.64776 time= 0.28700
Epoch: 0025 train_loss= 0.37884 train_acc= 0.90569 val_loss= 1.29426 val_acc= 0.64776 time= 0.28700
Epoch: 0026 train_loss= 0.32737 train_acc= 0.91396 val_loss= 1.29214 val_acc= 0.65075 time= 0.29000
Epoch: 0027 train_loss= 0.28707 train_acc= 0.93018 val_loss= 1.30950 val_acc= 0.65075 time= 0.28900
Epoch: 0028 train_loss= 0.24490 train_acc= 0.94077 val_loss= 1.31589 val_acc= 0.66269 time= 0.28797
Early stopping...
Optimization Finished!
Test set results: cost= 1.29432 accuracy= 0.68019 time= 0.12803
21557
Test Precision, Recall and F1-Score...
              precision    recall  f1-score   support

           0     0.7262    0.6901    0.7076       342
           1     0.6387    0.7379    0.6847       103
           2     0.6842    0.6500    0.6667       140
           3     0.4149    0.4937    0.4509        79
           4     0.6757    0.7576    0.7143       132
           5     0.6536    0.8019    0.7202       313
           6     0.6167    0.7255    0.6667       102
           7     0.5778    0.3714    0.4522        70
           8     0.5143    0.3600    0.4235        50
           9     0.6141    0.7290    0.6667       155
          10     0.8182    0.6738    0.7390       187
          11     0.6410    0.6494    0.6452       231
          12     0.7683    0.7079    0.7368       178
          13     0.7776    0.7867    0.7821       600
          14     0.7828    0.8492    0.8146       590
          15     0.7361    0.6974    0.7162        76
          16     0.7143    0.2941    0.4167        34
          17     0.5000    0.1000    0.1667        10
          18     0.4387    0.4272    0.4329       419
          19     0.6304    0.4496    0.5249       129
          20     0.5926    0.5714    0.5818        28
          21     0.9524    0.6897    0.8000        29
          22     0.6667    0.3043    0.4179        46

    accuracy                         0.6802      4043
   macro avg     0.6581    0.5877    0.6056      4043
weighted avg     0.6807    0.6802    0.6757      4043

Macro average Test Precision, Recall and F1-Score...
(0.6580521841019563, 0.5877220285251771, 0.6055746258331296, None)
Micro average Test Precision, Recall and F1-Score...
(0.680187979223349, 0.680187979223349, 0.680187979223349, None)
embeddings:
14157 3357 4043
[[ 0.3431137   0.15997274  0.4656859  ... -0.58133787  0.42094272
   0.69683295]
 [ 0.17256276 -0.11271356 -0.14939433 ... -0.16467345  0.09777416
   0.24380295]
 [ 0.36627847 -0.06477924  0.4751764  ... -0.3576121   0.25042993
   0.47251028]
 ...
 [ 0.08133048  0.11338073  0.34165365 ... -0.17803289  0.09600499
   0.39462122]
 [ 0.3227006  -0.16660699  0.12044197 ... -0.18832484  0.47374582
   0.6900939 ]
 [ 0.2144774   0.320277    0.06347802 ... -0.1831866   0.21649525
   0.2816575 ]]
