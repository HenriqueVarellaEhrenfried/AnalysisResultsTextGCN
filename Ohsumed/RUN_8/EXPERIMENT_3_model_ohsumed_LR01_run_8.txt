(3022, 300) (3022, 23) (4043, 300) (4043, 23) (17514, 300) (17514, 23)
21557
  (0, 3359)	5.577030769017057
  (0, 3385)	26.455355949884314
  (0, 3421)	13.939666206452838
  (0, 3587)	5.220355825078324
  (0, 3645)	0.9703478889312359
  (0, 3738)	5.8647128414688385
  (0, 3917)	19.628143287419626
  (0, 4195)	5.651138741170779
  (0, 4329)	31.721429608653622
  (0, 4385)	4.52720864451838
  (0, 4428)	19.128403576588678
  (0, 4548)	3.6781266623376743
  (0, 4600)	2.5007064881327628
  (0, 4711)	10.730794439619183
  (0, 4779)	3.68348860547906
  (0, 4822)	6.076021935136045
  (0, 4886)	1.3033452781391397
  (0, 5046)	3.7387512841541093
  (0, 5108)	13.65958747502485
  (0, 5197)	4.565429857338577
  (0, 5737)	5.731181448844316
  (0, 5896)	3.147183896412084
  (0, 5900)	1.6815727804636063
  (0, 6074)	3.7107382479264355
  (0, 6125)	4.502516031928008
  :	:
  (21556, 12648)	4.03403795599111
  (21556, 12692)	22.56882275421711
  (21556, 12705)	2.9278210679377805
  (21556, 12894)	4.53978742672524
  (21556, 12960)	2.644863488059361
  (21556, 13102)	6.963325130136948
  (21556, 13281)	3.0484490557263952
  (21556, 14226)	5.651138741170779
  (21556, 14662)	14.483872993990904
  (21556, 14684)	9.23755167608774
  (21556, 14980)	3.56690102722745
  (21556, 15283)	3.071504832026321
  (21556, 15587)	1.6650077635889111
  (21556, 15636)	4.245796185080194
  (21556, 15690)	11.729425682937677
  (21556, 15849)	3.859379271942724
  (21556, 16287)	6.076021935136045
  (21556, 16491)	3.2567460989236108
  (21556, 16547)	2.7292186255396884
  (21556, 16819)	1.8953198043817334
  (21556, 17017)	5.337918868042983
  (21556, 17066)	6.018675851219539
  (21556, 17095)	6.1366465569524795
  (21556, 17311)	6.344285921730725
  (21556, 17421)	3.744449305268747
(21557, 21557)
(21557, 21557)
21557
Tensor("graphconvolution_2/SparseTensorDenseMatMul/SparseTensorDenseMatMul:0", shape=(None, 23), dtype=float32)
Epoch: 0001 train_loss= 3.13545 train_acc= 0.05030 val_loss= 2.91299 val_acc= 0.28358 time= 0.59100
Epoch: 0002 train_loss= 2.91370 train_acc= 0.25711 val_loss= 2.73853 val_acc= 0.25373 time= 0.29601
Epoch: 0003 train_loss= 2.76182 train_acc= 0.23197 val_loss= 2.66790 val_acc= 0.20000 time= 0.29100
Epoch: 0004 train_loss= 2.68529 train_acc= 0.17141 val_loss= 2.55449 val_acc= 0.25672 time= 0.28808
Epoch: 0005 train_loss= 2.52872 train_acc= 0.22700 val_loss= 2.48376 val_acc= 0.31642 time= 0.29370
Epoch: 0006 train_loss= 2.42827 train_acc= 0.30940 val_loss= 2.35499 val_acc= 0.37313 time= 0.29803
Epoch: 0007 train_loss= 2.28892 train_acc= 0.38054 val_loss= 2.19264 val_acc= 0.39403 time= 0.28700
Epoch: 0008 train_loss= 2.11339 train_acc= 0.41992 val_loss= 2.05896 val_acc= 0.39701 time= 0.29197
Epoch: 0009 train_loss= 1.97678 train_acc= 0.45069 val_loss= 1.94039 val_acc= 0.47463 time= 0.29312
Epoch: 0010 train_loss= 1.81745 train_acc= 0.51985 val_loss= 1.82992 val_acc= 0.50149 time= 0.29300
Epoch: 0011 train_loss= 1.66357 train_acc= 0.57512 val_loss= 1.74886 val_acc= 0.51940 time= 0.29000
Epoch: 0012 train_loss= 1.51297 train_acc= 0.61218 val_loss= 1.67323 val_acc= 0.54030 time= 0.28700
Epoch: 0013 train_loss= 1.38929 train_acc= 0.64593 val_loss= 1.59296 val_acc= 0.56418 time= 0.28897
Epoch: 0014 train_loss= 1.26720 train_acc= 0.68696 val_loss= 1.51154 val_acc= 0.57015 time= 0.29561
Epoch: 0015 train_loss= 1.13809 train_acc= 0.71211 val_loss= 1.45353 val_acc= 0.57910 time= 0.28697
Epoch: 0016 train_loss= 1.03804 train_acc= 0.72071 val_loss= 1.41214 val_acc= 0.58806 time= 0.28801
Epoch: 0017 train_loss= 0.93070 train_acc= 0.74388 val_loss= 1.38336 val_acc= 0.60597 time= 0.28999
Epoch: 0018 train_loss= 0.83495 train_acc= 0.77929 val_loss= 1.35708 val_acc= 0.61493 time= 0.29704
Epoch: 0019 train_loss= 0.74379 train_acc= 0.80973 val_loss= 1.32418 val_acc= 0.61194 time= 0.28796
Epoch: 0020 train_loss= 0.66048 train_acc= 0.82660 val_loss= 1.29397 val_acc= 0.62985 time= 0.29103
Epoch: 0021 train_loss= 0.57590 train_acc= 0.84613 val_loss= 1.28267 val_acc= 0.62687 time= 0.28664
Epoch: 0022 train_loss= 0.50833 train_acc= 0.86102 val_loss= 1.28775 val_acc= 0.64179 time= 0.29737
Epoch: 0023 train_loss= 0.44077 train_acc= 0.88253 val_loss= 1.28902 val_acc= 0.65970 time= 0.28797
Epoch: 0024 train_loss= 0.38538 train_acc= 0.90801 val_loss= 1.28033 val_acc= 0.65373 time= 0.28710
Epoch: 0025 train_loss= 0.33307 train_acc= 0.91628 val_loss= 1.28881 val_acc= 0.63881 time= 0.28833
Epoch: 0026 train_loss= 0.29106 train_acc= 0.92654 val_loss= 1.29013 val_acc= 0.66866 time= 0.29297
Epoch: 0027 train_loss= 0.25294 train_acc= 0.93911 val_loss= 1.30630 val_acc= 0.67164 time= 0.29003
Epoch: 0028 train_loss= 0.22038 train_acc= 0.94672 val_loss= 1.32510 val_acc= 0.67463 time= 0.28800
Early stopping...
Optimization Finished!
Test set results: cost= 1.31245 accuracy= 0.67771 time= 0.12797
21557
Test Precision, Recall and F1-Score...
              precision    recall  f1-score   support

           0     0.7233    0.6725    0.6970       342
           1     0.7245    0.6893    0.7065       103
           2     0.7321    0.5857    0.6508       140
           3     0.4648    0.4177    0.4400        79
           4     0.6667    0.7727    0.7158       132
           5     0.7256    0.7604    0.7426       313
           6     0.6063    0.7549    0.6725       102
           7     0.4902    0.3571    0.4132        70
           8     0.5625    0.3600    0.4390        50
           9     0.6450    0.7032    0.6728       155
          10     0.8146    0.6578    0.7278       187
          11     0.6636    0.6234    0.6429       231
          12     0.7458    0.7416    0.7437       178
          13     0.7628    0.7933    0.7778       600
          14     0.7515    0.8508    0.7981       590
          15     0.7465    0.6974    0.7211        76
          16     0.6667    0.4118    0.5091        34
          17     0.5000    0.1000    0.1667        10
          18     0.4200    0.4821    0.4489       419
          19     0.6087    0.4341    0.5068       129
          20     0.6667    0.5714    0.6154        28
          21     0.9091    0.6897    0.7843        29
          22     0.4706    0.3478    0.4000        46

    accuracy                         0.6777      4043
   macro avg     0.6551    0.5859    0.6084      4043
weighted avg     0.6791    0.6777    0.6747      4043

Macro average Test Precision, Recall and F1-Score...
(0.655101026692842, 0.5858603599517815, 0.6083742013492108, None)
Micro average Test Precision, Recall and F1-Score...
(0.6777145683898096, 0.6777145683898096, 0.6777145683898096, None)
embeddings:
14157 3357 4043
[[ 0.28256637 -0.5757457   0.18972342 ... -0.6662961   0.4703949
   0.05296927]
 [ 0.30067426 -0.15652691  0.10225321 ... -0.17831427  0.26048455
   0.05082376]
 [ 0.31015456 -0.3566686   0.09500392 ... -0.37637353  0.54801965
   0.1638781 ]
 ...
 [ 0.17783678 -0.18289226  0.12205225 ... -0.21124595  0.17879742
   0.02387702]
 [ 0.07858792 -0.15719746 -0.14180595 ... -0.2120245   0.5328671
  -0.09680271]
 [ 0.15598059 -0.18826267  0.24491194 ... -0.2065114   0.15188834
   0.14784265]]
