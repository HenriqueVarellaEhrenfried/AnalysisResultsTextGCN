(3022, 300) (3022, 23) (4043, 300) (4043, 23) (17514, 300) (17514, 23)
21557
  (0, 3359)	5.577030769017057
  (0, 3385)	26.455355949884314
  (0, 3421)	13.939666206452838
  (0, 3587)	5.220355825078324
  (0, 3645)	0.9703478889312359
  (0, 3738)	5.8647128414688385
  (0, 3917)	19.628143287419626
  (0, 4195)	5.651138741170779
  (0, 4329)	31.721429608653622
  (0, 4385)	4.52720864451838
  (0, 4428)	19.128403576588678
  (0, 4548)	3.6781266623376743
  (0, 4600)	2.5007064881327628
  (0, 4711)	10.730794439619183
  (0, 4779)	3.68348860547906
  (0, 4822)	6.076021935136045
  (0, 4886)	1.3033452781391397
  (0, 5046)	3.7387512841541093
  (0, 5108)	13.65958747502485
  (0, 5197)	4.565429857338577
  (0, 5737)	5.731181448844316
  (0, 5896)	3.147183896412084
  (0, 5900)	1.6815727804636063
  (0, 6074)	3.7107382479264355
  (0, 6125)	4.502516031928008
  :	:
  (21556, 12648)	4.03403795599111
  (21556, 12692)	22.56882275421711
  (21556, 12705)	2.9278210679377805
  (21556, 12894)	4.53978742672524
  (21556, 12960)	2.644863488059361
  (21556, 13102)	6.963325130136948
  (21556, 13281)	3.0484490557263952
  (21556, 14226)	5.651138741170779
  (21556, 14662)	14.483872993990904
  (21556, 14684)	9.23755167608774
  (21556, 14980)	3.56690102722745
  (21556, 15283)	3.071504832026321
  (21556, 15587)	1.6650077635889111
  (21556, 15636)	4.245796185080194
  (21556, 15690)	11.729425682937677
  (21556, 15849)	3.859379271942724
  (21556, 16287)	6.076021935136045
  (21556, 16491)	3.2567460989236108
  (21556, 16547)	2.7292186255396884
  (21556, 16819)	1.8953198043817334
  (21556, 17017)	5.337918868042983
  (21556, 17066)	6.018675851219539
  (21556, 17095)	6.1366465569524795
  (21556, 17311)	6.344285921730725
  (21556, 17421)	3.744449305268747
(21557, 21557)
(21557, 21557)
21557
Tensor("graphconvolution_2/SparseTensorDenseMatMul/SparseTensorDenseMatMul:0", shape=(None, 23), dtype=float32)
Epoch: 0001 train_loss= 3.13558 train_acc= 0.01224 val_loss= 2.94754 val_acc= 0.22687 time= 0.58731
Epoch: 0002 train_loss= 2.94963 train_acc= 0.19193 val_loss= 2.71262 val_acc= 0.22090 time= 0.29456
Epoch: 0003 train_loss= 2.72969 train_acc= 0.18994 val_loss= 2.73307 val_acc= 0.20000 time= 0.29300
Epoch: 0004 train_loss= 2.75087 train_acc= 0.17141 val_loss= 2.56551 val_acc= 0.25075 time= 0.28900
Epoch: 0005 train_loss= 2.54369 train_acc= 0.22932 val_loss= 2.49254 val_acc= 0.32836 time= 0.28700
Epoch: 0006 train_loss= 2.44278 train_acc= 0.33388 val_loss= 2.39335 val_acc= 0.42090 time= 0.29400
Epoch: 0007 train_loss= 2.32937 train_acc= 0.43150 val_loss= 2.23697 val_acc= 0.42388 time= 0.29100
Epoch: 0008 train_loss= 2.16209 train_acc= 0.43647 val_loss= 2.09207 val_acc= 0.40299 time= 0.28900
Epoch: 0009 train_loss= 1.99511 train_acc= 0.43845 val_loss= 1.97923 val_acc= 0.40896 time= 0.29097
Epoch: 0010 train_loss= 1.85275 train_acc= 0.47419 val_loss= 1.85079 val_acc= 0.48955 time= 0.29800
Epoch: 0011 train_loss= 1.68148 train_acc= 0.57081 val_loss= 1.75342 val_acc= 0.52537 time= 0.29476
Epoch: 0012 train_loss= 1.53258 train_acc= 0.60854 val_loss= 1.65888 val_acc= 0.54030 time= 0.28900
Epoch: 0013 train_loss= 1.39732 train_acc= 0.64394 val_loss= 1.57670 val_acc= 0.56716 time= 0.29150
Epoch: 0014 train_loss= 1.26581 train_acc= 0.69259 val_loss= 1.50605 val_acc= 0.58806 time= 0.29500
Epoch: 0015 train_loss= 1.14586 train_acc= 0.71840 val_loss= 1.43937 val_acc= 0.59104 time= 0.29000
Epoch: 0016 train_loss= 1.03400 train_acc= 0.72237 val_loss= 1.38584 val_acc= 0.59701 time= 0.28800
Epoch: 0017 train_loss= 0.92560 train_acc= 0.74255 val_loss= 1.34664 val_acc= 0.60597 time= 0.29300
Epoch: 0018 train_loss= 0.83554 train_acc= 0.77300 val_loss= 1.31685 val_acc= 0.60299 time= 0.29297
Epoch: 0019 train_loss= 0.73824 train_acc= 0.81271 val_loss= 1.30069 val_acc= 0.61194 time= 0.29003
Epoch: 0020 train_loss= 0.65617 train_acc= 0.83157 val_loss= 1.27020 val_acc= 0.63582 time= 0.28711
Epoch: 0021 train_loss= 0.57433 train_acc= 0.84712 val_loss= 1.24654 val_acc= 0.64478 time= 0.29612
Epoch: 0022 train_loss= 0.50536 train_acc= 0.86234 val_loss= 1.23636 val_acc= 0.64478 time= 0.29410
Epoch: 0023 train_loss= 0.44073 train_acc= 0.87492 val_loss= 1.24488 val_acc= 0.63881 time= 0.29000
Epoch: 0024 train_loss= 0.38778 train_acc= 0.89808 val_loss= 1.25314 val_acc= 0.68060 time= 0.29300
Epoch: 0025 train_loss= 0.33883 train_acc= 0.91727 val_loss= 1.25755 val_acc= 0.67463 time= 0.29606
Epoch: 0026 train_loss= 0.29222 train_acc= 0.92985 val_loss= 1.26740 val_acc= 0.65373 time= 0.29003
Epoch: 0027 train_loss= 0.25412 train_acc= 0.93580 val_loss= 1.26091 val_acc= 0.65970 time= 0.29000
Epoch: 0028 train_loss= 0.21525 train_acc= 0.94606 val_loss= 1.27947 val_acc= 0.67463 time= 0.29300
Early stopping...
Optimization Finished!
Test set results: cost= 1.30069 accuracy= 0.68415 time= 0.13100
21557
Test Precision, Recall and F1-Score...
              precision    recall  f1-score   support

           0     0.7104    0.6813    0.6955       342
           1     0.7117    0.7670    0.7383       103
           2     0.6870    0.6429    0.6642       140
           3     0.6400    0.4051    0.4961        79
           4     0.6690    0.7348    0.7004       132
           5     0.6702    0.8051    0.7315       313
           6     0.6696    0.7353    0.7009       102
           7     0.6053    0.3286    0.4259        70
           8     0.5833    0.4200    0.4884        50
           9     0.6162    0.7355    0.6706       155
          10     0.8098    0.7059    0.7543       187
          11     0.5916    0.6710    0.6288       231
          12     0.8000    0.6966    0.7447       178
          13     0.7309    0.8150    0.7707       600
          14     0.7642    0.8458    0.8029       590
          15     0.7606    0.7105    0.7347        76
          16     0.6364    0.4118    0.5000        34
          17     0.3333    0.1000    0.1538        10
          18     0.4598    0.3962    0.4256       419
          19     0.6562    0.4884    0.5600       129
          20     0.5862    0.6071    0.5965        28
          21     0.9524    0.6897    0.8000        29
          22     0.6154    0.3478    0.4444        46

    accuracy                         0.6841      4043
   macro avg     0.6635    0.5974    0.6186      4043
weighted avg     0.6799    0.6841    0.6771      4043

Macro average Test Precision, Recall and F1-Score...
(0.6634598705272162, 0.5974454592533898, 0.6186252093422299, None)
Micro average Test Precision, Recall and F1-Score...
(0.6841454365570121, 0.6841454365570121, 0.6841454365570121, None)
embeddings:
14157 3357 4043
[[ 0.13209045  0.4069163   0.3295235  ...  0.5855633   0.12881391
   0.35492155]
 [-0.11831968 -0.04372505  0.14030823 ...  0.23548366 -0.10493299
   0.2926646 ]
 [ 0.04212461  0.2787584   0.03419599 ...  0.26187217  0.10877195
   0.37498552]
 ...
 [ 0.07731706  0.19776177  0.03295865 ...  0.44700974  0.02783723
   0.18843725]
 [-0.1343959   0.04303359  0.63462365 ... -0.06681706  0.0789163
  -0.0732958 ]
 [ 0.24546665  0.17788433  0.2562431  ...  0.24234274  0.06186622
   0.29328758]]
