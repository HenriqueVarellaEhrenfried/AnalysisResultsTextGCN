(4937, 300) (4937, 8) (2189, 300) (2189, 8) (13173, 300) (13173, 8)
15362
  (0, 5864)	1.021520945883481
  (0, 6572)	4.818458885761806
  (0, 7052)	3.362096962025199
  (0, 7916)	1.2457508634099117
  (0, 7933)	2.0838819303261675
  (0, 8096)	0.686135075474489
  (0, 9590)	1.1548972396321597
  (0, 10449)	5.949860997252907
  (0, 10914)	2.080745492836037
  (0, 11036)	1.6330397727043
  (0, 11444)	0.09164216929228669
  (0, 11878)	3.647275904258861
  (0, 12720)	0.9536627509544204
  (1, 5523)	5.7267174459386965
  (1, 5674)	3.6274732769626814
  (1, 5758)	4.360625792136326
  (1, 5917)	7.153833801578843
  (1, 5969)	7.631389111767649
  (1, 6209)	5.161403636888637
  (1, 6216)	3.9217127499606215
  (1, 6333)	6.547697998008527
  (1, 6737)	3.989766213205637
  (1, 6888)	1.7407007606022247
  (1, 7223)	2.810028379725159
  (1, 7295)	2.0131453792343894
  :	:
  (15361, 10641)	4.975301357254776
  (15361, 10690)	3.30014637316366
  (15361, 10787)	2.680292058069188
  (15361, 10833)	2.6898432290535306
  (15361, 10951)	4.868055826901179
  (15361, 11049)	3.7091513079769487
  (15361, 11110)	3.381072863484204
  (15361, 11181)	2.7552778649537504
  (15361, 11213)	2.929436111108544
  (15361, 11216)	6.866151729127062
  (15361, 11246)	3.88934746545859
  (15361, 11252)	5.687496732785416
  (15361, 11271)	0.967968172022305
  (15361, 11444)	0.09164216929228669
  (15361, 11902)	2.548663615590751
  (15361, 11922)	3.01069907518731
  (15361, 12000)	4.093563006887281
  (15361, 12048)	7.336155358372797
  (15361, 12172)	3.1962002848986444
  (15361, 12457)	4.5267526630103
  (15361, 12548)	3.0678574890272587
  (15361, 12694)	3.775109275768746
  (15361, 12757)	47.08188589283273
  (15361, 12768)	3.9416469648614387
  (15361, 13025)	6.921592674632485
(15362, 15362)
(15362, 15362)
15362
Tensor("graphconvolution_2/SparseTensorDenseMatMul/SparseTensorDenseMatMul:0", shape=(None, 8), dtype=float32)
Epoch: 0001 train_loss= 2.07967 train_acc= 0.03788 val_loss= 1.63719 val_acc= 0.70803 time= 0.40700
Epoch: 0002 train_loss= 1.61178 train_acc= 0.72412 val_loss= 1.27660 val_acc= 0.66423 time= 0.12700
Epoch: 0003 train_loss= 1.22941 train_acc= 0.68726 val_loss= 1.07881 val_acc= 0.65511 time= 0.12400
Epoch: 0004 train_loss= 1.02837 train_acc= 0.67328 val_loss= 0.84058 val_acc= 0.75182 time= 0.12307
Epoch: 0005 train_loss= 0.79810 train_acc= 0.78327 val_loss= 0.70807 val_acc= 0.75365 time= 0.12401
Epoch: 0006 train_loss= 0.66163 train_acc= 0.77719 val_loss= 0.64548 val_acc= 0.75912 time= 0.12403
Epoch: 0007 train_loss= 0.59898 train_acc= 0.78469 val_loss= 0.60886 val_acc= 0.78650 time= 0.12765
Epoch: 0008 train_loss= 0.54969 train_acc= 0.81061 val_loss= 0.57315 val_acc= 0.79197 time= 0.15754
Epoch: 0009 train_loss= 0.51145 train_acc= 0.82499 val_loss= 0.53821 val_acc= 0.82117 time= 0.12711
Epoch: 0010 train_loss= 0.46790 train_acc= 0.84383 val_loss= 0.50565 val_acc= 0.83759 time= 0.12342
Epoch: 0011 train_loss= 0.42988 train_acc= 0.86064 val_loss= 0.47251 val_acc= 0.85036 time= 0.12400
Epoch: 0012 train_loss= 0.38890 train_acc= 0.87887 val_loss= 0.43840 val_acc= 0.87226 time= 0.12400
Epoch: 0013 train_loss= 0.35850 train_acc= 0.88920 val_loss= 0.40674 val_acc= 0.88686 time= 0.12201
Epoch: 0014 train_loss= 0.32493 train_acc= 0.90196 val_loss= 0.37861 val_acc= 0.89416 time= 0.12399
Epoch: 0015 train_loss= 0.28408 train_acc= 0.91695 val_loss= 0.35590 val_acc= 0.90146 time= 0.12400
Epoch: 0016 train_loss= 0.25593 train_acc= 0.92445 val_loss= 0.33955 val_acc= 0.92336 time= 0.15700
Epoch: 0017 train_loss= 0.22454 train_acc= 0.94025 val_loss= 0.32299 val_acc= 0.92153 time= 0.12900
Epoch: 0018 train_loss= 0.20192 train_acc= 0.94855 val_loss= 0.30388 val_acc= 0.92883 time= 0.12600
Epoch: 0019 train_loss= 0.17711 train_acc= 0.95098 val_loss= 0.28474 val_acc= 0.93248 time= 0.12400
Epoch: 0020 train_loss= 0.15148 train_acc= 0.95726 val_loss= 0.26841 val_acc= 0.93613 time= 0.12397
Epoch: 0021 train_loss= 0.13504 train_acc= 0.96152 val_loss= 0.25811 val_acc= 0.93613 time= 0.12505
Epoch: 0022 train_loss= 0.12325 train_acc= 0.96496 val_loss= 0.25104 val_acc= 0.94343 time= 0.12399
Epoch: 0023 train_loss= 0.10315 train_acc= 0.97022 val_loss= 0.24887 val_acc= 0.94708 time= 0.12500
Epoch: 0024 train_loss= 0.09391 train_acc= 0.97104 val_loss= 0.25123 val_acc= 0.94161 time= 0.15900
Epoch: 0025 train_loss= 0.08022 train_acc= 0.97509 val_loss= 0.25196 val_acc= 0.94161 time= 0.12500
Epoch: 0026 train_loss= 0.07438 train_acc= 0.97468 val_loss= 0.25046 val_acc= 0.94343 time= 0.12701
Epoch: 0027 train_loss= 0.06626 train_acc= 0.97833 val_loss= 0.24664 val_acc= 0.94708 time= 0.12599
Epoch: 0028 train_loss= 0.06088 train_acc= 0.97995 val_loss= 0.24609 val_acc= 0.95073 time= 0.12600
Epoch: 0029 train_loss= 0.05281 train_acc= 0.98359 val_loss= 0.24399 val_acc= 0.95255 time= 0.12307
Epoch: 0030 train_loss= 0.04738 train_acc= 0.98663 val_loss= 0.24229 val_acc= 0.94891 time= 0.12401
Epoch: 0031 train_loss= 0.04399 train_acc= 0.98643 val_loss= 0.24303 val_acc= 0.95255 time= 0.16902
Epoch: 0032 train_loss= 0.04174 train_acc= 0.98663 val_loss= 0.24369 val_acc= 0.95255 time= 0.12296
Epoch: 0033 train_loss= 0.03484 train_acc= 0.98886 val_loss= 0.24936 val_acc= 0.95255 time= 0.12313
Early stopping...
Optimization Finished!
Test set results: cost= 0.14910 accuracy= 0.96528 time= 0.05696
15362
Test Precision, Recall and F1-Score...
              precision    recall  f1-score   support

           0     0.9274    0.9504    0.9388       121
           1     0.8675    0.9600    0.9114        75
           2     0.9790    0.9908    0.9849      1083
           3     0.6250    0.5000    0.5556        10
           4     0.9000    0.7500    0.8182        36
           5     0.8588    0.9012    0.8795        81
           6     0.9268    0.8736    0.8994        87
           7     0.9868    0.9655    0.9760       696

    accuracy                         0.9653      2189
   macro avg     0.8839    0.8614    0.8705      2189
weighted avg     0.9654    0.9653    0.9650      2189

Macro average Test Precision, Recall and F1-Score...
(0.8839175964463173, 0.8614368300587752, 0.8704652427474762, None)
Micro average Test Precision, Recall and F1-Score...
(0.9652809502055734, 0.9652809502055734, 0.9652809502055734, None)
embeddings:
7688 5485 2189
[[ 0.13737476 -0.35310245  0.29283828 ...  0.85451335  0.17836337
   0.06503879]
 [-0.1537882  -0.32226655 -0.15440921 ...  0.5088326  -0.1831122
   0.13584627]
 [ 0.01883638 -0.39543247 -0.20227648 ...  0.4359575  -0.15617415
   0.66032916]
 ...
 [ 0.26126194 -0.40662906 -0.05685613 ...  0.47849706 -0.00753163
   0.73905456]
 [-0.327661   -0.45915672 -0.32605535 ...  0.49929798 -0.3630602
   0.07204737]
 [ 0.16332732 -0.30098337 -0.02925642 ...  0.1641613   0.05330135
   0.55567765]]
