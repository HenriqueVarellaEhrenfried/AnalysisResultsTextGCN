(4937, 300) (4937, 8) (2189, 300) (2189, 8) (13173, 300) (13173, 8)
15362
  (0, 5864)	1.021520945883481
  (0, 6572)	4.818458885761806
  (0, 7052)	3.362096962025199
  (0, 7916)	1.2457508634099117
  (0, 7933)	2.0838819303261675
  (0, 8096)	0.686135075474489
  (0, 9590)	1.1548972396321597
  (0, 10449)	5.949860997252907
  (0, 10914)	2.080745492836037
  (0, 11036)	1.6330397727043
  (0, 11444)	0.09164216929228669
  (0, 11878)	3.647275904258861
  (0, 12720)	0.9536627509544204
  (1, 5523)	5.7267174459386965
  (1, 5674)	3.6274732769626814
  (1, 5758)	4.360625792136326
  (1, 5917)	7.153833801578843
  (1, 5969)	7.631389111767649
  (1, 6209)	5.161403636888637
  (1, 6216)	3.9217127499606215
  (1, 6333)	6.547697998008527
  (1, 6737)	3.989766213205637
  (1, 6888)	1.7407007606022247
  (1, 7223)	2.810028379725159
  (1, 7295)	2.0131453792343894
  :	:
  (15361, 10641)	4.975301357254776
  (15361, 10690)	3.30014637316366
  (15361, 10787)	2.680292058069188
  (15361, 10833)	2.6898432290535306
  (15361, 10951)	4.868055826901179
  (15361, 11049)	3.7091513079769487
  (15361, 11110)	3.381072863484204
  (15361, 11181)	2.7552778649537504
  (15361, 11213)	2.929436111108544
  (15361, 11216)	6.866151729127062
  (15361, 11246)	3.88934746545859
  (15361, 11252)	5.687496732785416
  (15361, 11271)	0.967968172022305
  (15361, 11444)	0.09164216929228669
  (15361, 11902)	2.548663615590751
  (15361, 11922)	3.01069907518731
  (15361, 12000)	4.093563006887281
  (15361, 12048)	7.336155358372797
  (15361, 12172)	3.1962002848986444
  (15361, 12457)	4.5267526630103
  (15361, 12548)	3.0678574890272587
  (15361, 12694)	3.775109275768746
  (15361, 12757)	47.08188589283273
  (15361, 12768)	3.9416469648614387
  (15361, 13025)	6.921592674632485
(15362, 15362)
(15362, 15362)
15362
Tensor("graphconvolution_2/SparseTensorDenseMatMul/SparseTensorDenseMatMul:0", shape=(None, 8), dtype=float32)
Epoch: 0001 train_loss= 2.07933 train_acc= 0.20194 val_loss= 2.05449 val_acc= 0.75000 time= 0.38800
Epoch: 0002 train_loss= 2.05360 train_acc= 0.76605 val_loss= 2.01789 val_acc= 0.74453 time= 0.13016
Epoch: 0003 train_loss= 2.01546 train_acc= 0.76281 val_loss= 1.97027 val_acc= 0.74270 time= 0.13300
Epoch: 0004 train_loss= 1.97054 train_acc= 0.75815 val_loss= 1.91217 val_acc= 0.73723 time= 0.13900
Epoch: 0005 train_loss= 1.90622 train_acc= 0.75066 val_loss= 1.84467 val_acc= 0.73540 time= 0.12700
Epoch: 0006 train_loss= 1.83820 train_acc= 0.75127 val_loss= 1.76956 val_acc= 0.73358 time= 0.12600
Epoch: 0007 train_loss= 1.76292 train_acc= 0.74924 val_loss= 1.68956 val_acc= 0.73358 time= 0.12501
Epoch: 0008 train_loss= 1.68436 train_acc= 0.75025 val_loss= 1.60829 val_acc= 0.73358 time= 0.12399
Epoch: 0009 train_loss= 1.59256 train_acc= 0.75228 val_loss= 1.52960 val_acc= 0.73723 time= 0.12300
Epoch: 0010 train_loss= 1.51265 train_acc= 0.75086 val_loss= 1.45701 val_acc= 0.74453 time= 0.12342
Epoch: 0011 train_loss= 1.43213 train_acc= 0.76180 val_loss= 1.39256 val_acc= 0.74453 time= 0.15907
Epoch: 0012 train_loss= 1.37199 train_acc= 0.76261 val_loss= 1.33651 val_acc= 0.74453 time= 0.13197
Epoch: 0013 train_loss= 1.30250 train_acc= 0.75511 val_loss= 1.28742 val_acc= 0.74453 time= 0.12312
Epoch: 0014 train_loss= 1.25397 train_acc= 0.76342 val_loss= 1.24323 val_acc= 0.73358 time= 0.12500
Epoch: 0015 train_loss= 1.19831 train_acc= 0.75187 val_loss= 1.20194 val_acc= 0.72993 time= 0.12600
Epoch: 0016 train_loss= 1.15732 train_acc= 0.74762 val_loss= 1.16189 val_acc= 0.72810 time= 0.12500
Epoch: 0017 train_loss= 1.11989 train_acc= 0.74357 val_loss= 1.12197 val_acc= 0.72810 time= 0.12403
Epoch: 0018 train_loss= 1.07991 train_acc= 0.73405 val_loss= 1.08157 val_acc= 0.73175 time= 0.12400
Epoch: 0019 train_loss= 1.03223 train_acc= 0.74559 val_loss= 1.04059 val_acc= 0.73358 time= 0.16200
Epoch: 0020 train_loss= 1.00534 train_acc= 0.74965 val_loss= 0.99934 val_acc= 0.74635 time= 0.12400
Epoch: 0021 train_loss= 0.96076 train_acc= 0.75592 val_loss= 0.95837 val_acc= 0.75365 time= 0.12300
Epoch: 0022 train_loss= 0.92464 train_acc= 0.77071 val_loss= 0.91853 val_acc= 0.76460 time= 0.12400
Epoch: 0023 train_loss= 0.88544 train_acc= 0.77962 val_loss= 0.88070 val_acc= 0.76460 time= 0.12400
Epoch: 0024 train_loss= 0.84217 train_acc= 0.78428 val_loss= 0.84562 val_acc= 0.76095 time= 0.12397
Epoch: 0025 train_loss= 0.80921 train_acc= 0.78854 val_loss= 0.81374 val_acc= 0.76460 time= 0.12700
Epoch: 0026 train_loss= 0.78391 train_acc= 0.78914 val_loss= 0.78517 val_acc= 0.76642 time= 0.12504
Epoch: 0027 train_loss= 0.75174 train_acc= 0.79076 val_loss= 0.75969 val_acc= 0.77007 time= 0.15800
Epoch: 0028 train_loss= 0.72878 train_acc= 0.79279 val_loss= 0.73681 val_acc= 0.76825 time= 0.12600
Epoch: 0029 train_loss= 0.70363 train_acc= 0.80130 val_loss= 0.71587 val_acc= 0.78285 time= 0.12300
Epoch: 0030 train_loss= 0.67992 train_acc= 0.80980 val_loss= 0.69627 val_acc= 0.79927 time= 0.12301
Epoch: 0031 train_loss= 0.66217 train_acc= 0.82621 val_loss= 0.67747 val_acc= 0.82117 time= 0.12299
Epoch: 0032 train_loss= 0.64643 train_acc= 0.83229 val_loss= 0.65909 val_acc= 0.83212 time= 0.12407
Epoch: 0033 train_loss= 0.62310 train_acc= 0.84626 val_loss= 0.64104 val_acc= 0.83759 time= 0.12601
Epoch: 0034 train_loss= 0.61148 train_acc= 0.85396 val_loss= 0.62327 val_acc= 0.84307 time= 0.12899
Epoch: 0035 train_loss= 0.58929 train_acc= 0.86186 val_loss= 0.60593 val_acc= 0.84307 time= 0.16600
Epoch: 0036 train_loss= 0.57241 train_acc= 0.86713 val_loss= 0.58922 val_acc= 0.84672 time= 0.12497
Epoch: 0037 train_loss= 0.55610 train_acc= 0.87097 val_loss= 0.57328 val_acc= 0.84672 time= 0.12504
Epoch: 0038 train_loss= 0.53322 train_acc= 0.87827 val_loss= 0.55823 val_acc= 0.85219 time= 0.12293
Epoch: 0039 train_loss= 0.52303 train_acc= 0.88090 val_loss= 0.54405 val_acc= 0.86131 time= 0.12301
Epoch: 0040 train_loss= 0.50454 train_acc= 0.88657 val_loss= 0.53065 val_acc= 0.87409 time= 0.12303
Epoch: 0041 train_loss= 0.49075 train_acc= 0.88920 val_loss= 0.51792 val_acc= 0.87774 time= 0.12200
Epoch: 0042 train_loss= 0.47684 train_acc= 0.89224 val_loss= 0.50567 val_acc= 0.87774 time= 0.16699
Epoch: 0043 train_loss= 0.46392 train_acc= 0.89569 val_loss= 0.49377 val_acc= 0.88686 time= 0.12600
Epoch: 0044 train_loss= 0.45127 train_acc= 0.89670 val_loss= 0.48214 val_acc= 0.88686 time= 0.12561
Epoch: 0045 train_loss= 0.43351 train_acc= 0.89771 val_loss= 0.47078 val_acc= 0.88869 time= 0.12703
Epoch: 0046 train_loss= 0.42731 train_acc= 0.89751 val_loss= 0.45969 val_acc= 0.88686 time= 0.12300
Epoch: 0047 train_loss= 0.41226 train_acc= 0.89791 val_loss= 0.44889 val_acc= 0.88869 time= 0.12307
Epoch: 0048 train_loss= 0.40325 train_acc= 0.90014 val_loss= 0.43839 val_acc= 0.89051 time= 0.12639
Epoch: 0049 train_loss= 0.39147 train_acc= 0.90277 val_loss= 0.42818 val_acc= 0.89051 time= 0.12300
Epoch: 0050 train_loss= 0.38231 train_acc= 0.90217 val_loss= 0.41825 val_acc= 0.88869 time= 0.14900
Epoch: 0051 train_loss= 0.37306 train_acc= 0.90521 val_loss= 0.40861 val_acc= 0.89599 time= 0.12297
Epoch: 0052 train_loss= 0.36178 train_acc= 0.90966 val_loss= 0.39922 val_acc= 0.89781 time= 0.12300
Epoch: 0053 train_loss= 0.35395 train_acc= 0.91250 val_loss= 0.39003 val_acc= 0.90693 time= 0.12852
Epoch: 0054 train_loss= 0.34537 train_acc= 0.91635 val_loss= 0.38106 val_acc= 0.90693 time= 0.12649
Epoch: 0055 train_loss= 0.33630 train_acc= 0.91857 val_loss= 0.37238 val_acc= 0.91058 time= 0.12364
Epoch: 0056 train_loss= 0.32188 train_acc= 0.92404 val_loss= 0.36400 val_acc= 0.91606 time= 0.12307
Epoch: 0057 train_loss= 0.31912 train_acc= 0.92465 val_loss= 0.35589 val_acc= 0.91606 time= 0.12300
Epoch: 0058 train_loss= 0.30760 train_acc= 0.93174 val_loss= 0.34806 val_acc= 0.91606 time= 0.16600
Epoch: 0059 train_loss= 0.29966 train_acc= 0.93255 val_loss= 0.34045 val_acc= 0.91788 time= 0.12320
Epoch: 0060 train_loss= 0.29256 train_acc= 0.93701 val_loss= 0.33307 val_acc= 0.91788 time= 0.12401
Epoch: 0061 train_loss= 0.28324 train_acc= 0.94308 val_loss= 0.32592 val_acc= 0.92153 time= 0.12519
Epoch: 0062 train_loss= 0.27796 train_acc= 0.94045 val_loss= 0.31893 val_acc= 0.92701 time= 0.12800
Epoch: 0063 train_loss= 0.26766 train_acc= 0.94531 val_loss= 0.31212 val_acc= 0.92701 time= 0.12600
Epoch: 0064 train_loss= 0.25799 train_acc= 0.95078 val_loss= 0.30554 val_acc= 0.93066 time= 0.12503
Epoch: 0065 train_loss= 0.25094 train_acc= 0.94936 val_loss= 0.29916 val_acc= 0.93066 time= 0.14510
Epoch: 0066 train_loss= 0.24400 train_acc= 0.94835 val_loss= 0.29291 val_acc= 0.92883 time= 0.13800
Epoch: 0067 train_loss= 0.23981 train_acc= 0.95200 val_loss= 0.28685 val_acc= 0.92883 time= 0.12408
Epoch: 0068 train_loss= 0.23184 train_acc= 0.95301 val_loss= 0.28095 val_acc= 0.93066 time= 0.12296
Epoch: 0069 train_loss= 0.22703 train_acc= 0.95503 val_loss= 0.27519 val_acc= 0.93248 time= 0.12500
Epoch: 0070 train_loss= 0.21846 train_acc= 0.95726 val_loss= 0.26954 val_acc= 0.93248 time= 0.12700
Epoch: 0071 train_loss= 0.21237 train_acc= 0.95746 val_loss= 0.26407 val_acc= 0.93248 time= 0.12400
Epoch: 0072 train_loss= 0.20448 train_acc= 0.95969 val_loss= 0.25878 val_acc= 0.93431 time= 0.13000
Epoch: 0073 train_loss= 0.20219 train_acc= 0.95908 val_loss= 0.25355 val_acc= 0.93613 time= 0.16700
Epoch: 0074 train_loss= 0.19919 train_acc= 0.95908 val_loss= 0.24855 val_acc= 0.93613 time= 0.12370
Epoch: 0075 train_loss= 0.19067 train_acc= 0.96253 val_loss= 0.24379 val_acc= 0.93613 time= 0.12312
Epoch: 0076 train_loss= 0.18265 train_acc= 0.96415 val_loss= 0.23925 val_acc= 0.93613 time= 0.12389
Epoch: 0077 train_loss= 0.17968 train_acc= 0.96334 val_loss= 0.23484 val_acc= 0.93796 time= 0.12260
Epoch: 0078 train_loss= 0.17663 train_acc= 0.96516 val_loss= 0.23066 val_acc= 0.93796 time= 0.12597
Epoch: 0079 train_loss= 0.17126 train_acc= 0.96536 val_loss= 0.22649 val_acc= 0.93978 time= 0.12410
Epoch: 0080 train_loss= 0.16621 train_acc= 0.96536 val_loss= 0.22239 val_acc= 0.93978 time= 0.12300
Epoch: 0081 train_loss= 0.15996 train_acc= 0.96901 val_loss= 0.21859 val_acc= 0.93978 time= 0.15297
Epoch: 0082 train_loss= 0.15815 train_acc= 0.96860 val_loss= 0.21499 val_acc= 0.94161 time= 0.12836
Epoch: 0083 train_loss= 0.15313 train_acc= 0.96820 val_loss= 0.21150 val_acc= 0.94161 time= 0.12400
Epoch: 0084 train_loss= 0.14968 train_acc= 0.97144 val_loss= 0.20811 val_acc= 0.94343 time= 0.12403
Epoch: 0085 train_loss= 0.14713 train_acc= 0.96901 val_loss= 0.20482 val_acc= 0.94526 time= 0.12310
Epoch: 0086 train_loss= 0.13823 train_acc= 0.97407 val_loss= 0.20160 val_acc= 0.94526 time= 0.12396
Epoch: 0087 train_loss= 0.13918 train_acc= 0.97347 val_loss= 0.19850 val_acc= 0.94526 time= 0.12800
Epoch: 0088 train_loss= 0.13577 train_acc= 0.97245 val_loss= 0.19551 val_acc= 0.94526 time= 0.12375
Epoch: 0089 train_loss= 0.13368 train_acc= 0.97387 val_loss= 0.19265 val_acc= 0.94526 time= 0.16700
Epoch: 0090 train_loss= 0.13176 train_acc= 0.97306 val_loss= 0.18987 val_acc= 0.94526 time= 0.12300
Epoch: 0091 train_loss= 0.12774 train_acc= 0.97529 val_loss= 0.18727 val_acc= 0.94526 time= 0.12547
Epoch: 0092 train_loss= 0.12186 train_acc= 0.97590 val_loss= 0.18485 val_acc= 0.94526 time= 0.12580
Epoch: 0093 train_loss= 0.12016 train_acc= 0.98096 val_loss= 0.18244 val_acc= 0.94526 time= 0.12403
Epoch: 0094 train_loss= 0.11496 train_acc= 0.97853 val_loss= 0.18009 val_acc= 0.94343 time= 0.12179
Epoch: 0095 train_loss= 0.11573 train_acc= 0.97873 val_loss= 0.17797 val_acc= 0.95073 time= 0.12504
Epoch: 0096 train_loss= 0.11152 train_acc= 0.97711 val_loss= 0.17600 val_acc= 0.95073 time= 0.13500
Epoch: 0097 train_loss= 0.10892 train_acc= 0.97711 val_loss= 0.17410 val_acc= 0.95255 time= 0.14897
Epoch: 0098 train_loss= 0.10734 train_acc= 0.97650 val_loss= 0.17212 val_acc= 0.95255 time= 0.12200
Epoch: 0099 train_loss= 0.10410 train_acc= 0.98055 val_loss= 0.17013 val_acc= 0.95255 time= 0.12304
Epoch: 0100 train_loss= 0.10225 train_acc= 0.98035 val_loss= 0.16830 val_acc= 0.95073 time= 0.12496
Epoch: 0101 train_loss= 0.10224 train_acc= 0.97893 val_loss= 0.16665 val_acc= 0.95073 time= 0.12610
Epoch: 0102 train_loss= 0.09913 train_acc= 0.98055 val_loss= 0.16518 val_acc= 0.95073 time= 0.12649
Epoch: 0103 train_loss= 0.09668 train_acc= 0.98177 val_loss= 0.16373 val_acc= 0.95255 time= 0.12497
Epoch: 0104 train_loss= 0.09592 train_acc= 0.98076 val_loss= 0.16219 val_acc= 0.95438 time= 0.16900
Epoch: 0105 train_loss= 0.09236 train_acc= 0.98278 val_loss= 0.16066 val_acc= 0.95255 time= 0.12263
Epoch: 0106 train_loss= 0.09299 train_acc= 0.98116 val_loss= 0.15911 val_acc= 0.95255 time= 0.12309
Epoch: 0107 train_loss= 0.08991 train_acc= 0.98278 val_loss= 0.15754 val_acc= 0.95255 time= 0.12236
Epoch: 0108 train_loss= 0.08838 train_acc= 0.98339 val_loss= 0.15628 val_acc= 0.95255 time= 0.12400
Epoch: 0109 train_loss= 0.08358 train_acc= 0.98420 val_loss= 0.15530 val_acc= 0.95255 time= 0.12409
Epoch: 0110 train_loss= 0.08373 train_acc= 0.98299 val_loss= 0.15431 val_acc= 0.95255 time= 0.12500
Epoch: 0111 train_loss= 0.08125 train_acc= 0.98461 val_loss= 0.15337 val_acc= 0.95255 time= 0.12600
Epoch: 0112 train_loss= 0.07985 train_acc= 0.98440 val_loss= 0.15246 val_acc= 0.95255 time= 0.15500
Epoch: 0113 train_loss= 0.07893 train_acc= 0.98461 val_loss= 0.15155 val_acc= 0.95255 time= 0.12300
Epoch: 0114 train_loss= 0.07892 train_acc= 0.98440 val_loss= 0.15047 val_acc= 0.95255 time= 0.12413
Epoch: 0115 train_loss= 0.07620 train_acc= 0.98521 val_loss= 0.14943 val_acc= 0.95255 time= 0.12301
Epoch: 0116 train_loss= 0.07388 train_acc= 0.98420 val_loss= 0.14829 val_acc= 0.95255 time= 0.12399
Epoch: 0117 train_loss= 0.07451 train_acc= 0.98501 val_loss= 0.14728 val_acc= 0.95255 time= 0.12500
Epoch: 0118 train_loss= 0.07156 train_acc= 0.98663 val_loss= 0.14631 val_acc= 0.95438 time= 0.12320
Epoch: 0119 train_loss= 0.07068 train_acc= 0.98602 val_loss= 0.14535 val_acc= 0.95438 time= 0.12400
Epoch: 0120 train_loss= 0.06898 train_acc= 0.98562 val_loss= 0.14455 val_acc= 0.95438 time= 0.17900
Epoch: 0121 train_loss= 0.06891 train_acc= 0.98704 val_loss= 0.14385 val_acc= 0.95438 time= 0.12600
Epoch: 0122 train_loss= 0.06638 train_acc= 0.98744 val_loss= 0.14323 val_acc= 0.95438 time= 0.12410
Epoch: 0123 train_loss= 0.06835 train_acc= 0.98623 val_loss= 0.14265 val_acc= 0.95438 time= 0.12301
Epoch: 0124 train_loss= 0.06600 train_acc= 0.98623 val_loss= 0.14212 val_acc= 0.95438 time= 0.12294
Epoch: 0125 train_loss= 0.06359 train_acc= 0.98886 val_loss= 0.14175 val_acc= 0.95438 time= 0.12355
Epoch: 0126 train_loss= 0.06283 train_acc= 0.98764 val_loss= 0.14148 val_acc= 0.95438 time= 0.12399
Epoch: 0127 train_loss= 0.06334 train_acc= 0.98845 val_loss= 0.14124 val_acc= 0.95438 time= 0.15500
Epoch: 0128 train_loss= 0.06236 train_acc= 0.98947 val_loss= 0.14103 val_acc= 0.95438 time= 0.13000
Epoch: 0129 train_loss= 0.06075 train_acc= 0.98866 val_loss= 0.14072 val_acc= 0.95438 time= 0.12697
Epoch: 0130 train_loss= 0.05939 train_acc= 0.98987 val_loss= 0.14029 val_acc= 0.95438 time= 0.12577
Epoch: 0131 train_loss= 0.05995 train_acc= 0.98845 val_loss= 0.13981 val_acc= 0.95438 time= 0.12603
Epoch: 0132 train_loss= 0.05697 train_acc= 0.98825 val_loss= 0.13937 val_acc= 0.95438 time= 0.12301
Epoch: 0133 train_loss= 0.05693 train_acc= 0.98825 val_loss= 0.13891 val_acc= 0.95438 time= 0.12359
Epoch: 0134 train_loss= 0.05579 train_acc= 0.98886 val_loss= 0.13847 val_acc= 0.95620 time= 0.12300
Epoch: 0135 train_loss= 0.05494 train_acc= 0.98866 val_loss= 0.13793 val_acc= 0.95620 time= 0.16706
Epoch: 0136 train_loss= 0.05235 train_acc= 0.98987 val_loss= 0.13742 val_acc= 0.95620 time= 0.12502
Epoch: 0137 train_loss= 0.05280 train_acc= 0.98926 val_loss= 0.13696 val_acc= 0.95438 time= 0.12698
Epoch: 0138 train_loss= 0.05123 train_acc= 0.99109 val_loss= 0.13663 val_acc= 0.95255 time= 0.12307
Epoch: 0139 train_loss= 0.05158 train_acc= 0.99149 val_loss= 0.13648 val_acc= 0.95255 time= 0.12697
Epoch: 0140 train_loss= 0.05129 train_acc= 0.98805 val_loss= 0.13637 val_acc= 0.95255 time= 0.12636
Epoch: 0141 train_loss= 0.05051 train_acc= 0.99170 val_loss= 0.13630 val_acc= 0.95255 time= 0.12306
Epoch: 0142 train_loss= 0.04843 train_acc= 0.99068 val_loss= 0.13619 val_acc= 0.95255 time= 0.12404
Epoch: 0143 train_loss= 0.04853 train_acc= 0.99251 val_loss= 0.13606 val_acc= 0.95255 time= 0.15001
Epoch: 0144 train_loss= 0.04938 train_acc= 0.99210 val_loss= 0.13597 val_acc= 0.95255 time= 0.12251
Epoch: 0145 train_loss= 0.04610 train_acc= 0.99109 val_loss= 0.13586 val_acc= 0.95255 time= 0.12500
Epoch: 0146 train_loss= 0.04636 train_acc= 0.99210 val_loss= 0.13587 val_acc= 0.95255 time= 0.12303
Epoch: 0147 train_loss= 0.04808 train_acc= 0.99048 val_loss= 0.13593 val_acc= 0.95255 time= 0.12401
Epoch: 0148 train_loss= 0.04474 train_acc= 0.99129 val_loss= 0.13593 val_acc= 0.95255 time= 0.12396
Epoch: 0149 train_loss= 0.04385 train_acc= 0.99352 val_loss= 0.13600 val_acc= 0.95438 time= 0.12523
Epoch: 0150 train_loss= 0.04298 train_acc= 0.99251 val_loss= 0.13598 val_acc= 0.95438 time= 0.12694
Epoch: 0151 train_loss= 0.04358 train_acc= 0.99170 val_loss= 0.13556 val_acc= 0.95255 time= 0.16903
Epoch: 0152 train_loss= 0.04363 train_acc= 0.99251 val_loss= 0.13510 val_acc= 0.95438 time= 0.12300
Epoch: 0153 train_loss= 0.04276 train_acc= 0.99170 val_loss= 0.13442 val_acc= 0.95438 time= 0.12500
Epoch: 0154 train_loss= 0.04169 train_acc= 0.99352 val_loss= 0.13402 val_acc= 0.95438 time= 0.12700
Epoch: 0155 train_loss= 0.04032 train_acc= 0.99230 val_loss= 0.13381 val_acc= 0.95438 time= 0.12301
Epoch: 0156 train_loss= 0.04133 train_acc= 0.99230 val_loss= 0.13370 val_acc= 0.95438 time= 0.12500
Epoch: 0157 train_loss= 0.04231 train_acc= 0.99210 val_loss= 0.13360 val_acc= 0.95438 time= 0.12200
Epoch: 0158 train_loss= 0.03934 train_acc= 0.99332 val_loss= 0.13356 val_acc= 0.95620 time= 0.15397
Epoch: 0159 train_loss= 0.03830 train_acc= 0.99352 val_loss= 0.13363 val_acc= 0.95620 time= 0.13600
Epoch: 0160 train_loss= 0.03919 train_acc= 0.99372 val_loss= 0.13370 val_acc= 0.95620 time= 0.12303
Epoch: 0161 train_loss= 0.03866 train_acc= 0.99352 val_loss= 0.13378 val_acc= 0.95620 time= 0.12500
Epoch: 0162 train_loss= 0.03732 train_acc= 0.99494 val_loss= 0.13385 val_acc= 0.95620 time= 0.12800
Epoch: 0163 train_loss= 0.03794 train_acc= 0.99433 val_loss= 0.13412 val_acc= 0.95620 time= 0.12309
Early stopping...
Optimization Finished!
Test set results: cost= 0.10726 accuracy= 0.97259 time= 0.05400
15362
Test Precision, Recall and F1-Score...
              precision    recall  f1-score   support

           0     0.9512    0.9669    0.9590       121
           1     0.8810    0.9867    0.9308        75
           2     0.9844    0.9917    0.9880      1083
           3     1.0000    1.0000    1.0000        10
           4     1.0000    0.7222    0.8387        36
           5     0.9211    0.8642    0.8917        81
           6     0.8876    0.9080    0.8977        87
           7     0.9841    0.9756    0.9798       696

    accuracy                         0.9726      2189
   macro avg     0.9512    0.9269    0.9357      2189
weighted avg     0.9731    0.9726    0.9723      2189

Macro average Test Precision, Recall and F1-Score...
(0.9511676137935893, 0.9269173761076387, 0.9357286446317398, None)
Micro average Test Precision, Recall and F1-Score...
(0.9725902238465053, 0.9725902238465053, 0.9725902238465053, None)
embeddings:
7688 5485 2189
[[ 0.20938689  0.24513608  0.24946193 ...  0.32665423  0.18605031
   0.11445717]
 [ 0.28989527  0.09356099  0.16613925 ...  0.17563735  0.07402042
   0.08860492]
 [ 0.06805122 -0.00627499  0.07783913 ... -0.01808357  0.17918669
   0.272763  ]
 ...
 [ 0.06213415  0.10657444  0.08331338 ...  0.10561479  0.19831818
   0.2573674 ]
 [ 0.32505864  0.09306878  0.32485142 ...  0.21923247  0.08506323
   0.12895687]
 [ 0.04292061  0.0207172   0.0708257  ... -0.01547134  0.15662183
   0.2200298 ]]
