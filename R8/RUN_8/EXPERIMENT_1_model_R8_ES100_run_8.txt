(4937, 300) (4937, 8) (2189, 300) (2189, 8) (13173, 300) (13173, 8)
15362
  (0, 5864)	1.021520945883481
  (0, 6572)	4.818458885761806
  (0, 7052)	3.362096962025199
  (0, 7916)	1.2457508634099117
  (0, 7933)	2.0838819303261675
  (0, 8096)	0.686135075474489
  (0, 9590)	1.1548972396321597
  (0, 10449)	5.949860997252907
  (0, 10914)	2.080745492836037
  (0, 11036)	1.6330397727043
  (0, 11444)	0.09164216929228669
  (0, 11878)	3.647275904258861
  (0, 12720)	0.9536627509544204
  (1, 5523)	5.7267174459386965
  (1, 5674)	3.6274732769626814
  (1, 5758)	4.360625792136326
  (1, 5917)	7.153833801578843
  (1, 5969)	7.631389111767649
  (1, 6209)	5.161403636888637
  (1, 6216)	3.9217127499606215
  (1, 6333)	6.547697998008527
  (1, 6737)	3.989766213205637
  (1, 6888)	1.7407007606022247
  (1, 7223)	2.810028379725159
  (1, 7295)	2.0131453792343894
  :	:
  (15361, 10641)	4.975301357254776
  (15361, 10690)	3.30014637316366
  (15361, 10787)	2.680292058069188
  (15361, 10833)	2.6898432290535306
  (15361, 10951)	4.868055826901179
  (15361, 11049)	3.7091513079769487
  (15361, 11110)	3.381072863484204
  (15361, 11181)	2.7552778649537504
  (15361, 11213)	2.929436111108544
  (15361, 11216)	6.866151729127062
  (15361, 11246)	3.88934746545859
  (15361, 11252)	5.687496732785416
  (15361, 11271)	0.967968172022305
  (15361, 11444)	0.09164216929228669
  (15361, 11902)	2.548663615590751
  (15361, 11922)	3.01069907518731
  (15361, 12000)	4.093563006887281
  (15361, 12048)	7.336155358372797
  (15361, 12172)	3.1962002848986444
  (15361, 12457)	4.5267526630103
  (15361, 12548)	3.0678574890272587
  (15361, 12694)	3.775109275768746
  (15361, 12757)	47.08188589283273
  (15361, 12768)	3.9416469648614387
  (15361, 13025)	6.921592674632485
(15362, 15362)
(15362, 15362)
15362
Tensor("graphconvolution_2/SparseTensorDenseMatMul/SparseTensorDenseMatMul:0", shape=(None, 8), dtype=float32)
Epoch: 0001 train_loss= 2.07936 train_acc= 0.14948 val_loss= 2.02200 val_acc= 0.75730 time= 0.39283
Epoch: 0002 train_loss= 2.01961 train_acc= 0.78773 val_loss= 1.92856 val_acc= 0.75547 time= 0.12814
Epoch: 0003 train_loss= 1.92317 train_acc= 0.78509 val_loss= 1.80314 val_acc= 0.76095 time= 0.15101
Epoch: 0004 train_loss= 1.79152 train_acc= 0.78469 val_loss= 1.65903 val_acc= 0.76277 time= 0.12499
Epoch: 0005 train_loss= 1.64133 train_acc= 0.78145 val_loss= 1.51739 val_acc= 0.75912 time= 0.12496
Epoch: 0006 train_loss= 1.49661 train_acc= 0.77780 val_loss= 1.39790 val_acc= 0.75730 time= 0.12400
Epoch: 0007 train_loss= 1.36984 train_acc= 0.77132 val_loss= 1.30550 val_acc= 0.74270 time= 0.12400
Epoch: 0008 train_loss= 1.27426 train_acc= 0.74985 val_loss= 1.23241 val_acc= 0.72263 time= 0.12600
Epoch: 0009 train_loss= 1.19228 train_acc= 0.72615 val_loss= 1.16790 val_acc= 0.69343 time= 0.12500
Epoch: 0010 train_loss= 1.13672 train_acc= 0.71582 val_loss= 1.10371 val_acc= 0.69526 time= 0.12300
Epoch: 0011 train_loss= 1.05508 train_acc= 0.70954 val_loss= 1.03538 val_acc= 0.73175 time= 0.15003
Epoch: 0012 train_loss= 0.99687 train_acc= 0.74154 val_loss= 0.96403 val_acc= 0.75000 time= 0.12300
Epoch: 0013 train_loss= 0.92003 train_acc= 0.77415 val_loss= 0.89424 val_acc= 0.76277 time= 0.12597
Epoch: 0014 train_loss= 0.85423 train_acc= 0.78145 val_loss= 0.83079 val_acc= 0.76095 time= 0.12603
Epoch: 0015 train_loss= 0.80265 train_acc= 0.78773 val_loss= 0.77681 val_acc= 0.75912 time= 0.12300
Epoch: 0016 train_loss= 0.74207 train_acc= 0.78631 val_loss= 0.73296 val_acc= 0.76095 time= 0.12297
Epoch: 0017 train_loss= 0.69982 train_acc= 0.78732 val_loss= 0.69801 val_acc= 0.77555 time= 0.12400
Epoch: 0018 train_loss= 0.66520 train_acc= 0.79765 val_loss= 0.66934 val_acc= 0.79927 time= 0.12700
Epoch: 0019 train_loss= 0.63777 train_acc= 0.81770 val_loss= 0.64410 val_acc= 0.81204 time= 0.16800
Epoch: 0020 train_loss= 0.60533 train_acc= 0.83391 val_loss= 0.62032 val_acc= 0.82482 time= 0.12303
Epoch: 0021 train_loss= 0.58541 train_acc= 0.84464 val_loss= 0.59680 val_acc= 0.83394 time= 0.12397
Epoch: 0022 train_loss= 0.56178 train_acc= 0.85254 val_loss= 0.57343 val_acc= 0.84672 time= 0.12603
Epoch: 0023 train_loss= 0.53241 train_acc= 0.86287 val_loss= 0.55096 val_acc= 0.84854 time= 0.12306
Epoch: 0024 train_loss= 0.50971 train_acc= 0.87016 val_loss= 0.52987 val_acc= 0.85219 time= 0.12401
Epoch: 0025 train_loss= 0.48695 train_acc= 0.87968 val_loss= 0.51038 val_acc= 0.85584 time= 0.12200
Epoch: 0026 train_loss= 0.46717 train_acc= 0.88455 val_loss= 0.49246 val_acc= 0.85766 time= 0.12399
Epoch: 0027 train_loss= 0.44493 train_acc= 0.89184 val_loss= 0.47579 val_acc= 0.87044 time= 0.16500
Epoch: 0028 train_loss= 0.42735 train_acc= 0.89346 val_loss= 0.45999 val_acc= 0.87591 time= 0.12600
Epoch: 0029 train_loss= 0.41032 train_acc= 0.89852 val_loss= 0.44466 val_acc= 0.88504 time= 0.12300
Epoch: 0030 train_loss= 0.39356 train_acc= 0.90075 val_loss= 0.42958 val_acc= 0.89416 time= 0.12476
Epoch: 0031 train_loss= 0.37533 train_acc= 0.90399 val_loss= 0.41471 val_acc= 0.89599 time= 0.12610
Epoch: 0032 train_loss= 0.36190 train_acc= 0.90602 val_loss= 0.40006 val_acc= 0.89599 time= 0.12400
Epoch: 0033 train_loss= 0.34050 train_acc= 0.91128 val_loss= 0.38569 val_acc= 0.89599 time= 0.12201
Epoch: 0034 train_loss= 0.33057 train_acc= 0.91594 val_loss= 0.37162 val_acc= 0.89964 time= 0.16799
Epoch: 0035 train_loss= 0.31708 train_acc= 0.91837 val_loss= 0.35786 val_acc= 0.91058 time= 0.12300
Epoch: 0036 train_loss= 0.29910 train_acc= 0.92283 val_loss= 0.34462 val_acc= 0.91241 time= 0.12400
Epoch: 0037 train_loss= 0.29094 train_acc= 0.92830 val_loss= 0.33205 val_acc= 0.91423 time= 0.12600
Epoch: 0038 train_loss= 0.27292 train_acc= 0.93397 val_loss= 0.32026 val_acc= 0.91971 time= 0.12500
Epoch: 0039 train_loss= 0.25636 train_acc= 0.93680 val_loss= 0.30912 val_acc= 0.91971 time= 0.12600
Epoch: 0040 train_loss= 0.25016 train_acc= 0.93680 val_loss= 0.29862 val_acc= 0.92336 time= 0.12300
Epoch: 0041 train_loss= 0.23800 train_acc= 0.94268 val_loss= 0.28859 val_acc= 0.92883 time= 0.12399
Epoch: 0042 train_loss= 0.22234 train_acc= 0.94612 val_loss= 0.27881 val_acc= 0.93248 time= 0.15100
Epoch: 0043 train_loss= 0.21735 train_acc= 0.94916 val_loss= 0.26943 val_acc= 0.93613 time= 0.12303
Epoch: 0044 train_loss= 0.20481 train_acc= 0.95564 val_loss= 0.26035 val_acc= 0.93613 time= 0.12400
Epoch: 0045 train_loss= 0.19229 train_acc= 0.95443 val_loss= 0.25158 val_acc= 0.93248 time= 0.12303
Epoch: 0046 train_loss= 0.18430 train_acc= 0.95645 val_loss= 0.24317 val_acc= 0.93248 time= 0.12610
Epoch: 0047 train_loss= 0.17243 train_acc= 0.95888 val_loss= 0.23546 val_acc= 0.93431 time= 0.12703
Epoch: 0048 train_loss= 0.16624 train_acc= 0.96091 val_loss= 0.22831 val_acc= 0.93796 time= 0.12500
Epoch: 0049 train_loss= 0.15666 train_acc= 0.96273 val_loss= 0.22151 val_acc= 0.93796 time= 0.12412
Epoch: 0050 train_loss= 0.14826 train_acc= 0.96233 val_loss= 0.21525 val_acc= 0.93978 time= 0.16700
Epoch: 0051 train_loss= 0.14287 train_acc= 0.96435 val_loss= 0.20941 val_acc= 0.93978 time= 0.12453
Epoch: 0052 train_loss= 0.13685 train_acc= 0.96678 val_loss= 0.20397 val_acc= 0.93796 time= 0.12307
Epoch: 0053 train_loss= 0.13284 train_acc= 0.96779 val_loss= 0.19880 val_acc= 0.93796 time= 0.12396
Epoch: 0054 train_loss= 0.12699 train_acc= 0.96820 val_loss= 0.19411 val_acc= 0.93978 time= 0.12203
Epoch: 0055 train_loss= 0.11830 train_acc= 0.97266 val_loss= 0.18976 val_acc= 0.94161 time= 0.12458
Epoch: 0056 train_loss= 0.11443 train_acc= 0.97326 val_loss= 0.18584 val_acc= 0.93796 time= 0.12863
Epoch: 0057 train_loss= 0.11051 train_acc= 0.97367 val_loss= 0.18226 val_acc= 0.94161 time= 0.15100
Epoch: 0058 train_loss= 0.10103 train_acc= 0.97488 val_loss= 0.17875 val_acc= 0.94161 time= 0.13405
Epoch: 0059 train_loss= 0.09834 train_acc= 0.97671 val_loss= 0.17529 val_acc= 0.94343 time= 0.12194
Epoch: 0060 train_loss= 0.09576 train_acc= 0.97650 val_loss= 0.17184 val_acc= 0.94891 time= 0.12399
Epoch: 0061 train_loss= 0.09113 train_acc= 0.97954 val_loss= 0.16863 val_acc= 0.95073 time= 0.12500
Epoch: 0062 train_loss= 0.08709 train_acc= 0.97954 val_loss= 0.16577 val_acc= 0.95073 time= 0.12401
Epoch: 0063 train_loss= 0.08430 train_acc= 0.98015 val_loss= 0.16342 val_acc= 0.95255 time= 0.12300
Epoch: 0064 train_loss= 0.08039 train_acc= 0.98116 val_loss= 0.16159 val_acc= 0.95073 time= 0.12600
Epoch: 0065 train_loss= 0.07742 train_acc= 0.98197 val_loss= 0.15993 val_acc= 0.95255 time= 0.17097
Epoch: 0066 train_loss= 0.07562 train_acc= 0.98278 val_loss= 0.15872 val_acc= 0.95255 time= 0.12600
Epoch: 0067 train_loss= 0.07089 train_acc= 0.98400 val_loss= 0.15773 val_acc= 0.95255 time= 0.12303
Epoch: 0068 train_loss= 0.06943 train_acc= 0.98380 val_loss= 0.15643 val_acc= 0.95255 time= 0.12400
Epoch: 0069 train_loss= 0.07003 train_acc= 0.98380 val_loss= 0.15517 val_acc= 0.95073 time= 0.12242
Epoch: 0070 train_loss= 0.06386 train_acc= 0.98481 val_loss= 0.15367 val_acc= 0.95073 time= 0.12200
Epoch: 0071 train_loss= 0.06362 train_acc= 0.98380 val_loss= 0.15195 val_acc= 0.95073 time= 0.12205
Epoch: 0072 train_loss= 0.06166 train_acc= 0.98481 val_loss= 0.15044 val_acc= 0.95255 time= 0.12395
Epoch: 0073 train_loss= 0.05879 train_acc= 0.98602 val_loss= 0.14865 val_acc= 0.95438 time= 0.15405
Epoch: 0074 train_loss= 0.05774 train_acc= 0.98602 val_loss= 0.14761 val_acc= 0.95438 time= 0.12295
Epoch: 0075 train_loss= 0.05569 train_acc= 0.98785 val_loss= 0.14692 val_acc= 0.95438 time= 0.12600
Epoch: 0076 train_loss= 0.05398 train_acc= 0.98805 val_loss= 0.14704 val_acc= 0.95438 time= 0.12504
Epoch: 0077 train_loss= 0.05420 train_acc= 0.98764 val_loss= 0.14744 val_acc= 0.95255 time= 0.12196
Epoch: 0078 train_loss= 0.05102 train_acc= 0.98906 val_loss= 0.14837 val_acc= 0.95438 time= 0.12211
Epoch: 0079 train_loss= 0.04980 train_acc= 0.98764 val_loss= 0.14860 val_acc= 0.95620 time= 0.12296
Epoch: 0080 train_loss= 0.04746 train_acc= 0.98886 val_loss= 0.14762 val_acc= 0.95620 time= 0.12300
Epoch: 0081 train_loss= 0.04470 train_acc= 0.99048 val_loss= 0.14655 val_acc= 0.95438 time= 0.17003
Epoch: 0082 train_loss= 0.04581 train_acc= 0.98967 val_loss= 0.14561 val_acc= 0.95255 time= 0.12297
Epoch: 0083 train_loss= 0.04248 train_acc= 0.99129 val_loss= 0.14495 val_acc= 0.95438 time= 0.12303
Epoch: 0084 train_loss= 0.04165 train_acc= 0.99007 val_loss= 0.14446 val_acc= 0.95620 time= 0.12597
Epoch: 0085 train_loss= 0.04249 train_acc= 0.99028 val_loss= 0.14395 val_acc= 0.95620 time= 0.12600
Epoch: 0086 train_loss= 0.04108 train_acc= 0.99190 val_loss= 0.14366 val_acc= 0.95620 time= 0.12303
Epoch: 0087 train_loss= 0.03877 train_acc= 0.99230 val_loss= 0.14354 val_acc= 0.95803 time= 0.12300
Epoch: 0088 train_loss= 0.03916 train_acc= 0.99129 val_loss= 0.14324 val_acc= 0.95620 time= 0.14200
Epoch: 0089 train_loss= 0.03809 train_acc= 0.99170 val_loss= 0.14321 val_acc= 0.95620 time= 0.14500
Epoch: 0090 train_loss= 0.03715 train_acc= 0.99311 val_loss= 0.14372 val_acc= 0.95438 time= 0.12296
Epoch: 0091 train_loss= 0.03560 train_acc= 0.99291 val_loss= 0.14443 val_acc= 0.95620 time= 0.12458
Epoch: 0092 train_loss= 0.03482 train_acc= 0.99352 val_loss= 0.14519 val_acc= 0.95620 time= 0.12350
Epoch: 0093 train_loss= 0.03502 train_acc= 0.99372 val_loss= 0.14588 val_acc= 0.95620 time= 0.12406
Epoch: 0094 train_loss= 0.03357 train_acc= 0.99230 val_loss= 0.14628 val_acc= 0.95620 time= 0.12700
Epoch: 0095 train_loss= 0.03199 train_acc= 0.99372 val_loss= 0.14631 val_acc= 0.95620 time= 0.12400
Epoch: 0096 train_loss= 0.03217 train_acc= 0.99352 val_loss= 0.14588 val_acc= 0.95620 time= 0.16500
Epoch: 0097 train_loss= 0.03081 train_acc= 0.99392 val_loss= 0.14587 val_acc= 0.95620 time= 0.12425
Epoch: 0098 train_loss= 0.03072 train_acc= 0.99332 val_loss= 0.14577 val_acc= 0.95620 time= 0.12601
Epoch: 0099 train_loss= 0.02993 train_acc= 0.99392 val_loss= 0.14542 val_acc= 0.95620 time= 0.12303
Epoch: 0100 train_loss= 0.02901 train_acc= 0.99494 val_loss= 0.14550 val_acc= 0.95620 time= 0.12400
Epoch: 0101 train_loss= 0.02913 train_acc= 0.99433 val_loss= 0.14593 val_acc= 0.95620 time= 0.12200
Epoch: 0102 train_loss= 0.02805 train_acc= 0.99473 val_loss= 0.14627 val_acc= 0.95620 time= 0.12300
Epoch: 0103 train_loss= 0.02743 train_acc= 0.99473 val_loss= 0.14655 val_acc= 0.95620 time= 0.12490
Epoch: 0104 train_loss= 0.02618 train_acc= 0.99534 val_loss= 0.14689 val_acc= 0.95803 time= 0.15617
Epoch: 0105 train_loss= 0.02639 train_acc= 0.99554 val_loss= 0.14770 val_acc= 0.95803 time= 0.12400
Epoch: 0106 train_loss= 0.02417 train_acc= 0.99635 val_loss= 0.14843 val_acc= 0.95620 time= 0.12600
Epoch: 0107 train_loss= 0.02530 train_acc= 0.99473 val_loss= 0.14889 val_acc= 0.95620 time= 0.12401
Epoch: 0108 train_loss= 0.02360 train_acc= 0.99615 val_loss= 0.14922 val_acc= 0.95620 time= 0.12399
Epoch: 0109 train_loss= 0.02349 train_acc= 0.99595 val_loss= 0.14971 val_acc= 0.95620 time= 0.12300
Epoch: 0110 train_loss= 0.02339 train_acc= 0.99595 val_loss= 0.14994 val_acc= 0.95803 time= 0.12296
Epoch: 0111 train_loss= 0.02312 train_acc= 0.99554 val_loss= 0.15013 val_acc= 0.95803 time= 0.12301
Epoch: 0112 train_loss= 0.02276 train_acc= 0.99595 val_loss= 0.15014 val_acc= 0.95620 time= 0.16896
Epoch: 0113 train_loss= 0.02185 train_acc= 0.99575 val_loss= 0.14964 val_acc= 0.95620 time= 0.12600
Epoch: 0114 train_loss= 0.02067 train_acc= 0.99575 val_loss= 0.14941 val_acc= 0.95620 time= 0.12703
Epoch: 0115 train_loss= 0.02123 train_acc= 0.99656 val_loss= 0.14947 val_acc= 0.95620 time= 0.12403
Epoch: 0116 train_loss= 0.01987 train_acc= 0.99635 val_loss= 0.14960 val_acc= 0.95620 time= 0.12315
Epoch: 0117 train_loss= 0.02264 train_acc= 0.99453 val_loss= 0.15031 val_acc= 0.95620 time= 0.12291
Epoch: 0118 train_loss= 0.01912 train_acc= 0.99615 val_loss= 0.15154 val_acc= 0.95620 time= 0.12328
Epoch: 0119 train_loss= 0.01922 train_acc= 0.99635 val_loss= 0.15302 val_acc= 0.95803 time= 0.14595
Epoch: 0120 train_loss= 0.01852 train_acc= 0.99737 val_loss= 0.15459 val_acc= 0.95803 time= 0.13700
Epoch: 0121 train_loss= 0.01951 train_acc= 0.99615 val_loss= 0.15536 val_acc= 0.95803 time= 0.12400
Epoch: 0122 train_loss= 0.01901 train_acc= 0.99635 val_loss= 0.15609 val_acc= 0.95803 time= 0.12500
Epoch: 0123 train_loss= 0.01799 train_acc= 0.99656 val_loss= 0.15660 val_acc= 0.95803 time= 0.12935
Epoch: 0124 train_loss= 0.01790 train_acc= 0.99656 val_loss= 0.15708 val_acc= 0.95620 time= 0.12504
Epoch: 0125 train_loss= 0.01773 train_acc= 0.99716 val_loss= 0.15747 val_acc= 0.95438 time= 0.12214
Epoch: 0126 train_loss= 0.01768 train_acc= 0.99696 val_loss= 0.15805 val_acc= 0.95620 time= 0.12208
Epoch: 0127 train_loss= 0.01792 train_acc= 0.99635 val_loss= 0.15850 val_acc= 0.95438 time= 0.16403
Epoch: 0128 train_loss= 0.01692 train_acc= 0.99696 val_loss= 0.15895 val_acc= 0.95438 time= 0.12201
Epoch: 0129 train_loss= 0.01626 train_acc= 0.99777 val_loss= 0.15951 val_acc= 0.95620 time= 0.12296
Epoch: 0130 train_loss= 0.01668 train_acc= 0.99716 val_loss= 0.16050 val_acc= 0.95620 time= 0.12303
Epoch: 0131 train_loss= 0.01665 train_acc= 0.99716 val_loss= 0.16138 val_acc= 0.95620 time= 0.12400
Epoch: 0132 train_loss= 0.01631 train_acc= 0.99656 val_loss= 0.16303 val_acc= 0.95620 time= 0.12514
Epoch: 0133 train_loss= 0.01586 train_acc= 0.99716 val_loss= 0.16448 val_acc= 0.95620 time= 0.12900
Epoch: 0134 train_loss= 0.01586 train_acc= 0.99716 val_loss= 0.16547 val_acc= 0.95620 time= 0.12232
Epoch: 0135 train_loss= 0.01546 train_acc= 0.99676 val_loss= 0.16557 val_acc= 0.95620 time= 0.15100
Epoch: 0136 train_loss= 0.01497 train_acc= 0.99716 val_loss= 0.16508 val_acc= 0.95620 time= 0.12207
Epoch: 0137 train_loss= 0.01387 train_acc= 0.99777 val_loss= 0.16454 val_acc= 0.95438 time= 0.12319
Epoch: 0138 train_loss= 0.01474 train_acc= 0.99737 val_loss= 0.16397 val_acc= 0.95438 time= 0.12099
Epoch: 0139 train_loss= 0.01404 train_acc= 0.99696 val_loss= 0.16308 val_acc= 0.95438 time= 0.12410
Epoch: 0140 train_loss= 0.01412 train_acc= 0.99777 val_loss= 0.16230 val_acc= 0.95438 time= 0.12603
Epoch: 0141 train_loss= 0.01389 train_acc= 0.99777 val_loss= 0.16197 val_acc= 0.95620 time= 0.12400
Epoch: 0142 train_loss= 0.01355 train_acc= 0.99737 val_loss= 0.16216 val_acc= 0.95620 time= 0.12697
Epoch: 0143 train_loss= 0.01432 train_acc= 0.99676 val_loss= 0.16297 val_acc= 0.95620 time= 0.17403
Epoch: 0144 train_loss= 0.01329 train_acc= 0.99777 val_loss= 0.16452 val_acc= 0.95620 time= 0.12204
Early stopping...
Optimization Finished!
Test set results: cost= 0.11087 accuracy= 0.96802 time= 0.05500
15362
Test Precision, Recall and F1-Score...
              precision    recall  f1-score   support

           0     0.9431    0.9587    0.9508       121
           1     0.8916    0.9867    0.9367        75
           2     0.9799    0.9917    0.9858      1083
           3     1.0000    0.9000    0.9474        10
           4     0.9615    0.6944    0.8065        36
           5     0.9067    0.8395    0.8718        81
           6     0.8587    0.9080    0.8827        87
           7     0.9839    0.9684    0.9761       696

    accuracy                         0.9680      2189
   macro avg     0.9407    0.9059    0.9197      2189
weighted avg     0.9684    0.9680    0.9676      2189

Macro average Test Precision, Recall and F1-Score...
(0.9406781361840347, 0.9059276877753434, 0.9197128207067353, None)
Micro average Test Precision, Recall and F1-Score...
(0.9680219278209228, 0.9680219278209228, 0.9680219278209228, None)
embeddings:
7688 5485 2189
[[0.03214906 0.01806935 0.00377342 ... 0.18067764 0.16179064 0.14972189]
 [0.10252504 0.1667056  0.17916034 ... 0.05345142 0.05266229 0.06383917]
 [0.40354398 0.40195027 0.62525976 ... 0.15920988 0.13743636 0.2233112 ]
 ...
 [0.34840232 0.3782404  0.4154791  ... 0.22320879 0.22958538 0.29535294]
 [0.20542128 0.2665158  0.36586863 ... 0.05184485 0.03300332 0.04590089]
 [0.35937342 0.35910758 0.43063888 ... 0.17875007 0.15894529 0.2098844 ]]
