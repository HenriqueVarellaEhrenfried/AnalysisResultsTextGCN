(4937, 300) (4937, 8) (2189, 300) (2189, 8) (13173, 300) (13173, 8)
15362
  (0, 5864)	1.021520945883481
  (0, 6572)	4.818458885761806
  (0, 7052)	3.362096962025199
  (0, 7916)	1.2457508634099117
  (0, 7933)	2.0838819303261675
  (0, 8096)	0.686135075474489
  (0, 9590)	1.1548972396321597
  (0, 10449)	5.949860997252907
  (0, 10914)	2.080745492836037
  (0, 11036)	1.6330397727043
  (0, 11444)	0.09164216929228669
  (0, 11878)	3.647275904258861
  (0, 12720)	0.9536627509544204
  (1, 5523)	5.7267174459386965
  (1, 5674)	3.6274732769626814
  (1, 5758)	4.360625792136326
  (1, 5917)	7.153833801578843
  (1, 5969)	7.631389111767649
  (1, 6209)	5.161403636888637
  (1, 6216)	3.9217127499606215
  (1, 6333)	6.547697998008527
  (1, 6737)	3.989766213205637
  (1, 6888)	1.7407007606022247
  (1, 7223)	2.810028379725159
  (1, 7295)	2.0131453792343894
  :	:
  (15361, 10641)	4.975301357254776
  (15361, 10690)	3.30014637316366
  (15361, 10787)	2.680292058069188
  (15361, 10833)	2.6898432290535306
  (15361, 10951)	4.868055826901179
  (15361, 11049)	3.7091513079769487
  (15361, 11110)	3.381072863484204
  (15361, 11181)	2.7552778649537504
  (15361, 11213)	2.929436111108544
  (15361, 11216)	6.866151729127062
  (15361, 11246)	3.88934746545859
  (15361, 11252)	5.687496732785416
  (15361, 11271)	0.967968172022305
  (15361, 11444)	0.09164216929228669
  (15361, 11902)	2.548663615590751
  (15361, 11922)	3.01069907518731
  (15361, 12000)	4.093563006887281
  (15361, 12048)	7.336155358372797
  (15361, 12172)	3.1962002848986444
  (15361, 12457)	4.5267526630103
  (15361, 12548)	3.0678574890272587
  (15361, 12694)	3.775109275768746
  (15361, 12757)	47.08188589283273
  (15361, 12768)	3.9416469648614387
  (15361, 13025)	6.921592674632485
(15362, 15362)
(15362, 15362)
15362
Tensor("graphconvolution_2/SparseTensorDenseMatMul/SparseTensorDenseMatMul:0", shape=(None, 8), dtype=float32)
Epoch: 0001 train_loss= 2.07956 train_acc= 0.05064 val_loss= 1.64330 val_acc= 0.76095 time= 0.40191
Epoch: 0002 train_loss= 1.63450 train_acc= 0.78367 val_loss= 1.29061 val_acc= 0.75912 time= 0.13000
Epoch: 0003 train_loss= 1.25996 train_acc= 0.78307 val_loss= 1.08787 val_acc= 0.60766 time= 0.12600
Epoch: 0004 train_loss= 1.03991 train_acc= 0.62123 val_loss= 0.82657 val_acc= 0.75912 time= 0.12553
Epoch: 0005 train_loss= 0.78676 train_acc= 0.78874 val_loss= 0.69117 val_acc= 0.75547 time= 0.12300
Epoch: 0006 train_loss= 0.64927 train_acc= 0.77294 val_loss= 0.61993 val_acc= 0.78467 time= 0.12300
Epoch: 0007 train_loss= 0.57626 train_acc= 0.80514 val_loss= 0.56645 val_acc= 0.83212 time= 0.12354
Epoch: 0008 train_loss= 0.51403 train_acc= 0.85842 val_loss= 0.51686 val_acc= 0.84489 time= 0.15004
Epoch: 0009 train_loss= 0.45820 train_acc= 0.86976 val_loss= 0.46994 val_acc= 0.85401 time= 0.12196
Epoch: 0010 train_loss= 0.40685 train_acc= 0.87887 val_loss= 0.43006 val_acc= 0.86314 time= 0.12600
Epoch: 0011 train_loss= 0.36507 train_acc= 0.88718 val_loss= 0.39773 val_acc= 0.86861 time= 0.12504
Epoch: 0012 train_loss= 0.31910 train_acc= 0.89690 val_loss= 0.37044 val_acc= 0.88686 time= 0.12496
Epoch: 0013 train_loss= 0.28127 train_acc= 0.91452 val_loss= 0.34491 val_acc= 0.89599 time= 0.12600
Epoch: 0014 train_loss= 0.24760 train_acc= 0.92526 val_loss= 0.32107 val_acc= 0.90876 time= 0.12403
Epoch: 0015 train_loss= 0.22090 train_acc= 0.93478 val_loss= 0.30015 val_acc= 0.92153 time= 0.12400
Epoch: 0016 train_loss= 0.19485 train_acc= 0.94430 val_loss= 0.27906 val_acc= 0.92883 time= 0.16800
Epoch: 0017 train_loss= 0.16881 train_acc= 0.94977 val_loss= 0.26337 val_acc= 0.93066 time= 0.12500
Epoch: 0018 train_loss= 0.15006 train_acc= 0.95564 val_loss= 0.25491 val_acc= 0.93613 time= 0.12697
Epoch: 0019 train_loss= 0.13481 train_acc= 0.95787 val_loss= 0.24904 val_acc= 0.93796 time= 0.12700
Epoch: 0020 train_loss= 0.12256 train_acc= 0.96131 val_loss= 0.24127 val_acc= 0.94343 time= 0.12600
Epoch: 0021 train_loss= 0.10706 train_acc= 0.96658 val_loss= 0.23847 val_acc= 0.94161 time= 0.12404
Epoch: 0022 train_loss= 0.10131 train_acc= 0.96860 val_loss= 0.23714 val_acc= 0.93796 time= 0.12596
Epoch: 0023 train_loss= 0.08756 train_acc= 0.97286 val_loss= 0.23355 val_acc= 0.94526 time= 0.16900
Epoch: 0024 train_loss= 0.07486 train_acc= 0.97590 val_loss= 0.23073 val_acc= 0.94891 time= 0.12503
Epoch: 0025 train_loss= 0.06959 train_acc= 0.97893 val_loss= 0.22884 val_acc= 0.94708 time= 0.12300
Epoch: 0026 train_loss= 0.06739 train_acc= 0.97711 val_loss= 0.22810 val_acc= 0.94891 time= 0.12600
Epoch: 0027 train_loss= 0.05703 train_acc= 0.98076 val_loss= 0.22941 val_acc= 0.94891 time= 0.12700
Epoch: 0028 train_loss= 0.05139 train_acc= 0.98380 val_loss= 0.22886 val_acc= 0.94891 time= 0.12301
Epoch: 0029 train_loss= 0.04840 train_acc= 0.98461 val_loss= 0.23001 val_acc= 0.94891 time= 0.12496
Epoch: 0030 train_loss= 0.04260 train_acc= 0.98623 val_loss= 0.22729 val_acc= 0.95073 time= 0.12408
Epoch: 0031 train_loss= 0.04085 train_acc= 0.98724 val_loss= 0.22826 val_acc= 0.95255 time= 0.15500
Epoch: 0032 train_loss= 0.04062 train_acc= 0.98623 val_loss= 0.23012 val_acc= 0.95255 time= 0.12700
Epoch: 0033 train_loss= 0.03308 train_acc= 0.98866 val_loss= 0.23384 val_acc= 0.95255 time= 0.12500
Early stopping...
Optimization Finished!
Test set results: cost= 0.14710 accuracy= 0.96482 time= 0.05400
15362
Test Precision, Recall and F1-Score...
              precision    recall  f1-score   support

           0     0.9286    0.9669    0.9474       121
           1     0.8902    0.9733    0.9299        75
           2     0.9799    0.9908    0.9853      1083
           3     0.7143    0.5000    0.5882        10
           4     0.8966    0.7222    0.8000        36
           5     0.8701    0.8272    0.8481        81
           6     0.8602    0.9195    0.8889        87
           7     0.9868    0.9641    0.9753       696

    accuracy                         0.9648      2189
   macro avg     0.8908    0.8580    0.8704      2189
weighted avg     0.9648    0.9648    0.9644      2189

Macro average Test Precision, Recall and F1-Score...
(0.8908338843761061, 0.858005659682072, 0.8703910618700141, None)
Micro average Test Precision, Recall and F1-Score...
(0.964824120603015, 0.964824120603015, 0.964824120603015, None)
embeddings:
7688 5485 2189
[[-0.35098332  0.02585033  0.10113368 ...  0.10602794  0.54803
  -0.02790713]
 [-0.28987736 -0.1603496  -0.18432099 ... -0.15069155  0.14331001
   0.18473816]
 [-0.36508366 -0.28544557 -0.19697395 ...  0.10999972  0.01285048
  -0.04050592]
 ...
 [-0.39226586 -0.241525   -0.0599579  ...  0.2868758   0.28286558
  -0.3466523 ]
 [-0.3882495  -0.36280462 -0.330575   ... -0.28026232  0.13535891
   0.41059127]
 [-0.28209782 -0.20894031 -0.00424483 ...  0.20053636  0.0774237
  -0.12258548]]
