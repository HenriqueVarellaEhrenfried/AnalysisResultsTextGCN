(4937, 300) (4937, 8) (2189, 300) (2189, 8) (13173, 300) (13173, 8)
15362
  (0, 5864)	1.021520945883481
  (0, 6572)	4.818458885761806
  (0, 7052)	3.362096962025199
  (0, 7916)	1.2457508634099117
  (0, 7933)	2.0838819303261675
  (0, 8096)	0.686135075474489
  (0, 9590)	1.1548972396321597
  (0, 10449)	5.949860997252907
  (0, 10914)	2.080745492836037
  (0, 11036)	1.6330397727043
  (0, 11444)	0.09164216929228669
  (0, 11878)	3.647275904258861
  (0, 12720)	0.9536627509544204
  (1, 5523)	5.7267174459386965
  (1, 5674)	3.6274732769626814
  (1, 5758)	4.360625792136326
  (1, 5917)	7.153833801578843
  (1, 5969)	7.631389111767649
  (1, 6209)	5.161403636888637
  (1, 6216)	3.9217127499606215
  (1, 6333)	6.547697998008527
  (1, 6737)	3.989766213205637
  (1, 6888)	1.7407007606022247
  (1, 7223)	2.810028379725159
  (1, 7295)	2.0131453792343894
  :	:
  (15361, 10641)	4.975301357254776
  (15361, 10690)	3.30014637316366
  (15361, 10787)	2.680292058069188
  (15361, 10833)	2.6898432290535306
  (15361, 10951)	4.868055826901179
  (15361, 11049)	3.7091513079769487
  (15361, 11110)	3.381072863484204
  (15361, 11181)	2.7552778649537504
  (15361, 11213)	2.929436111108544
  (15361, 11216)	6.866151729127062
  (15361, 11246)	3.88934746545859
  (15361, 11252)	5.687496732785416
  (15361, 11271)	0.967968172022305
  (15361, 11444)	0.09164216929228669
  (15361, 11902)	2.548663615590751
  (15361, 11922)	3.01069907518731
  (15361, 12000)	4.093563006887281
  (15361, 12048)	7.336155358372797
  (15361, 12172)	3.1962002848986444
  (15361, 12457)	4.5267526630103
  (15361, 12548)	3.0678574890272587
  (15361, 12694)	3.775109275768746
  (15361, 12757)	47.08188589283273
  (15361, 12768)	3.9416469648614387
  (15361, 13025)	6.921592674632485
(15362, 15362)
(15362, 15362)
15362
Tensor("graphconvolution_2/SparseTensorDenseMatMul/SparseTensorDenseMatMul:0", shape=(None, 8), dtype=float32)
Epoch: 0001 train_loss= 2.07949 train_acc= 0.06907 val_loss= 1.64148 val_acc= 0.70073 time= 0.39254
Epoch: 0002 train_loss= 1.62316 train_acc= 0.71379 val_loss= 1.29021 val_acc= 0.74453 time= 0.13000
Epoch: 0003 train_loss= 1.24811 train_acc= 0.76646 val_loss= 1.08739 val_acc= 0.59854 time= 0.13704
Epoch: 0004 train_loss= 1.04037 train_acc= 0.60766 val_loss= 0.83639 val_acc= 0.75912 time= 0.12361
Epoch: 0005 train_loss= 0.79744 train_acc= 0.78388 val_loss= 0.70520 val_acc= 0.75547 time= 0.12400
Epoch: 0006 train_loss= 0.66282 train_acc= 0.77375 val_loss= 0.64711 val_acc= 0.75912 time= 0.12300
Epoch: 0007 train_loss= 0.59843 train_acc= 0.77962 val_loss= 0.59945 val_acc= 0.79197 time= 0.12200
Epoch: 0008 train_loss= 0.54929 train_acc= 0.81973 val_loss= 0.55349 val_acc= 0.82482 time= 0.12300
Epoch: 0009 train_loss= 0.49681 train_acc= 0.84950 val_loss= 0.51004 val_acc= 0.83212 time= 0.12475
Epoch: 0010 train_loss= 0.45016 train_acc= 0.85700 val_loss= 0.47056 val_acc= 0.84672 time= 0.12436
Epoch: 0011 train_loss= 0.40471 train_acc= 0.86834 val_loss= 0.43504 val_acc= 0.85584 time= 0.15500
Epoch: 0012 train_loss= 0.35967 train_acc= 0.87847 val_loss= 0.40532 val_acc= 0.86679 time= 0.12597
Epoch: 0013 train_loss= 0.32149 train_acc= 0.89265 val_loss= 0.38029 val_acc= 0.88869 time= 0.12500
Epoch: 0014 train_loss= 0.28896 train_acc= 0.91128 val_loss= 0.35619 val_acc= 0.89599 time= 0.12310
Epoch: 0015 train_loss= 0.25803 train_acc= 0.92708 val_loss= 0.33199 val_acc= 0.90876 time= 0.12416
Epoch: 0016 train_loss= 0.22408 train_acc= 0.93761 val_loss= 0.30863 val_acc= 0.92336 time= 0.12300
Epoch: 0017 train_loss= 0.20256 train_acc= 0.94491 val_loss= 0.28720 val_acc= 0.92336 time= 0.13144
Epoch: 0018 train_loss= 0.17880 train_acc= 0.95037 val_loss= 0.27179 val_acc= 0.93248 time= 0.12500
Epoch: 0019 train_loss= 0.16430 train_acc= 0.95260 val_loss= 0.26055 val_acc= 0.93796 time= 0.16901
Epoch: 0020 train_loss= 0.13408 train_acc= 0.96435 val_loss= 0.24960 val_acc= 0.93613 time= 0.12600
Epoch: 0021 train_loss= 0.11738 train_acc= 0.96617 val_loss= 0.24121 val_acc= 0.93613 time= 0.12204
Epoch: 0022 train_loss= 0.10417 train_acc= 0.96840 val_loss= 0.23575 val_acc= 0.94161 time= 0.12407
Epoch: 0023 train_loss= 0.10285 train_acc= 0.96800 val_loss= 0.23177 val_acc= 0.93978 time= 0.12303
Epoch: 0024 train_loss= 0.08772 train_acc= 0.97124 val_loss= 0.22711 val_acc= 0.94161 time= 0.12403
Epoch: 0025 train_loss= 0.07545 train_acc= 0.97691 val_loss= 0.22298 val_acc= 0.94526 time= 0.12678
Epoch: 0026 train_loss= 0.07238 train_acc= 0.97772 val_loss= 0.22204 val_acc= 0.94708 time= 0.15799
Epoch: 0027 train_loss= 0.06035 train_acc= 0.98319 val_loss= 0.22289 val_acc= 0.94891 time= 0.12397
Epoch: 0028 train_loss= 0.05708 train_acc= 0.98177 val_loss= 0.22664 val_acc= 0.94708 time= 0.12803
Epoch: 0029 train_loss= 0.05319 train_acc= 0.98400 val_loss= 0.23130 val_acc= 0.94891 time= 0.12397
Epoch: 0030 train_loss= 0.04981 train_acc= 0.98521 val_loss= 0.22938 val_acc= 0.95073 time= 0.12300
Epoch: 0031 train_loss= 0.04502 train_acc= 0.98582 val_loss= 0.22590 val_acc= 0.95620 time= 0.12203
Epoch: 0032 train_loss= 0.03919 train_acc= 0.98805 val_loss= 0.22443 val_acc= 0.95620 time= 0.12200
Epoch: 0033 train_loss= 0.03688 train_acc= 0.98724 val_loss= 0.22266 val_acc= 0.95438 time= 0.12497
Epoch: 0034 train_loss= 0.03174 train_acc= 0.98886 val_loss= 0.22269 val_acc= 0.95438 time= 0.16600
Epoch: 0035 train_loss= 0.02987 train_acc= 0.98967 val_loss= 0.22476 val_acc= 0.95255 time= 0.12303
Epoch: 0036 train_loss= 0.03206 train_acc= 0.98866 val_loss= 0.22348 val_acc= 0.95438 time= 0.12697
Epoch: 0037 train_loss= 0.02518 train_acc= 0.99068 val_loss= 0.22548 val_acc= 0.95803 time= 0.12449
Early stopping...
Optimization Finished!
Test set results: cost= 0.15423 accuracy= 0.96437 time= 0.05400
15362
Test Precision, Recall and F1-Score...
              precision    recall  f1-score   support

           0     0.9350    0.9504    0.9426       121
           1     0.9103    0.9467    0.9281        75
           2     0.9799    0.9908    0.9853      1083
           3     0.5882    1.0000    0.7407        10
           4     0.9630    0.7222    0.8254        36
           5     0.9275    0.7901    0.8533        81
           6     0.8218    0.9540    0.8830        87
           7     0.9853    0.9612    0.9731       696

    accuracy                         0.9644      2189
   macro avg     0.8889    0.9144    0.8914      2189
weighted avg     0.9665    0.9644    0.9644      2189

Macro average Test Precision, Recall and F1-Score...
(0.8888641952913432, 0.9144277304419169, 0.8914469599525491, None)
Micro average Test Precision, Recall and F1-Score...
(0.9643672910004568, 0.9643672910004568, 0.9643672910004568, None)
embeddings:
7688 5485 2189
[[ 0.19313203  0.16175884 -0.08821129 ...  0.23529197  0.16447473
   0.16678315]
 [-0.11855843 -0.12548344 -0.06270033 ... -0.14627737  0.34430704
  -0.15507771]
 [ 0.093033   -0.04231054  0.49129555 ...  0.05863467  0.02643747
   0.08747976]
 ...
 [ 0.26795205  0.1177633   0.51792353 ...  0.23312819  0.10083473
   0.2470497 ]
 [-0.2707658  -0.2479407  -0.14761262 ... -0.29400957  0.40386605
  -0.31400698]
 [ 0.18992953  0.10418133  0.48961845 ...  0.16824314  0.09289265
   0.166048  ]]
